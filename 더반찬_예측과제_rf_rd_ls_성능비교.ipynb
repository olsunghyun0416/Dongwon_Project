{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제#1. 더반찬 주문량 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 환경준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리 가져오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ORD_NO</th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>O_YMD</th>\n",
       "      <th>PKG_GOODS_NO</th>\n",
       "      <th>PKG_GOODS_NM</th>\n",
       "      <th>GOODS_NO</th>\n",
       "      <th>GOODS_NM</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM</th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>RECVR_ROAD_BASE_ADDR</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>202201095519105</td>\n",
       "      <td>2022-01-11 00:00:00</td>\n",
       "      <td>2022-01-09 12:26:10</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1901012353</td>\n",
       "      <td>수제계란말이(350g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>충청북도 증평군 증평읍 송산로 11 (지평더웰아파트)</td>\n",
       "      <td>6900</td>\n",
       "      <td>569.0</td>\n",
       "      <td>6331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>202201105522898</td>\n",
       "      <td>2022-01-11 00:00:00</td>\n",
       "      <td>2022-01-10 10:35:49</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1901012353</td>\n",
       "      <td>수제계란말이(350g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 강남구 논현로85길 52 (역삼동)</td>\n",
       "      <td>6900</td>\n",
       "      <td>177.0</td>\n",
       "      <td>6723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>202201115527172</td>\n",
       "      <td>2022-01-12 00:00:00</td>\n",
       "      <td>2022-01-11 11:38:32</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1901012353</td>\n",
       "      <td>수제계란말이(350g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 송파구 올림픽로4길 42 (잠실동, 우성아파트)</td>\n",
       "      <td>6900</td>\n",
       "      <td>221.0</td>\n",
       "      <td>6679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>202201105523467</td>\n",
       "      <td>2022-01-12 00:00:00</td>\n",
       "      <td>2022-01-10 13:21:51</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1901012353</td>\n",
       "      <td>수제계란말이(350g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>강원도 속초시 도리원길 11-14 (노학동)</td>\n",
       "      <td>6900</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>202201105522519</td>\n",
       "      <td>2022-01-11 00:00:00</td>\n",
       "      <td>2022-01-10 08:16:21</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1901012353</td>\n",
       "      <td>수제계란말이(350g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 용인시 수지구 동천로 64 (동천동, 동천마을동문굿모닝힐5차아파트)</td>\n",
       "      <td>6900</td>\n",
       "      <td>157.0</td>\n",
       "      <td>6743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           ORD_NO                H_YMD                O_YMD  \\\n",
       "0           0  202201095519105  2022-01-11 00:00:00  2022-01-09 12:26:10   \n",
       "1           1  202201105522898  2022-01-11 00:00:00  2022-01-10 10:35:49   \n",
       "2           2  202201115527172  2022-01-12 00:00:00  2022-01-11 11:38:32   \n",
       "3           3  202201105523467  2022-01-12 00:00:00  2022-01-10 13:21:51   \n",
       "4           4  202201105522519  2022-01-11 00:00:00  2022-01-10 08:16:21   \n",
       "\n",
       "  PKG_GOODS_NO PKG_GOODS_NM    GOODS_NO      GOODS_NM STD_GSGR_NO_LEV1_NM  \\\n",
       "0           단품           단품  1901012353  수제계란말이(350g)                  반찬   \n",
       "1           단품           단품  1901012353  수제계란말이(350g)                  반찬   \n",
       "2           단품           단품  1901012353  수제계란말이(350g)                  반찬   \n",
       "3           단품           단품  1901012353  수제계란말이(350g)                  반찬   \n",
       "4           단품           단품  1901012353  수제계란말이(350g)                  반찬   \n",
       "\n",
       "   ORD_QTY  CANCEL_QTY  RET_QTY  REAL_ORD_QTY  \\\n",
       "0        1           0        0             1   \n",
       "1        1           0        0             1   \n",
       "2        1           0        0             1   \n",
       "3        1           0        0             1   \n",
       "4        1           0        0             1   \n",
       "\n",
       "                        RECVR_ROAD_BASE_ADDR  SALE_PRICE  DISCOUNT_AMT  \\\n",
       "0              충청북도 증평군 증평읍 송산로 11 (지평더웰아파트)        6900         569.0   \n",
       "1                  서울특별시 강남구 논현로85길 52 (역삼동)        6900         177.0   \n",
       "2           서울특별시 송파구 올림픽로4길 42 (잠실동, 우성아파트)        6900         221.0   \n",
       "3                   강원도 속초시 도리원길 11-14 (노학동)        6900         128.0   \n",
       "4  경기도 용인시 수지구 동천로 64 (동천동, 동천마을동문굿모닝힐5차아파트)        6900         157.0   \n",
       "\n",
       "   FINAL_PRICE  \n",
       "0         6331  \n",
       "1         6723  \n",
       "2         6679  \n",
       "3         6772  \n",
       "4         6743  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw data 로딩 \n",
    "raw_data = pd.read_csv(r'C:\\Users\\user\\Desktop\\intern.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain</th>\n",
       "      <th>humid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>91.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>85.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15595</th>\n",
       "      <td>15595</td>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>62.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15596</th>\n",
       "      <td>15596</td>\n",
       "      <td>2022-07-11</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15597</th>\n",
       "      <td>15597</td>\n",
       "      <td>2022-07-09</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15598</th>\n",
       "      <td>15598</td>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>5.5</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15599</th>\n",
       "      <td>15599</td>\n",
       "      <td>2022-07-11</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15600 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      H_YMD       temp  rain      humid\n",
       "0               0 2020-04-29  14.400000   0.0  65.000000\n",
       "1               1 2020-04-30  16.300000   0.0  78.300000\n",
       "2               2 2020-05-01  20.400000   0.0  88.300000\n",
       "3               3 2020-05-02  20.800000   0.1  91.100000\n",
       "4               4 2020-05-03  21.100000   0.6  85.800000\n",
       "...           ...        ...        ...   ...        ...\n",
       "15595       15595 2022-07-10  29.400000   0.4  62.900000\n",
       "15596       15596 2022-07-11   2.333333   0.0  58.333333\n",
       "15597       15597 2022-07-09  28.100000   0.0  74.300000\n",
       "15598       15598 2022-07-10  25.500000   5.5  87.000000\n",
       "15599       15599 2022-07-11   1.708333   0.0  48.541667\n",
       "\n",
       "[15600 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_excel(r'C:\\Users\\user\\Desktop\\w.xlsx')\n",
    "weather.rename(columns={'date':'H_YMD'}, inplace=True)\n",
    "weather['H_YMD'] = pd.to_datetime(weather['H_YMD'])\n",
    "weather.drop('spot', axis=1, inplace=True)\n",
    "\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ORD_NO</th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>O_YMD</th>\n",
       "      <th>PKG_GOODS_NO</th>\n",
       "      <th>PKG_GOODS_NM</th>\n",
       "      <th>GOODS_NO</th>\n",
       "      <th>GOODS_NM</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM</th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>RECVR_ROAD_BASE_ADDR</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166288</th>\n",
       "      <td>119348</td>\n",
       "      <td>201912302355791</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 21:59:40</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>14375</td>\n",
       "      <td>옛날잡채(500g)</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 수원시 장안구 경수대로976번길 22 (조원동, 수원 한일타운)</td>\n",
       "      <td>8600</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>7192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37753</th>\n",
       "      <td>37753</td>\n",
       "      <td>201912302355557</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 20:50:07</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1901012353</td>\n",
       "      <td>수제계란말이(350g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>서울 성북구 동소문로34길 24 삼성아파트</td>\n",
       "      <td>6300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162585</th>\n",
       "      <td>115645</td>\n",
       "      <td>201912302353567</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 11:02:39</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1823</td>\n",
       "      <td>숙주나물(300g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 삼개로 33 (도화동, 도화3지구우성아파트)</td>\n",
       "      <td>3300</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164041</th>\n",
       "      <td>117101</td>\n",
       "      <td>201912302354611</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 15:19:58</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1712010310</td>\n",
       "      <td>두메산나물비빔밥재료</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 용인시 수지구 문인로3번길 22 (풍덕천동)</td>\n",
       "      <td>6900</td>\n",
       "      <td>264.0</td>\n",
       "      <td>6636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164040</th>\n",
       "      <td>117100</td>\n",
       "      <td>201912302352965</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 10:08:58</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1712010310</td>\n",
       "      <td>두메산나물비빔밥재료</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 구리시 아차산로487번길 27 (교문동, 아차산어울림아파트)</td>\n",
       "      <td>6900</td>\n",
       "      <td>317.0</td>\n",
       "      <td>6583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           ORD_NO      H_YMD                O_YMD  \\\n",
       "166288      119348  201912302355791 2020-01-01  2019-12-30 21:59:40   \n",
       "37753        37753  201912302355557 2020-01-01  2019-12-30 20:50:07   \n",
       "162585      115645  201912302353567 2020-01-01  2019-12-30 11:02:39   \n",
       "164041      117101  201912302354611 2020-01-01  2019-12-30 15:19:58   \n",
       "164040      117100  201912302352965 2020-01-01  2019-12-30 10:08:58   \n",
       "\n",
       "       PKG_GOODS_NO PKG_GOODS_NM    GOODS_NO      GOODS_NM  \\\n",
       "166288           단품           단품       14375    옛날잡채(500g)   \n",
       "37753            단품           단품  1901012353  수제계란말이(350g)   \n",
       "162585           단품           단품        1823    숙주나물(300g)   \n",
       "164041           단품           단품  1712010310    두메산나물비빔밥재료   \n",
       "164040           단품           단품  1712010310    두메산나물비빔밥재료   \n",
       "\n",
       "       STD_GSGR_NO_LEV1_NM  ORD_QTY  CANCEL_QTY  RET_QTY  REAL_ORD_QTY  \\\n",
       "166288                메인요리        1           0        0             1   \n",
       "37753                   반찬        2           0        0             2   \n",
       "162585                  반찬        1           0        0             1   \n",
       "164041                메인요리        1           0        0             1   \n",
       "164040                메인요리        1           0        0             1   \n",
       "\n",
       "                           RECVR_ROAD_BASE_ADDR  SALE_PRICE  DISCOUNT_AMT  \\\n",
       "166288  경기도 수원시 장안구 경수대로976번길 22 (조원동, 수원 한일타운)        8600        1408.0   \n",
       "37753                   서울 성북구 동소문로34길 24 삼성아파트        6300           NaN   \n",
       "162585       서울특별시 마포구 삼개로 33 (도화동, 도화3지구우성아파트)        3300         486.0   \n",
       "164041             경기도 용인시 수지구 문인로3번길 22 (풍덕천동)        6900         264.0   \n",
       "164040    경기도 구리시 아차산로487번길 27 (교문동, 아차산어울림아파트)        6900         317.0   \n",
       "\n",
       "        FINAL_PRICE  \n",
       "166288         7192  \n",
       "37753          6300  \n",
       "162585         2814  \n",
       "164041         6636  \n",
       "164040         6583  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 카피 데이터 생성\n",
    "copy_data = raw_data.copy()\n",
    "\n",
    "# 희망배송일 순서대로 데이터를 정렬\n",
    "copy_data = copy_data.sort_values(by = 'H_YMD')\n",
    "copy_data['H_YMD'] = pd.to_datetime(copy_data['H_YMD'])\n",
    "\n",
    "\n",
    "copy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ORD_NO</th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>O_YMD</th>\n",
       "      <th>PKG_GOODS_NO</th>\n",
       "      <th>PKG_GOODS_NM</th>\n",
       "      <th>GOODS_NO</th>\n",
       "      <th>GOODS_NM</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM</th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>RECVR_ROAD_BASE_ADDR</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166288</th>\n",
       "      <td>119348</td>\n",
       "      <td>201912302355791</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 21:59:40</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>14375</td>\n",
       "      <td>옛날잡채(500g)</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 수원시 장안구 경수대로976번길 22 (조원동, 수원 한일타운)</td>\n",
       "      <td>8600</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>7192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163504</th>\n",
       "      <td>116564</td>\n",
       "      <td>201912302355378</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 19:49:25</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>14375</td>\n",
       "      <td>옛날잡채(500g)</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 용인시 기흥구 연원로42번길 2 (마북동, 연원마을 삼호.벽산아파트)</td>\n",
       "      <td>8600</td>\n",
       "      <td>246.0</td>\n",
       "      <td>8354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170134</th>\n",
       "      <td>123194</td>\n",
       "      <td>201912302355473</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 20:20:12</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>14375</td>\n",
       "      <td>옛날잡채(500g)</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기 부천시 성주로23번가길 4 경원빌리지</td>\n",
       "      <td>8600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175012</th>\n",
       "      <td>128072</td>\n",
       "      <td>201912302355858</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 22:20:13</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>14375</td>\n",
       "      <td>옛날잡채(500g)</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>경기 용인시 수지구 진산로34번길 24 수지진산마을푸르지오</td>\n",
       "      <td>8600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163460</th>\n",
       "      <td>116520</td>\n",
       "      <td>201912292348570</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-29 00:14:26</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>14375</td>\n",
       "      <td>옛날잡채(500g)</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 송파구 송파대로32길 33 (가락동, 가락동부센트레빌)</td>\n",
       "      <td>8600</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>6600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           ORD_NO      H_YMD                O_YMD  \\\n",
       "166288      119348  201912302355791 2020-01-01  2019-12-30 21:59:40   \n",
       "163504      116564  201912302355378 2020-01-01  2019-12-30 19:49:25   \n",
       "170134      123194  201912302355473 2020-01-01  2019-12-30 20:20:12   \n",
       "175012      128072  201912302355858 2020-01-01  2019-12-30 22:20:13   \n",
       "163460      116520  201912292348570 2020-01-01  2019-12-29 00:14:26   \n",
       "\n",
       "       PKG_GOODS_NO PKG_GOODS_NM  GOODS_NO    GOODS_NM STD_GSGR_NO_LEV1_NM  \\\n",
       "166288           단품           단품     14375  옛날잡채(500g)                메인요리   \n",
       "163504           단품           단품     14375  옛날잡채(500g)                메인요리   \n",
       "170134           단품           단품     14375  옛날잡채(500g)                메인요리   \n",
       "175012           단품           단품     14375  옛날잡채(500g)                메인요리   \n",
       "163460           단품           단품     14375  옛날잡채(500g)                메인요리   \n",
       "\n",
       "        ORD_QTY  CANCEL_QTY  RET_QTY  REAL_ORD_QTY  \\\n",
       "166288        1           0        0             1   \n",
       "163504        1           0        0             1   \n",
       "170134        1           0        0             1   \n",
       "175012        2           0        0             2   \n",
       "163460        1           0        0             1   \n",
       "\n",
       "                              RECVR_ROAD_BASE_ADDR  SALE_PRICE  DISCOUNT_AMT  \\\n",
       "166288     경기도 수원시 장안구 경수대로976번길 22 (조원동, 수원 한일타운)        8600        1408.0   \n",
       "163504  경기도 용인시 기흥구 연원로42번길 2 (마북동, 연원마을 삼호.벽산아파트)        8600         246.0   \n",
       "170134                     경기 부천시 성주로23번가길 4 경원빌리지        8600           NaN   \n",
       "175012            경기 용인시 수지구 진산로34번길 24 수지진산마을푸르지오        8600           NaN   \n",
       "163460        서울특별시 송파구 송파대로32길 33 (가락동, 가락동부센트레빌)        8600        2000.0   \n",
       "\n",
       "        FINAL_PRICE  \n",
       "166288         7192  \n",
       "163504         8354  \n",
       "170134         8600  \n",
       "175012         8600  \n",
       "163460         6600  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = copy_data[copy_data['GOODS_NO'] == 14375]\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476589   2022-04-20\n",
       "476595   2022-04-20\n",
       "476612   2022-04-20\n",
       "476593   2022-04-20\n",
       "476590   2022-04-20\n",
       "            ...    \n",
       "231310   2022-05-31\n",
       "231303   2022-05-31\n",
       "231300   2022-05-31\n",
       "231287   2022-05-31\n",
       "239764   2022-05-31\n",
       "Name: H_YMD, Length: 1899, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data['H_YMD'].loc[copy_data['GOODS_NM']== '소고기유니짜장소스(1인분, 200g)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   0\n",
       "ORD_NO                       0\n",
       "H_YMD                        0\n",
       "O_YMD                        0\n",
       "PKG_GOODS_NO                 0\n",
       "PKG_GOODS_NM                 0\n",
       "GOODS_NO                     0\n",
       "GOODS_NM                     0\n",
       "STD_GSGR_NO_LEV1_NM          0\n",
       "ORD_QTY                      0\n",
       "CANCEL_QTY                   0\n",
       "RET_QTY                      0\n",
       "REAL_ORD_QTY                 0\n",
       "RECVR_ROAD_BASE_ADDR         0\n",
       "SALE_PRICE                   0\n",
       "DISCOUNT_AMT            376247\n",
       "FINAL_PRICE                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치가 있는 데이터 확인\n",
    "copy_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 예측 대상과 다른 데이터를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>GOODS_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247444</th>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>고소한도토리묵무침(265g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258485</th>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>고소한도토리묵무침(265g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258467</th>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>고소한도토리묵무침(265g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258533</th>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>고소한도토리묵무침(265g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258513</th>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>고소한도토리묵무침(265g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187039</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>고소한도토리묵무침(265g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187054</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>고소한도토리묵무침(265g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197774</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>고소한도토리묵무침(265g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187092</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>고소한도토리묵무침(265g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187093</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>고소한도토리묵무침(265g)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21898 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            H_YMD         GOODS_NM\n",
       "247444 2020-06-03  고소한도토리묵무침(265g)\n",
       "258485 2020-06-03  고소한도토리묵무침(265g)\n",
       "258467 2020-06-03  고소한도토리묵무침(265g)\n",
       "258533 2020-06-03  고소한도토리묵무침(265g)\n",
       "258513 2020-06-03  고소한도토리묵무침(265g)\n",
       "...           ...              ...\n",
       "187039 2022-02-28  고소한도토리묵무침(265g)\n",
       "187054 2022-02-28  고소한도토리묵무침(265g)\n",
       "197774 2022-02-28  고소한도토리묵무침(265g)\n",
       "187092 2022-02-28  고소한도토리묵무침(265g)\n",
       "187093 2022-02-28  고소한도토리묵무침(265g)\n",
       "\n",
       "[21898 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data[['H_YMD', 'GOODS_NM']].loc[copy_data['GOODS_NM'] == '고소한도토리묵무침(265g)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>GOODS_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171876</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>꼬막무침 (250g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162252</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>꼬막무침 (250g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171662</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>꼬막무침 (250g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171659</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>꼬막무침 (250g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171657</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>꼬막무침 (250g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670874</th>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>꼬막무침 (250g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649116</th>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>꼬막무침 (250g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670873</th>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>꼬막무침 (250g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641145</th>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>꼬막무침 (250g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670872</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>꼬막무침 (250g)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            H_YMD     GOODS_NM\n",
       "171876 2020-01-01  꼬막무침 (250g)\n",
       "162252 2020-01-01  꼬막무침 (250g)\n",
       "171662 2020-01-01  꼬막무침 (250g)\n",
       "171659 2020-01-01  꼬막무침 (250g)\n",
       "171657 2020-01-01  꼬막무침 (250g)\n",
       "...           ...          ...\n",
       "670874 2021-07-02  꼬막무침 (250g)\n",
       "649116 2021-07-02  꼬막무침 (250g)\n",
       "670873 2021-07-03  꼬막무침 (250g)\n",
       "641145 2021-07-09  꼬막무침 (250g)\n",
       "670872 2021-07-12  꼬막무침 (250g)\n",
       "\n",
       "[26499 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data[['H_YMD', 'GOODS_NM']].loc[copy_data['GOODS_NM'] == '꼬막무침 (250g)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>GOODS_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167308</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>건고사리나물볶음(150g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167529</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>건고사리나물볶음(150g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164823</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>건고사리나물볶음(150g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174673</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>건고사리나물볶음(150g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167336</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>건고사리나물볶음(150g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397331</th>\n",
       "      <td>2021-10-30</td>\n",
       "      <td>건고사리나물볶음(150g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397444</th>\n",
       "      <td>2021-10-30</td>\n",
       "      <td>건고사리나물볶음(150g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395160</th>\n",
       "      <td>2021-10-30</td>\n",
       "      <td>건고사리나물볶음(150g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386418</th>\n",
       "      <td>2021-10-30</td>\n",
       "      <td>건고사리나물볶음(150g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386423</th>\n",
       "      <td>2021-10-30</td>\n",
       "      <td>건고사리나물볶음(150g)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17556 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            H_YMD        GOODS_NM\n",
       "167308 2020-01-01  건고사리나물볶음(150g)\n",
       "167529 2020-01-01  건고사리나물볶음(150g)\n",
       "164823 2020-01-01  건고사리나물볶음(150g)\n",
       "174673 2020-01-01  건고사리나물볶음(150g)\n",
       "167336 2020-01-01  건고사리나물볶음(150g)\n",
       "...           ...             ...\n",
       "397331 2021-10-30  건고사리나물볶음(150g)\n",
       "397444 2021-10-30  건고사리나물볶음(150g)\n",
       "395160 2021-10-30  건고사리나물볶음(150g)\n",
       "386418 2021-10-30  건고사리나물볶음(150g)\n",
       "386423 2021-10-30  건고사리나물볶음(150g)\n",
       "\n",
       "[17556 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data[['H_YMD', 'GOODS_NM']].loc[copy_data['GOODS_NM'] == '건고사리나물볶음(150g)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3208\\3925397722.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  copy_data['GOODS_NM'].loc[copy_data['GOODS_NM'] == '꼬막무침 (250g)'] = '꼬막무침 (260g)'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3208\\3925397722.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  copy_data['GOODS_NM'].loc[copy_data['GOODS_NM'] == '고소한도토리묵무침(265g)'] = '고소한도토리묵무침(360g)'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3208\\3925397722.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  copy_data['GOODS_NM'].loc[copy_data['GOODS_NM'] == '건고사리나물볶음(150g)'] = '고사리나물볶음(150g)'\n"
     ]
    }
   ],
   "source": [
    "# 예측 대상에는 없는 상품들은 모두 nan값으로 변경\n",
    "copy_data['GOODS_NM'].loc[copy_data['GOODS_NM'] == '꼬막무침 (250g)'] = '꼬막무침 (260g)'\n",
    "copy_data['GOODS_NM'].loc[copy_data['GOODS_NM'] == '고소한도토리묵무침(265g)'] = '고소한도토리묵무침(360g)'\n",
    "copy_data['GOODS_NM'].loc[copy_data['GOODS_NM'] == '건고사리나물볶음(150g)'] = '고사리나물볶음(150g)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 잘못 적재되어 있는 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3208\\1220614922.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  copy_data['PKG_GOODS_NM'].loc[copy_data['PKG_GOODS_NM'].str.contains('내일한정')] = '단품'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3208\\1220614922.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  copy_data['PKG_GOODS_NM'].loc[copy_data['PKG_GOODS_NM'] == '[한정판매] 두메산나물비빔밥재료'] = '단품'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3208\\1220614922.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  copy_data['PKG_GOODS_NM'].loc[copy_data['PKG_GOODS_NM'] == '[한정판매] 옛날잡채(500g)'] = '단품'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3208\\1220614922.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  copy_data['PKG_GOODS_NM'].loc[copy_data['PKG_GOODS_NM'] != '단품'] = '세트'\n"
     ]
    }
   ],
   "source": [
    "# 내일한정, 한정판매는 단품으로 대체\n",
    "# 한정판매 중에는 단품이 아닌 세트도 있어서 이를 유의해야 함(ex. '[한정판매]손님초대상 set', '[한정판매]반찬 한 상 set', '[한정판매]키즈 set')\n",
    "\n",
    "# 내일한정이 붙은 제품은 모두 단품인 것을 확인하여 카테고리를 단품으로 바꿔줌, \n",
    "# [내일한정] 고소한도토리묵무침(265g), [내일한정] 건고사리나물볶음(150g), [내일한정] 꼬막무침 (250g)은 제외\n",
    "copy_data['PKG_GOODS_NM'].loc[copy_data['PKG_GOODS_NM'].str.contains('내일한정')] = '단품'\n",
    "\n",
    "# 한정판매 중에서 두 제품만 단품이었기에 두 제품을 단품으로 바꿔줌\n",
    "copy_data['PKG_GOODS_NM'].loc[copy_data['PKG_GOODS_NM'] == '[한정판매] 두메산나물비빔밥재료'] = '단품'  \n",
    "copy_data['PKG_GOODS_NM'].loc[copy_data['PKG_GOODS_NM'] == '[한정판매] 옛날잡채(500g)'] = '단품'\n",
    "\n",
    "# 단품으로 바꿔주지 않은 모든 제품을 세트로 바꿔줌\n",
    "copy_data['PKG_GOODS_NM'].loc[copy_data['PKG_GOODS_NM'] != '단품'] = '세트'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 데이터 타입 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 희망배송일 변수를 datetime 형식으로 변환\n",
    "\n",
    "copy_data['H_YMD'] = pd.to_datetime(copy_data['H_YMD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 특정 컬럼의 결측치 채우기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ORD_NO</th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>O_YMD</th>\n",
       "      <th>PKG_GOODS_NO</th>\n",
       "      <th>PKG_GOODS_NM</th>\n",
       "      <th>GOODS_NO</th>\n",
       "      <th>GOODS_NM</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM</th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>RECVR_ROAD_BASE_ADDR</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166288</th>\n",
       "      <td>119348</td>\n",
       "      <td>201912302355791</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 21:59:40</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>14375</td>\n",
       "      <td>옛날잡채(500g)</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 수원시 장안구 경수대로976번길 22 (조원동, 수원 한일타운)</td>\n",
       "      <td>8600</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>7192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37753</th>\n",
       "      <td>37753</td>\n",
       "      <td>201912302355557</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 20:50:07</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1901012353</td>\n",
       "      <td>수제계란말이(350g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>서울 성북구 동소문로34길 24 삼성아파트</td>\n",
       "      <td>6300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162585</th>\n",
       "      <td>115645</td>\n",
       "      <td>201912302353567</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 11:02:39</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1823</td>\n",
       "      <td>숙주나물(300g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 삼개로 33 (도화동, 도화3지구우성아파트)</td>\n",
       "      <td>3300</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164041</th>\n",
       "      <td>117101</td>\n",
       "      <td>201912302354611</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 15:19:58</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1712010310</td>\n",
       "      <td>두메산나물비빔밥재료</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 용인시 수지구 문인로3번길 22 (풍덕천동)</td>\n",
       "      <td>6900</td>\n",
       "      <td>264.0</td>\n",
       "      <td>6636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164040</th>\n",
       "      <td>117100</td>\n",
       "      <td>201912302352965</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 10:08:58</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1712010310</td>\n",
       "      <td>두메산나물비빔밥재료</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 구리시 아차산로487번길 27 (교문동, 아차산어울림아파트)</td>\n",
       "      <td>6900</td>\n",
       "      <td>317.0</td>\n",
       "      <td>6583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           ORD_NO      H_YMD                O_YMD  \\\n",
       "166288      119348  201912302355791 2020-01-01  2019-12-30 21:59:40   \n",
       "37753        37753  201912302355557 2020-01-01  2019-12-30 20:50:07   \n",
       "162585      115645  201912302353567 2020-01-01  2019-12-30 11:02:39   \n",
       "164041      117101  201912302354611 2020-01-01  2019-12-30 15:19:58   \n",
       "164040      117100  201912302352965 2020-01-01  2019-12-30 10:08:58   \n",
       "\n",
       "       PKG_GOODS_NO PKG_GOODS_NM    GOODS_NO      GOODS_NM  \\\n",
       "166288           단품           단품       14375    옛날잡채(500g)   \n",
       "37753            단품           단품  1901012353  수제계란말이(350g)   \n",
       "162585           단품           단품        1823    숙주나물(300g)   \n",
       "164041           단품           단품  1712010310    두메산나물비빔밥재료   \n",
       "164040           단품           단품  1712010310    두메산나물비빔밥재료   \n",
       "\n",
       "       STD_GSGR_NO_LEV1_NM  ORD_QTY  CANCEL_QTY  RET_QTY  REAL_ORD_QTY  \\\n",
       "166288                메인요리        1           0        0             1   \n",
       "37753                   반찬        2           0        0             2   \n",
       "162585                  반찬        1           0        0             1   \n",
       "164041                메인요리        1           0        0             1   \n",
       "164040                메인요리        1           0        0             1   \n",
       "\n",
       "                           RECVR_ROAD_BASE_ADDR  SALE_PRICE  DISCOUNT_AMT  \\\n",
       "166288  경기도 수원시 장안구 경수대로976번길 22 (조원동, 수원 한일타운)        8600        1408.0   \n",
       "37753                   서울 성북구 동소문로34길 24 삼성아파트        6300           NaN   \n",
       "162585       서울특별시 마포구 삼개로 33 (도화동, 도화3지구우성아파트)        3300         486.0   \n",
       "164041             경기도 용인시 수지구 문인로3번길 22 (풍덕천동)        6900         264.0   \n",
       "164040    경기도 구리시 아차산로487번길 27 (교문동, 아차산어울림아파트)        6900         317.0   \n",
       "\n",
       "        FINAL_PRICE  \n",
       "166288         7192  \n",
       "37753          6300  \n",
       "162585         2814  \n",
       "164041         6636  \n",
       "164040         6583  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 할인액의 NaN값을 모두 0으로 대체\n",
    "# 할인되지 않은 상품을 산것으로 추측되어 이 경우 할인액은 0이 되는게 맞다.\n",
    "\n",
    "copy_data['DISCOUNT_AMT'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 만든 예측 대상과 다른 데이터에 들어있는 NaN 값을 모두 제거\n",
    "\n",
    "copy_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              0\n",
       "ORD_NO                  0\n",
       "H_YMD                   0\n",
       "O_YMD                   0\n",
       "PKG_GOODS_NO            0\n",
       "PKG_GOODS_NM            0\n",
       "GOODS_NO                0\n",
       "GOODS_NM                0\n",
       "STD_GSGR_NO_LEV1_NM     0\n",
       "ORD_QTY                 0\n",
       "CANCEL_QTY              0\n",
       "RET_QTY                 0\n",
       "REAL_ORD_QTY            0\n",
       "RECVR_ROAD_BASE_ADDR    0\n",
       "SALE_PRICE              0\n",
       "DISCOUNT_AMT            0\n",
       "FINAL_PRICE             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Feature Engineerung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 할인율을 나타내는 SALE_PERCENTAGE 변수 생성\n",
    "# 할인액 / 판매가격 * 100\n",
    "\n",
    "copy_data['SALE_PERCETANGE'] = (copy_data['DISCOUNT_AMT'] / copy_data['SALE_PRICE']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 희망배송일의 연도,월,일,시간,분,초를 각각 컬럼으로 만들어줌\n",
    "\n",
    "copy_data['year'] = copy_data['H_YMD'].dt.year\n",
    "copy_data['month'] = copy_data['H_YMD'].dt.month\n",
    "copy_data['day'] = copy_data['H_YMD'].dt.day\n",
    "# copy_data['hour'] = copy_data['H_YMD'].dt.hour\n",
    "# copy_data['minute'] = copy_data['H_YMD'].dt.minute\n",
    "# copy_data['second'] = copy_data['H_YMD'].dt.second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ORD_NO</th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>O_YMD</th>\n",
       "      <th>PKG_GOODS_NO</th>\n",
       "      <th>PKG_GOODS_NM</th>\n",
       "      <th>GOODS_NO</th>\n",
       "      <th>GOODS_NM</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM</th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>...</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>RECVR_ROAD_BASE_ADDR</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "      <th>SALE_PERCETANGE</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166288</th>\n",
       "      <td>119348</td>\n",
       "      <td>201912302355791</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 21:59:40</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>14375</td>\n",
       "      <td>옛날잡채(500g)</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 수원시 장안구 경수대로976번길 22 (조원동, 수원 한일타운)</td>\n",
       "      <td>8600</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>7192</td>\n",
       "      <td>16.372093</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37753</th>\n",
       "      <td>37753</td>\n",
       "      <td>201912302355557</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 20:50:07</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1901012353</td>\n",
       "      <td>수제계란말이(350g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>서울 성북구 동소문로34길 24 삼성아파트</td>\n",
       "      <td>6300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162585</th>\n",
       "      <td>115645</td>\n",
       "      <td>201912302353567</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 11:02:39</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1823</td>\n",
       "      <td>숙주나물(300g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 삼개로 33 (도화동, 도화3지구우성아파트)</td>\n",
       "      <td>3300</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2814</td>\n",
       "      <td>14.727273</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164041</th>\n",
       "      <td>117101</td>\n",
       "      <td>201912302354611</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 15:19:58</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1712010310</td>\n",
       "      <td>두메산나물비빔밥재료</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 용인시 수지구 문인로3번길 22 (풍덕천동)</td>\n",
       "      <td>6900</td>\n",
       "      <td>264.0</td>\n",
       "      <td>6636</td>\n",
       "      <td>3.826087</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164040</th>\n",
       "      <td>117100</td>\n",
       "      <td>201912302352965</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2019-12-30 10:08:58</td>\n",
       "      <td>단품</td>\n",
       "      <td>단품</td>\n",
       "      <td>1712010310</td>\n",
       "      <td>두메산나물비빔밥재료</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>경기도 구리시 아차산로487번길 27 (교문동, 아차산어울림아파트)</td>\n",
       "      <td>6900</td>\n",
       "      <td>317.0</td>\n",
       "      <td>6583</td>\n",
       "      <td>4.594203</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           ORD_NO      H_YMD                O_YMD  \\\n",
       "166288      119348  201912302355791 2020-01-01  2019-12-30 21:59:40   \n",
       "37753        37753  201912302355557 2020-01-01  2019-12-30 20:50:07   \n",
       "162585      115645  201912302353567 2020-01-01  2019-12-30 11:02:39   \n",
       "164041      117101  201912302354611 2020-01-01  2019-12-30 15:19:58   \n",
       "164040      117100  201912302352965 2020-01-01  2019-12-30 10:08:58   \n",
       "\n",
       "       PKG_GOODS_NO PKG_GOODS_NM    GOODS_NO      GOODS_NM  \\\n",
       "166288           단품           단품       14375    옛날잡채(500g)   \n",
       "37753            단품           단품  1901012353  수제계란말이(350g)   \n",
       "162585           단품           단품        1823    숙주나물(300g)   \n",
       "164041           단품           단품  1712010310    두메산나물비빔밥재료   \n",
       "164040           단품           단품  1712010310    두메산나물비빔밥재료   \n",
       "\n",
       "       STD_GSGR_NO_LEV1_NM  ORD_QTY  ...  RET_QTY  REAL_ORD_QTY  \\\n",
       "166288                메인요리        1  ...        0             1   \n",
       "37753                   반찬        2  ...        0             2   \n",
       "162585                  반찬        1  ...        0             1   \n",
       "164041                메인요리        1  ...        0             1   \n",
       "164040                메인요리        1  ...        0             1   \n",
       "\n",
       "                           RECVR_ROAD_BASE_ADDR SALE_PRICE  DISCOUNT_AMT  \\\n",
       "166288  경기도 수원시 장안구 경수대로976번길 22 (조원동, 수원 한일타운)       8600        1408.0   \n",
       "37753                   서울 성북구 동소문로34길 24 삼성아파트       6300           0.0   \n",
       "162585       서울특별시 마포구 삼개로 33 (도화동, 도화3지구우성아파트)       3300         486.0   \n",
       "164041             경기도 용인시 수지구 문인로3번길 22 (풍덕천동)       6900         264.0   \n",
       "164040    경기도 구리시 아차산로487번길 27 (교문동, 아차산어울림아파트)       6900         317.0   \n",
       "\n",
       "        FINAL_PRICE  SALE_PERCETANGE  year  month  day  \n",
       "166288         7192        16.372093  2020      1    1  \n",
       "37753          6300         0.000000  2020      1    1  \n",
       "162585         2814        14.727273  2020      1    1  \n",
       "164041         6636         3.826087  2020      1    1  \n",
       "164040         6583         4.594203  2020      1    1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 컬럼 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ORD_NO', 'H_YMD', 'O_YMD', 'PKG_GOODS_NO',\n",
       "       'PKG_GOODS_NM', 'GOODS_NO', 'GOODS_NM', 'STD_GSGR_NO_LEV1_NM',\n",
       "       'ORD_QTY', 'CANCEL_QTY', 'RET_QTY', 'REAL_ORD_QTY',\n",
       "       'RECVR_ROAD_BASE_ADDR', 'SALE_PRICE', 'DISCOUNT_AMT', 'FINAL_PRICE',\n",
       "       'COMMNET_CNT', 'SALE_PERCETANGE', 'year', 'month', 'day', 'hour',\n",
       "       'minute', 'second'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터의 컬럼 확인\n",
    "copy_data.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>PKG_GOODS_NM</th>\n",
       "      <th>GOODS_NM</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM</th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "      <th>SALE_PERCETANGE</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166288</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>단품</td>\n",
       "      <td>옛날잡채(500g)</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8600</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>7192</td>\n",
       "      <td>16.372093</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37753</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>단품</td>\n",
       "      <td>수제계란말이(350g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162585</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>단품</td>\n",
       "      <td>숙주나물(300g)</td>\n",
       "      <td>반찬</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2814</td>\n",
       "      <td>14.727273</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164041</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>단품</td>\n",
       "      <td>두메산나물비빔밥재료</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6900</td>\n",
       "      <td>264.0</td>\n",
       "      <td>6636</td>\n",
       "      <td>3.826087</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164040</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>단품</td>\n",
       "      <td>두메산나물비빔밥재료</td>\n",
       "      <td>메인요리</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6900</td>\n",
       "      <td>317.0</td>\n",
       "      <td>6583</td>\n",
       "      <td>4.594203</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            H_YMD PKG_GOODS_NM      GOODS_NM STD_GSGR_NO_LEV1_NM  ORD_QTY  \\\n",
       "166288 2020-01-01           단품    옛날잡채(500g)                메인요리        1   \n",
       "37753  2020-01-01           단품  수제계란말이(350g)                  반찬        2   \n",
       "162585 2020-01-01           단품    숙주나물(300g)                  반찬        1   \n",
       "164041 2020-01-01           단품    두메산나물비빔밥재료                메인요리        1   \n",
       "164040 2020-01-01           단품    두메산나물비빔밥재료                메인요리        1   \n",
       "\n",
       "        CANCEL_QTY  RET_QTY  REAL_ORD_QTY  SALE_PRICE  DISCOUNT_AMT  \\\n",
       "166288           0        0             1        8600        1408.0   \n",
       "37753            0        0             2        6300           0.0   \n",
       "162585           0        0             1        3300         486.0   \n",
       "164041           0        0             1        6900         264.0   \n",
       "164040           0        0             1        6900         317.0   \n",
       "\n",
       "        FINAL_PRICE  SALE_PERCETANGE  year  month  day  \n",
       "166288         7192        16.372093  2020      1    1  \n",
       "37753          6300         0.000000  2020      1    1  \n",
       "162585         2814        14.727273  2020      1    1  \n",
       "164041         6636         3.826087  2020      1    1  \n",
       "164040         6583         4.594203  2020      1    1  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불필요한 컬럼들 제거\n",
    "# Unnamed: 단순 데이터 순서를 나타내는 컬럼이기에 삭제\n",
    "# O_YMD: 주문 시간은 오더 건수와 큰 상관이 없기에 삭제\n",
    "# ORD_NO: 주문 내용의 일련번호이기에 삭제\n",
    "# PKG_GOODS_NO: PKG_GOODS_NM과 내용이 겹치고 잘못 적재된 데이터이기에 삭제\n",
    "# RECVR_ROAD_BASE_ADDR: 비대면으로 주문하는 시대에 지역정보는 큰 의미가 없을 것 같아 삭제\n",
    "\n",
    "dummy_col = ['Unnamed: 0', 'GOODS_NO', 'O_YMD', 'ORD_NO', 'PKG_GOODS_NO', 'RECVR_ROAD_BASE_ADDR']\n",
    "copy_data = copy_data.drop(dummy_col, axis=1)\n",
    "\n",
    "copy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 이상치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='FINAL_PRICE'>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(3,3,1)\n",
    "sns.boxplot(x='ORD_QTY',  orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "sns.boxplot(x='CANCEL_QTY', orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "sns.boxplot(x='RET_QTY', orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "sns.boxplot(x='REAL_ORD_QTY', orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "sns.boxplot(x='SALE_PRICE', orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "sns.boxplot(x='DISCOUNT_AMT', orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,7)\n",
    "sns.boxplot(x='FINAL_PRICE', orient = \"v\", data=copy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier(df,col):\n",
    "    q1 = df[col].quantile(0.25) # 1사분위\n",
    "    q3 = df[col].quantile(0.75) # 3사분위 \n",
    "    iqr = q3 - q1               # iqr 수치\n",
    "\n",
    "    df.loc[(df[col] > (q3 + 1.5 * iqr)) | (df[col] < (q1 - 1.5 * iqr)), col] = df[col].median() # 이상치를 중앙값으로 대체\n",
    "\n",
    "ol_col = ['ORD_QTY', 'CANCEL_QTY', 'RET_QTY', 'REAL_ORD_QTY', 'SALE_PRICE', 'FINAL_PRICE']\n",
    "\n",
    "for i in ol_col:\n",
    "    #print(i)\n",
    "    outlier(copy_data, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1326: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='FINAL_PRICE'>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(3,3,1)\n",
    "sns.boxplot(x='ORD_QTY',  orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "sns.boxplot(x='CANCEL_QTY', orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "sns.boxplot(x='RET_QTY', orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "sns.boxplot(x='REAL_ORD_QTY', orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "sns.boxplot(x='SALE_PRICE', orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "sns.boxplot(x='DISCOUNT_AMT', orient = \"v\", data=copy_data)\n",
    "\n",
    "plt.subplot(3,3,7)\n",
    "sns.boxplot(x='FINAL_PRICE', orient = \"v\", data=copy_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 가변수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 724702 entries, 166288 to 237568\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   H_YMD                724702 non-null  datetime64[ns]\n",
      " 1   PKG_GOODS_NM         724702 non-null  object        \n",
      " 2   GOODS_NM             724702 non-null  object        \n",
      " 3   STD_GSGR_NO_LEV1_NM  724702 non-null  object        \n",
      " 4   ORD_QTY              724702 non-null  int64         \n",
      " 5   CANCEL_QTY           724702 non-null  int64         \n",
      " 6   RET_QTY              724702 non-null  int64         \n",
      " 7   REAL_ORD_QTY         724702 non-null  int64         \n",
      " 8   SALE_PRICE           724702 non-null  int64         \n",
      " 9   DISCOUNT_AMT         724702 non-null  float64       \n",
      " 10  FINAL_PRICE          724702 non-null  int64         \n",
      " 11  COMMNET_CNT          724702 non-null  int64         \n",
      " 12  SALE_PERCETANGE      724702 non-null  float64       \n",
      " 13  year                 724702 non-null  int64         \n",
      " 14  month                724702 non-null  int64         \n",
      " 15  day                  724702 non-null  int64         \n",
      " 16  hour                 724702 non-null  int64         \n",
      " 17  minute               724702 non-null  int64         \n",
      " 18  second               724702 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(13), object(3)\n",
      "memory usage: 110.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# 가변수화가 필요한 데이터들을 확인한다.\n",
    "\n",
    "copy_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['PKG_GOODS_NM', 'GOODS_NM', 'STD_GSGR_NO_LEV1_NM']\n",
    "\n",
    "copy_data= pd.get_dummies(copy_data, columns = cols, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H_YMD</th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "      <th>SALE_PERCETANGE</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_국</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_메인요리</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_반찬</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166288</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8600</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>7192</td>\n",
       "      <td>16.372093</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37753</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162585</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2814</td>\n",
       "      <td>14.727273</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164041</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6900</td>\n",
       "      <td>264.0</td>\n",
       "      <td>6636</td>\n",
       "      <td>3.826087</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164040</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6900</td>\n",
       "      <td>317.0</td>\n",
       "      <td>6583</td>\n",
       "      <td>4.594203</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            H_YMD  ORD_QTY  CANCEL_QTY  RET_QTY  REAL_ORD_QTY  SALE_PRICE  \\\n",
       "166288 2020-01-01        1           0        0             1        8600   \n",
       "37753  2020-01-01        1           0        0             1        6300   \n",
       "162585 2020-01-01        1           0        0             1        3300   \n",
       "164041 2020-01-01        1           0        0             1        6900   \n",
       "164040 2020-01-01        1           0        0             1        6900   \n",
       "\n",
       "        DISCOUNT_AMT  FINAL_PRICE  SALE_PERCETANGE  year  ...  \\\n",
       "166288        1408.0         7192        16.372093  2020  ...   \n",
       "37753            0.0         6300         0.000000  2020  ...   \n",
       "162585         486.0         2814        14.727273  2020  ...   \n",
       "164041         264.0         6636         3.826087  2020  ...   \n",
       "164040         317.0         6583         4.594203  2020  ...   \n",
       "\n",
       "        GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  GOODS_NM_열무비빔밥재료믹스(2인분)  \\\n",
       "166288                       0             0                        0   \n",
       "37753                        0             0                        0   \n",
       "162585                       0             0                        0   \n",
       "164041                       0             0                        0   \n",
       "164040                       0             0                        0   \n",
       "\n",
       "        GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  GOODS_NM_채소계란찜(340g)  \\\n",
       "166288                    1                       0                     0   \n",
       "37753                     0                       0                     0   \n",
       "162585                    0                       0                     0   \n",
       "164041                    0                       0                     0   \n",
       "164040                    0                       0                     0   \n",
       "\n",
       "        GOODS_NM_한돈 제육볶음(700g)  STD_GSGR_NO_LEV1_NM_국  \\\n",
       "166288                       0                      0   \n",
       "37753                        0                      0   \n",
       "162585                       0                      0   \n",
       "164041                       0                      0   \n",
       "164040                       0                      0   \n",
       "\n",
       "        STD_GSGR_NO_LEV1_NM_메인요리  STD_GSGR_NO_LEV1_NM_반찬  \n",
       "166288                         1                       0  \n",
       "37753                          0                       1  \n",
       "162585                         0                       1  \n",
       "164041                         1                       0  \n",
       "164040                         1                       0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 데이터를 타겟에 맞게 변형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 주 단위로 groupby 하고 해당 주에 팔린 상품의 개수를 sum()한다.\n",
    "\n",
    "resampled = copy_data.resample(rule='1D', on='H_YMD')\n",
    "resampled.sum()\n",
    "\n",
    "copy_data = resampled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ORD_QTY', 'CANCEL_QTY', 'RET_QTY', 'REAL_ORD_QTY', 'SALE_PRICE',\n",
       "       'DISCOUNT_AMT', 'FINAL_PRICE', 'SALE_PERCETANGE', 'year', 'month',\n",
       "       'day', 'PKG_GOODS_NM_단품', 'PKG_GOODS_NM_세트',\n",
       "       'GOODS_NM_[심방골주부X더반찬] 시골 돼지짜글이(600g)', 'GOODS_NM_가정집 오징어불고기/셀프(380g)',\n",
       "       'GOODS_NM_건표고버섯볶음', 'GOODS_NM_고구마 품은 라자냐(450g)',\n",
       "       'GOODS_NM_고사리나물볶음(150g)', 'GOODS_NM_고소한도토리묵무침(360g)',\n",
       "       'GOODS_NM_꼬막무침 (260g)', 'GOODS_NM_두메산나물비빔밥재료', 'GOODS_NM_메밀소바(2인분)',\n",
       "       'GOODS_NM_셀프두부조림(600g)', 'GOODS_NM_소고기유니짜장소스(1인분, 200g)',\n",
       "       'GOODS_NM_수제계란말이(350g)', 'GOODS_NM_숙주나물(300g)',\n",
       "       'GOODS_NM_순살코다리강정(180g)', 'GOODS_NM_양장피', 'GOODS_NM_열무비빔밥재료믹스(2인분)',\n",
       "       'GOODS_NM_옛날잡채(500g)', 'GOODS_NM_우삼겹숙주볶음(250g)', 'GOODS_NM_채소계란찜(340g)',\n",
       "       'GOODS_NM_한돈 제육볶음(700g)', 'STD_GSGR_NO_LEV1_NM_국',\n",
       "       'STD_GSGR_NO_LEV1_NM_메인요리', 'STD_GSGR_NO_LEV1_NM_반찬'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\raw.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "      <th>SALE_PERCETANGE</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_국</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_메인요리</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_반찬</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_YMD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "      <td>2268700</td>\n",
       "      <td>90476.0</td>\n",
       "      <td>2178224</td>\n",
       "      <td>1284.546126</td>\n",
       "      <td>656500</td>\n",
       "      <td>325</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "      <td>3461000</td>\n",
       "      <td>137145.0</td>\n",
       "      <td>3323855</td>\n",
       "      <td>2015.121625</td>\n",
       "      <td>1024140</td>\n",
       "      <td>507</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>653</td>\n",
       "      <td>4586400</td>\n",
       "      <td>91408.0</td>\n",
       "      <td>4494992</td>\n",
       "      <td>1336.728764</td>\n",
       "      <td>1319060</td>\n",
       "      <td>653</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>722</td>\n",
       "      <td>4960200</td>\n",
       "      <td>126515.0</td>\n",
       "      <td>4833685</td>\n",
       "      <td>1822.520913</td>\n",
       "      <td>1458440</td>\n",
       "      <td>722</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27</th>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>860</td>\n",
       "      <td>6390800</td>\n",
       "      <td>309422.0</td>\n",
       "      <td>6081378</td>\n",
       "      <td>3907.776253</td>\n",
       "      <td>1738920</td>\n",
       "      <td>4300</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-28</th>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>770</td>\n",
       "      <td>5850500</td>\n",
       "      <td>340604.0</td>\n",
       "      <td>5509896</td>\n",
       "      <td>4508.781336</td>\n",
       "      <td>1556940</td>\n",
       "      <td>3850</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-30</th>\n",
       "      <td>740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>740</td>\n",
       "      <td>5172900</td>\n",
       "      <td>161235.0</td>\n",
       "      <td>5022531</td>\n",
       "      <td>2605.660809</td>\n",
       "      <td>1496280</td>\n",
       "      <td>3700</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>1099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1099</td>\n",
       "      <td>7903870</td>\n",
       "      <td>353046.0</td>\n",
       "      <td>7550824</td>\n",
       "      <td>4951.298520</td>\n",
       "      <td>2222178</td>\n",
       "      <td>5495</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>675.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>882 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ORD_QTY  CANCEL_QTY  RET_QTY  REAL_ORD_QTY  SALE_PRICE  \\\n",
       "H_YMD                                                                \n",
       "2020-01-01      325           0        0           325     2268700   \n",
       "2020-01-02      507           0        0           507     3461000   \n",
       "2020-01-03      653           0        0           653     4586400   \n",
       "2020-01-04      722           0        0           722     4960200   \n",
       "2020-01-05        0           0        0             0           0   \n",
       "...             ...         ...      ...           ...         ...   \n",
       "2022-05-27      860           0        0           860     6390800   \n",
       "2022-05-28      770           0        0           770     5850500   \n",
       "2022-05-29        0           0        0             0           0   \n",
       "2022-05-30      740           0        0           740     5172900   \n",
       "2022-05-31     1099           0        0          1099     7903870   \n",
       "\n",
       "            DISCOUNT_AMT  FINAL_PRICE  SALE_PERCETANGE     year  month  ...  \\\n",
       "H_YMD                                                                   ...   \n",
       "2020-01-01       90476.0      2178224      1284.546126   656500    325  ...   \n",
       "2020-01-02      137145.0      3323855      2015.121625  1024140    507  ...   \n",
       "2020-01-03       91408.0      4494992      1336.728764  1319060    653  ...   \n",
       "2020-01-04      126515.0      4833685      1822.520913  1458440    722  ...   \n",
       "2020-01-05           0.0            0         0.000000        0      0  ...   \n",
       "...                  ...          ...              ...      ...    ...  ...   \n",
       "2022-05-27      309422.0      6081378      3907.776253  1738920   4300  ...   \n",
       "2022-05-28      340604.0      5509896      4508.781336  1556940   3850  ...   \n",
       "2022-05-29           0.0            0         0.000000        0      0  ...   \n",
       "2022-05-30      161235.0      5022531      2605.660809  1496280   3700  ...   \n",
       "2022-05-31      353046.0      7550824      4951.298520  2222178   5495  ...   \n",
       "\n",
       "            GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  GOODS_NM_열무비빔밥재료믹스(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2020-01-01                     6.0          16.0                      0.0   \n",
       "2020-01-02                    14.0          20.0                      0.0   \n",
       "2020-01-03                    17.0          27.0                      0.0   \n",
       "2020-01-04                    25.0          24.0                      0.0   \n",
       "2020-01-05                     0.0           0.0                      0.0   \n",
       "...                            ...           ...                      ...   \n",
       "2022-05-27                    22.0          44.0                     51.0   \n",
       "2022-05-28                    28.0          47.0                     34.0   \n",
       "2022-05-29                     0.0           0.0                      0.0   \n",
       "2022-05-30                    14.0          25.0                     31.0   \n",
       "2022-05-31                    26.0          29.0                     50.0   \n",
       "\n",
       "            GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  GOODS_NM_채소계란찜(340g)  \\\n",
       "H_YMD                                                                           \n",
       "2020-01-01                 84.0                     0.0                  22.0   \n",
       "2020-01-02                106.0                     0.0                  29.0   \n",
       "2020-01-03                169.0                     0.0                  35.0   \n",
       "2020-01-04                143.0                     0.0                  41.0   \n",
       "2020-01-05                  0.0                     0.0                   0.0   \n",
       "...                         ...                     ...                   ...   \n",
       "2022-05-27                 95.0                    19.0                  44.0   \n",
       "2022-05-28                 86.0                    24.0                  21.0   \n",
       "2022-05-29                  0.0                     0.0                   0.0   \n",
       "2022-05-30                 72.0                    35.0                  58.0   \n",
       "2022-05-31                105.0                    22.0                  78.0   \n",
       "\n",
       "            GOODS_NM_한돈 제육볶음(700g)  STD_GSGR_NO_LEV1_NM_국  \\\n",
       "H_YMD                                                       \n",
       "2020-01-01                     0.0                    0.0   \n",
       "2020-01-02                     0.0                    0.0   \n",
       "2020-01-03                     0.0                    0.0   \n",
       "2020-01-04                     0.0                    0.0   \n",
       "2020-01-05                     0.0                    0.0   \n",
       "...                            ...                    ...   \n",
       "2022-05-27                    42.0                   16.0   \n",
       "2022-05-28                    48.0                   11.0   \n",
       "2022-05-29                     0.0                    0.0   \n",
       "2022-05-30                    30.0                   12.0   \n",
       "2022-05-31                    53.0                   39.0   \n",
       "\n",
       "            STD_GSGR_NO_LEV1_NM_메인요리  STD_GSGR_NO_LEV1_NM_반찬  \n",
       "H_YMD                                                         \n",
       "2020-01-01                     188.0                   137.0  \n",
       "2020-01-02                     281.0                   226.0  \n",
       "2020-01-03                     346.0                   307.0  \n",
       "2020-01-04                     335.0                   387.0  \n",
       "2020-01-05                       0.0                     0.0  \n",
       "...                              ...                     ...  \n",
       "2022-05-27                     321.0                   523.0  \n",
       "2022-05-28                     325.0                   434.0  \n",
       "2022-05-29                       0.0                     0.0  \n",
       "2022-05-30                     230.0                   498.0  \n",
       "2022-05-31                     385.0                   675.0  \n",
       "\n",
       "[882 rows x 36 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'H_YMD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'H_YMD'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Dongwon\\Dongwon_Project\\더반찬_예측과제_rf_rd_ls_성능비교.ipynb 셀 49\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000049?line=0'>1</a>\u001b[0m H_YMD \u001b[39m=\u001b[39m copy_data[\u001b[39m'\u001b[39;49m\u001b[39mH_YMD\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'H_YMD'"
     ]
    }
   ],
   "source": [
    "H_YMD = copy_data['H_YMD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data.drop('H_YMD', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "      <th>SALE_PERCETANGE</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_국</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_메인요리</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_반찬</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166288</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8600</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>7192</td>\n",
       "      <td>16.372093</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37753</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162585</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2814</td>\n",
       "      <td>14.727273</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164041</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6900</td>\n",
       "      <td>264.0</td>\n",
       "      <td>6636</td>\n",
       "      <td>3.826087</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164040</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6900</td>\n",
       "      <td>317.0</td>\n",
       "      <td>6583</td>\n",
       "      <td>4.594203</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ORD_QTY  CANCEL_QTY  RET_QTY  REAL_ORD_QTY  SALE_PRICE  DISCOUNT_AMT  \\\n",
       "166288        1           0        0             1        8600        1408.0   \n",
       "37753         1           0        0             1        6300           0.0   \n",
       "162585        1           0        0             1        3300         486.0   \n",
       "164041        1           0        0             1        6900         264.0   \n",
       "164040        1           0        0             1        6900         317.0   \n",
       "\n",
       "        FINAL_PRICE  SALE_PERCETANGE  year  month  ...  \\\n",
       "166288         7192        16.372093  2020      1  ...   \n",
       "37753          6300         0.000000  2020      1  ...   \n",
       "162585         2814        14.727273  2020      1  ...   \n",
       "164041         6636         3.826087  2020      1  ...   \n",
       "164040         6583         4.594203  2020      1  ...   \n",
       "\n",
       "        GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  GOODS_NM_열무비빔밥재료믹스(2인분)  \\\n",
       "166288                       0             0                        0   \n",
       "37753                        0             0                        0   \n",
       "162585                       0             0                        0   \n",
       "164041                       0             0                        0   \n",
       "164040                       0             0                        0   \n",
       "\n",
       "        GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  GOODS_NM_채소계란찜(340g)  \\\n",
       "166288                    1                       0                     0   \n",
       "37753                     0                       0                     0   \n",
       "162585                    0                       0                     0   \n",
       "164041                    0                       0                     0   \n",
       "164040                    0                       0                     0   \n",
       "\n",
       "        GOODS_NM_한돈 제육볶음(700g)  STD_GSGR_NO_LEV1_NM_국  \\\n",
       "166288                       0                      0   \n",
       "37753                        0                      0   \n",
       "162585                       0                      0   \n",
       "164041                       0                      0   \n",
       "164040                       0                      0   \n",
       "\n",
       "        STD_GSGR_NO_LEV1_NM_메인요리  STD_GSGR_NO_LEV1_NM_반찬  \n",
       "166288                         1                       0  \n",
       "37753                          0                       1  \n",
       "162585                         0                       1  \n",
       "164041                         1                       0  \n",
       "164040                         1                       0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 컬럼명 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 컬럼에 '['나 ','같은 특수기호가 들어가 있으면 학습이 안되기 때문에 제거해준다.\n",
    "import re\n",
    "\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "copy_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in copy_data.columns.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 train/val, test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "      <th>SALE_PERCETANGE</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_국</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_메인요리</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_반찬</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_YMD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-02</th>\n",
       "      <td>1138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1138</td>\n",
       "      <td>8018400</td>\n",
       "      <td>820060.0</td>\n",
       "      <td>7198340</td>\n",
       "      <td>11229.558757</td>\n",
       "      <td>2301036</td>\n",
       "      <td>5690</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-03</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "      <td>6330800</td>\n",
       "      <td>452701.0</td>\n",
       "      <td>5878099</td>\n",
       "      <td>5859.831790</td>\n",
       "      <td>1787448</td>\n",
       "      <td>4420</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-04</th>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1088</td>\n",
       "      <td>7733300</td>\n",
       "      <td>489668.0</td>\n",
       "      <td>7243632</td>\n",
       "      <td>6890.301874</td>\n",
       "      <td>2199936</td>\n",
       "      <td>5440</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-05</th>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "      <td>3754750</td>\n",
       "      <td>339780.0</td>\n",
       "      <td>3414970</td>\n",
       "      <td>4843.365530</td>\n",
       "      <td>1069638</td>\n",
       "      <td>2645</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ORD_QTY  CANCEL_QTY  RET_QTY  REAL_ORD_QTY  SALE_PRICE  \\\n",
       "H_YMD                                                                \n",
       "2022-05-01        0           0        0             0           0   \n",
       "2022-05-02     1138           0        0          1138     8018400   \n",
       "2022-05-03      884           0        0           884     6330800   \n",
       "2022-05-04     1088           0        0          1088     7733300   \n",
       "2022-05-05      529           0        0           529     3754750   \n",
       "\n",
       "            DISCOUNT_AMT  FINAL_PRICE  SALE_PERCETANGE     year  month  ...  \\\n",
       "H_YMD                                                                   ...   \n",
       "2022-05-01           0.0            0         0.000000        0      0  ...   \n",
       "2022-05-02      820060.0      7198340     11229.558757  2301036   5690  ...   \n",
       "2022-05-03      452701.0      5878099      5859.831790  1787448   4420  ...   \n",
       "2022-05-04      489668.0      7243632      6890.301874  2199936   5440  ...   \n",
       "2022-05-05      339780.0      3414970      4843.365530  1069638   2645  ...   \n",
       "\n",
       "            GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  GOODS_NM_열무비빔밥재료믹스(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01                     0.0           0.0                      0.0   \n",
       "2022-05-02                    52.0          70.0                      0.0   \n",
       "2022-05-03                    22.0          45.0                      0.0   \n",
       "2022-05-04                    26.0          64.0                      0.0   \n",
       "2022-05-05                    18.0          20.0                      0.0   \n",
       "\n",
       "            GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  GOODS_NM_채소계란찜(340g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01                  0.0                     0.0                   0.0   \n",
       "2022-05-02                126.0                    15.0                  93.0   \n",
       "2022-05-03                100.0                    22.0                  76.0   \n",
       "2022-05-04                150.0                    24.0                  75.0   \n",
       "2022-05-05                 69.0                    11.0                  28.0   \n",
       "\n",
       "            GOODS_NM_한돈 제육볶음(700g)  STD_GSGR_NO_LEV1_NM_국  \\\n",
       "H_YMD                                                       \n",
       "2022-05-01                     0.0                    0.0   \n",
       "2022-05-02                    50.0                   33.0   \n",
       "2022-05-03                    52.0                   36.0   \n",
       "2022-05-04                    51.0                   34.0   \n",
       "2022-05-05                    15.0                   15.0   \n",
       "\n",
       "            STD_GSGR_NO_LEV1_NM_메인요리  STD_GSGR_NO_LEV1_NM_반찬  \n",
       "H_YMD                                                         \n",
       "2022-05-01                       0.0                     0.0  \n",
       "2022-05-02                     338.0                   767.0  \n",
       "2022-05-03                     280.0                   568.0  \n",
       "2022-05-04                     375.0                   679.0  \n",
       "2022-05-05                     160.0                   354.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만들어진 데이터 기준 121행부터 2022년 5월의 데이터이므로 2022년 5월 이후 데이터를 test 데이터로 사용한다\n",
    "# 104: 2022 전체 데이터\n",
    "# 121: 2022.05 데이터\n",
    "\n",
    "# train_data = copy_data[:104]\n",
    "# test_data = copy_data[104:]\n",
    "\n",
    "# train_data = copy_data[:121]\n",
    "# test_data = copy_data[121:]\n",
    "\n",
    "train_data = copy_data[:-31]\n",
    "test_data = copy_data[-31:]\n",
    "\n",
    "# train_data = copy_data[:-26567]\n",
    "# test_data = copy_data[-26567:]\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Target 데이터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# 타겟이 되는 20개 제품을 설정한다\n",
    "\n",
    "target = ['GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)',\n",
    "       'GOODS_NM_가정집 오징어불고기/셀프(380g)', 'GOODS_NM_고사리나물볶음(150g)',\n",
    "       'GOODS_NM_건표고버섯볶음', 'GOODS_NM_고구마 품은 라자냐(450g)',\n",
    "       'GOODS_NM_고소한도토리묵무침(360g)', 'GOODS_NM_꼬막무침 (260g)',\n",
    "       'GOODS_NM_두메산나물비빔밥재료', 'GOODS_NM_메밀소바(2인분)', 'GOODS_NM_셀프두부조림(600g)',\n",
    "       'GOODS_NM_소고기유니짜장소스(1인분, 200g)', 'GOODS_NM_수제계란말이(350g)',\n",
    "       'GOODS_NM_숙주나물(300g)', 'GOODS_NM_순살코다리강정(180g)', 'GOODS_NM_양장피',\n",
    "       'GOODS_NM_열무비빔밥재료믹스(2인분)', 'GOODS_NM_옛날잡채(500g)',\n",
    "       'GOODS_NM_우삼겹숙주볶음(250g)', 'GOODS_NM_채소계란찜(340g)',\n",
    "       'GOODS_NM_한돈 제육볶음(700g)']\n",
    "\n",
    "print(len(target)) # // 20\n",
    "\n",
    "# 학습&검증 데이터와 테스트 데이터를 나눈다.\n",
    "# X, y -> 학습 및 검증데이터\n",
    "# X_test, y_test -> 테스트데이터 \n",
    "X, X_test = train_data.drop(target, axis=1), test_data.drop(target, axis=1)\n",
    "y, y_test = train_data[target], test_data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)</th>\n",
       "      <th>GOODS_NM_가정집 오징어불고기/셀프(380g)</th>\n",
       "      <th>GOODS_NM_고사리나물볶음(150g)</th>\n",
       "      <th>GOODS_NM_건표고버섯볶음</th>\n",
       "      <th>GOODS_NM_고구마 품은 라자냐(450g)</th>\n",
       "      <th>GOODS_NM_고소한도토리묵무침(360g)</th>\n",
       "      <th>GOODS_NM_꼬막무침 (260g)</th>\n",
       "      <th>GOODS_NM_두메산나물비빔밥재료</th>\n",
       "      <th>GOODS_NM_메밀소바(2인분)</th>\n",
       "      <th>GOODS_NM_셀프두부조림(600g)</th>\n",
       "      <th>GOODS_NM_소고기유니짜장소스(1인분, 200g)</th>\n",
       "      <th>GOODS_NM_수제계란말이(350g)</th>\n",
       "      <th>GOODS_NM_숙주나물(300g)</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242449</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19075</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19726</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)  GOODS_NM_가정집 오징어불고기/셀프(380g)  \\\n",
       "242449                                    0                             0   \n",
       "246203                                    0                             0   \n",
       "246201                                    0                             0   \n",
       "19075                                     0                             0   \n",
       "19726                                     0                             0   \n",
       "\n",
       "        GOODS_NM_고사리나물볶음(150g)  GOODS_NM_건표고버섯볶음  GOODS_NM_고구마 품은 라자냐(450g)  \\\n",
       "242449                       0                 0                          0   \n",
       "246203                       0                 0                          0   \n",
       "246201                       0                 0                          0   \n",
       "19075                        0                 0                          0   \n",
       "19726                        0                 0                          0   \n",
       "\n",
       "        GOODS_NM_고소한도토리묵무침(360g)  GOODS_NM_꼬막무침 (260g)  GOODS_NM_두메산나물비빔밥재료  \\\n",
       "242449                         0                     0                    0   \n",
       "246203                         0                     0                    1   \n",
       "246201                         0                     0                    1   \n",
       "19075                          0                     0                    0   \n",
       "19726                          0                     0                    0   \n",
       "\n",
       "        GOODS_NM_메밀소바(2인분)  GOODS_NM_셀프두부조림(600g)  \\\n",
       "242449                   0                      0   \n",
       "246203                   0                      0   \n",
       "246201                   0                      0   \n",
       "19075                    0                      0   \n",
       "19726                    0                      0   \n",
       "\n",
       "        GOODS_NM_소고기유니짜장소스(1인분, 200g)  GOODS_NM_수제계란말이(350g)  \\\n",
       "242449                              0                      0   \n",
       "246203                              0                      0   \n",
       "246201                              0                      0   \n",
       "19075                               0                      1   \n",
       "19726                               0                      1   \n",
       "\n",
       "        GOODS_NM_숙주나물(300g)  GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  \\\n",
       "242449                    0                       1             0   \n",
       "246203                    0                       0             0   \n",
       "246201                    0                       0             0   \n",
       "19075                     0                       0             0   \n",
       "19726                     0                       0             0   \n",
       "\n",
       "        GOODS_NM_열무비빔밥재료믹스(2인분)  GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  \\\n",
       "242449                        0                    0                       0   \n",
       "246203                        0                    0                       0   \n",
       "246201                        0                    0                       0   \n",
       "19075                         0                    0                       0   \n",
       "19726                         0                    0                       0   \n",
       "\n",
       "        GOODS_NM_채소계란찜(340g)  GOODS_NM_한돈 제육볶음(700g)  \n",
       "242449                     0                       0  \n",
       "246203                     0                       0  \n",
       "246201                     0                       0  \n",
       "19075                      0                       0  \n",
       "19726                      0                       0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Target / Validation data 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split 메서드를 사용하여 학습 검증 데이터를 7:3비율로 나눈다\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = .2, shuffle=False, random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(680, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습데이터 모양 확인\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범위가 제각각인 각 컬럼들을 0~1 사이에 범위로 조정해준다.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "col_x = list(X)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s = scaler.transform(X_val)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 모델 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 모델 선언 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 20)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "      <th>SALE_PERCETANGE</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>PKG_GOODS_NM_단품</th>\n",
       "      <th>PKG_GOODS_NM_세트</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_국</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_메인요리</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_반찬</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_YMD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "      <td>2268700</td>\n",
       "      <td>90476.0</td>\n",
       "      <td>2178224</td>\n",
       "      <td>1284.546126</td>\n",
       "      <td>656500</td>\n",
       "      <td>325</td>\n",
       "      <td>325</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "      <td>3461000</td>\n",
       "      <td>137145.0</td>\n",
       "      <td>3323855</td>\n",
       "      <td>2015.121625</td>\n",
       "      <td>1024140</td>\n",
       "      <td>507</td>\n",
       "      <td>1014</td>\n",
       "      <td>507.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>653</td>\n",
       "      <td>4586400</td>\n",
       "      <td>91408.0</td>\n",
       "      <td>4494992</td>\n",
       "      <td>1336.728764</td>\n",
       "      <td>1319060</td>\n",
       "      <td>653</td>\n",
       "      <td>1959</td>\n",
       "      <td>653.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>722</td>\n",
       "      <td>4960200</td>\n",
       "      <td>126515.0</td>\n",
       "      <td>4833685</td>\n",
       "      <td>1822.520913</td>\n",
       "      <td>1458440</td>\n",
       "      <td>722</td>\n",
       "      <td>2888</td>\n",
       "      <td>718.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>1246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1246</td>\n",
       "      <td>9531160</td>\n",
       "      <td>657224.0</td>\n",
       "      <td>8873936</td>\n",
       "      <td>7436.660359</td>\n",
       "      <td>2518166</td>\n",
       "      <td>9968</td>\n",
       "      <td>16198</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-14</th>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>698</td>\n",
       "      <td>5292700</td>\n",
       "      <td>424389.0</td>\n",
       "      <td>4868311</td>\n",
       "      <td>4709.816065</td>\n",
       "      <td>1410658</td>\n",
       "      <td>5584</td>\n",
       "      <td>9772</td>\n",
       "      <td>642.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-16</th>\n",
       "      <td>603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>603</td>\n",
       "      <td>4411236</td>\n",
       "      <td>387597.0</td>\n",
       "      <td>4023439</td>\n",
       "      <td>4582.043271</td>\n",
       "      <td>1218663</td>\n",
       "      <td>4824</td>\n",
       "      <td>9648</td>\n",
       "      <td>553.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17</th>\n",
       "      <td>1231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1231</td>\n",
       "      <td>9543113</td>\n",
       "      <td>578019.0</td>\n",
       "      <td>8979152</td>\n",
       "      <td>6650.060501</td>\n",
       "      <td>2487851</td>\n",
       "      <td>9848</td>\n",
       "      <td>20927</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>557.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ORD_QTY  CANCEL_QTY  RET_QTY  REAL_ORD_QTY  SALE_PRICE  \\\n",
       "H_YMD                                                                \n",
       "2020-01-01      325           0        0           325     2268700   \n",
       "2020-01-02      507           0        0           507     3461000   \n",
       "2020-01-03      653           0        0           653     4586400   \n",
       "2020-01-04      722           0        0           722     4960200   \n",
       "2020-01-05        0           0        0             0           0   \n",
       "...             ...         ...      ...           ...         ...   \n",
       "2021-08-13     1246           0        0          1246     9531160   \n",
       "2021-08-14      698           0        0           698     5292700   \n",
       "2021-08-15        0           0        0             0           0   \n",
       "2021-08-16      603           0        0           603     4411236   \n",
       "2021-08-17     1231           0        0          1231     9543113   \n",
       "\n",
       "            DISCOUNT_AMT  FINAL_PRICE  SALE_PERCETANGE     year  month    day  \\\n",
       "H_YMD                                                                           \n",
       "2020-01-01       90476.0      2178224      1284.546126   656500    325    325   \n",
       "2020-01-02      137145.0      3323855      2015.121625  1024140    507   1014   \n",
       "2020-01-03       91408.0      4494992      1336.728764  1319060    653   1959   \n",
       "2020-01-04      126515.0      4833685      1822.520913  1458440    722   2888   \n",
       "2020-01-05           0.0            0         0.000000        0      0      0   \n",
       "...                  ...          ...              ...      ...    ...    ...   \n",
       "2021-08-13      657224.0      8873936      7436.660359  2518166   9968  16198   \n",
       "2021-08-14      424389.0      4868311      4709.816065  1410658   5584   9772   \n",
       "2021-08-15           0.0            0         0.000000        0      0      0   \n",
       "2021-08-16      387597.0      4023439      4582.043271  1218663   4824   9648   \n",
       "2021-08-17      578019.0      8979152      6650.060501  2487851   9848  20927   \n",
       "\n",
       "            PKG_GOODS_NM_단품  PKG_GOODS_NM_세트  STD_GSGR_NO_LEV1_NM_국  \\\n",
       "H_YMD                                                                 \n",
       "2020-01-01            325.0              0.0                    0.0   \n",
       "2020-01-02            507.0              0.0                    0.0   \n",
       "2020-01-03            653.0              0.0                    0.0   \n",
       "2020-01-04            718.0              4.0                    0.0   \n",
       "2020-01-05              0.0              0.0                    0.0   \n",
       "...                     ...              ...                    ...   \n",
       "2021-08-13           1176.0             70.0                    0.0   \n",
       "2021-08-14            642.0             56.0                    0.0   \n",
       "2021-08-15              0.0              0.0                    0.0   \n",
       "2021-08-16            553.0             50.0                    0.0   \n",
       "2021-08-17           1161.0             70.0                    0.0   \n",
       "\n",
       "            STD_GSGR_NO_LEV1_NM_메인요리  STD_GSGR_NO_LEV1_NM_반찬  \n",
       "H_YMD                                                         \n",
       "2020-01-01                     188.0                   137.0  \n",
       "2020-01-02                     281.0                   226.0  \n",
       "2020-01-03                     346.0                   307.0  \n",
       "2020-01-04                     335.0                   387.0  \n",
       "2020-01-05                       0.0                     0.0  \n",
       "...                              ...                     ...  \n",
       "2021-08-13                     683.0                   563.0  \n",
       "2021-08-14                     371.0                   327.0  \n",
       "2021-08-15                       0.0                     0.0  \n",
       "2021-08-16                     282.0                   321.0  \n",
       "2021-08-17                     674.0                   557.0  \n",
       "\n",
       "[595 rows x 16 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    booster='gblinear',\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.1, \n",
    "    gamma=1, \n",
    "    subsample=0.75,\n",
    "    colsample_bytree=1, \n",
    "    max_depth=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:35.38760\tvalidation_1-rmse:33.01936\n",
      "[1]\tvalidation_0-rmse:30.51943\tvalidation_1-rmse:28.44034\n",
      "[2]\tvalidation_0-rmse:29.80996\tvalidation_1-rmse:28.21143\n",
      "[3]\tvalidation_0-rmse:29.47131\tvalidation_1-rmse:28.17634\n",
      "[4]\tvalidation_0-rmse:29.20055\tvalidation_1-rmse:28.12839\n",
      "[5]\tvalidation_0-rmse:28.97158\tvalidation_1-rmse:28.02142\n",
      "[6]\tvalidation_0-rmse:28.77500\tvalidation_1-rmse:27.95902\n",
      "[7]\tvalidation_0-rmse:28.60437\tvalidation_1-rmse:27.87662\n",
      "[8]\tvalidation_0-rmse:28.45739\tvalidation_1-rmse:27.80100\n",
      "[9]\tvalidation_0-rmse:28.32551\tvalidation_1-rmse:27.77366\n",
      "[10]\tvalidation_0-rmse:28.21158\tvalidation_1-rmse:27.68385\n",
      "[11]\tvalidation_0-rmse:28.10822\tvalidation_1-rmse:27.65833\n",
      "[12]\tvalidation_0-rmse:28.01668\tvalidation_1-rmse:27.57259\n",
      "[13]\tvalidation_0-rmse:27.93187\tvalidation_1-rmse:27.54751\n",
      "[14]\tvalidation_0-rmse:27.85483\tvalidation_1-rmse:27.47258\n",
      "[15]\tvalidation_0-rmse:27.78405\tvalidation_1-rmse:27.41106\n",
      "[16]\tvalidation_0-rmse:27.71687\tvalidation_1-rmse:27.39168\n",
      "[17]\tvalidation_0-rmse:27.65452\tvalidation_1-rmse:27.34469\n",
      "[18]\tvalidation_0-rmse:27.59575\tvalidation_1-rmse:27.30235\n",
      "[19]\tvalidation_0-rmse:27.53968\tvalidation_1-rmse:27.27097\n",
      "[20]\tvalidation_0-rmse:27.48703\tvalidation_1-rmse:27.19924\n",
      "[21]\tvalidation_0-rmse:27.43601\tvalidation_1-rmse:27.15431\n",
      "[22]\tvalidation_0-rmse:27.38660\tvalidation_1-rmse:27.12868\n",
      "[23]\tvalidation_0-rmse:27.33937\tvalidation_1-rmse:27.08577\n",
      "[24]\tvalidation_0-rmse:27.29364\tvalidation_1-rmse:27.07314\n",
      "[25]\tvalidation_0-rmse:27.24956\tvalidation_1-rmse:27.01806\n",
      "[26]\tvalidation_0-rmse:27.20657\tvalidation_1-rmse:26.98700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]\tvalidation_0-rmse:27.16448\tvalidation_1-rmse:26.96354\n",
      "[28]\tvalidation_0-rmse:27.12348\tvalidation_1-rmse:26.94961\n",
      "[29]\tvalidation_0-rmse:27.08409\tvalidation_1-rmse:26.89860\n",
      "[30]\tvalidation_0-rmse:27.04514\tvalidation_1-rmse:26.89292\n",
      "[31]\tvalidation_0-rmse:27.00753\tvalidation_1-rmse:26.84699\n",
      "[32]\tvalidation_0-rmse:26.97003\tvalidation_1-rmse:26.83871\n",
      "[33]\tvalidation_0-rmse:26.93368\tvalidation_1-rmse:26.80700\n",
      "[34]\tvalidation_0-rmse:26.89783\tvalidation_1-rmse:26.79378\n",
      "[35]\tvalidation_0-rmse:26.86274\tvalidation_1-rmse:26.77844\n",
      "[36]\tvalidation_0-rmse:26.82841\tvalidation_1-rmse:26.75961\n",
      "[37]\tvalidation_0-rmse:26.79466\tvalidation_1-rmse:26.73892\n",
      "[38]\tvalidation_0-rmse:26.76167\tvalidation_1-rmse:26.71969\n",
      "[39]\tvalidation_0-rmse:26.72919\tvalidation_1-rmse:26.70303\n",
      "[40]\tvalidation_0-rmse:26.69735\tvalidation_1-rmse:26.68539\n",
      "[41]\tvalidation_0-rmse:26.66610\tvalidation_1-rmse:26.67138\n",
      "[42]\tvalidation_0-rmse:26.63530\tvalidation_1-rmse:26.65429\n",
      "[43]\tvalidation_0-rmse:26.60520\tvalidation_1-rmse:26.63172\n",
      "[44]\tvalidation_0-rmse:26.57571\tvalidation_1-rmse:26.60967\n",
      "[45]\tvalidation_0-rmse:26.54681\tvalidation_1-rmse:26.59204\n",
      "[46]\tvalidation_0-rmse:26.51831\tvalidation_1-rmse:26.58112\n",
      "[47]\tvalidation_0-rmse:26.49001\tvalidation_1-rmse:26.58380\n",
      "[48]\tvalidation_0-rmse:26.46246\tvalidation_1-rmse:26.58041\n",
      "[49]\tvalidation_0-rmse:26.43564\tvalidation_1-rmse:26.56168\n",
      "[50]\tvalidation_0-rmse:26.40893\tvalidation_1-rmse:26.57018\n",
      "[51]\tvalidation_0-rmse:26.38262\tvalidation_1-rmse:26.56460\n",
      "[52]\tvalidation_0-rmse:26.35680\tvalidation_1-rmse:26.55875\n",
      "[53]\tvalidation_0-rmse:26.33166\tvalidation_1-rmse:26.53864\n",
      "[54]\tvalidation_0-rmse:26.30673\tvalidation_1-rmse:26.53820\n",
      "[55]\tvalidation_0-rmse:26.28218\tvalidation_1-rmse:26.53042\n",
      "[56]\tvalidation_0-rmse:26.25816\tvalidation_1-rmse:26.52011\n",
      "[57]\tvalidation_0-rmse:26.23421\tvalidation_1-rmse:26.53132\n",
      "[58]\tvalidation_0-rmse:26.21093\tvalidation_1-rmse:26.54102\n",
      "[59]\tvalidation_0-rmse:26.18791\tvalidation_1-rmse:26.52790\n",
      "[60]\tvalidation_0-rmse:26.16521\tvalidation_1-rmse:26.53728\n",
      "[61]\tvalidation_0-rmse:26.14294\tvalidation_1-rmse:26.53749\n",
      "[62]\tvalidation_0-rmse:26.12105\tvalidation_1-rmse:26.53125\n",
      "[63]\tvalidation_0-rmse:26.09933\tvalidation_1-rmse:26.53635\n",
      "[64]\tvalidation_0-rmse:26.07809\tvalidation_1-rmse:26.54635\n",
      "[65]\tvalidation_0-rmse:26.05699\tvalidation_1-rmse:26.54943\n",
      "[66]\tvalidation_0-rmse:26.03633\tvalidation_1-rmse:26.55029\n",
      "[67]\tvalidation_0-rmse:26.01594\tvalidation_1-rmse:26.55726\n",
      "[68]\tvalidation_0-rmse:25.99609\tvalidation_1-rmse:26.54808\n",
      "[69]\tvalidation_0-rmse:25.97627\tvalidation_1-rmse:26.55745\n",
      "[70]\tvalidation_0-rmse:25.95672\tvalidation_1-rmse:26.56439\n",
      "[71]\tvalidation_0-rmse:25.93761\tvalidation_1-rmse:26.56462\n",
      "[72]\tvalidation_0-rmse:25.91853\tvalidation_1-rmse:26.58059\n",
      "[73]\tvalidation_0-rmse:25.89994\tvalidation_1-rmse:26.57799\n",
      "[74]\tvalidation_0-rmse:25.88151\tvalidation_1-rmse:26.59169\n",
      "[75]\tvalidation_0-rmse:25.86348\tvalidation_1-rmse:26.59361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=1, gpu_id=-1, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.1, max_bin=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "             random_state=0, reg_alpha=0, reg_lambda=0, ...)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(\n",
    "    X_train_s,\n",
    "    y_train, \n",
    "    eval_metric=\"rmse\",\n",
    "    eval_set=[(X_train_s, y_train), (X_val_s, y_val)], \n",
    "    early_stopping_rounds=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.316845, 24.678417, 23.157665, ..., 19.821756, 37.732132,\n",
       "        32.74822 ],\n",
       "       [26.439959, 22.09774 , 21.61559 , ..., 21.853123, 37.698032,\n",
       "        46.055687],\n",
       "       [16.441462, 28.182745, 26.056227, ..., 22.003162, 40.51548 ,\n",
       "        32.164207],\n",
       "       ...,\n",
       "       [25.65746 , 38.888397, 33.33506 , ..., 28.349539, 55.70768 ,\n",
       "        51.83116 ],\n",
       "       [45.61211 , 39.475563, 34.821953, ..., 38.00387 , 63.2885  ,\n",
       "        80.36252 ],\n",
       "       [38.103012, 42.656174, 36.88105 , ..., 35.562283, 62.00186 ,\n",
       "        69.75758 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pred = xgb_model.predict(X_val_s)\n",
    "\n",
    "xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.23876896257376123\n",
      "RMSE:  23.081926965865065\n"
     ]
    }
   ],
   "source": [
    "# 모델의 성능을 점검하는 지표로 r2와 RMSE를 사용한다.\n",
    "# r2는 회귀모델에서 독립변수가 종속변수를 얼마만큼 설명해주는지 가리키는 지표이기에 사용했다.\n",
    "# 회귀 예측에 대한 정확도는 accuracy로 판단할 수 없기 때문에 rmse를 사용했다.\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "r2 = r2_score(y_val, xgb_pred)\n",
    "RMSE = mean_squared_error(y_val, xgb_pred, squared=False)\n",
    "\n",
    "print('r2: ', r2)\n",
    "print('RMSE: ', RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORD_QTY</th>\n",
       "      <th>CANCEL_QTY</th>\n",
       "      <th>RET_QTY</th>\n",
       "      <th>REAL_ORD_QTY</th>\n",
       "      <th>SALE_PRICE</th>\n",
       "      <th>DISCOUNT_AMT</th>\n",
       "      <th>FINAL_PRICE</th>\n",
       "      <th>SALE_PERCETANGE</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>PKG_GOODS_NM_단품</th>\n",
       "      <th>PKG_GOODS_NM_세트</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_국</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_메인요리</th>\n",
       "      <th>STD_GSGR_NO_LEV1_NM_반찬</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_YMD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-02</th>\n",
       "      <td>1138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1138</td>\n",
       "      <td>8018400</td>\n",
       "      <td>820060.0</td>\n",
       "      <td>7198340</td>\n",
       "      <td>11229.558757</td>\n",
       "      <td>2301036</td>\n",
       "      <td>5690</td>\n",
       "      <td>2276</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-03</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "      <td>6330800</td>\n",
       "      <td>452701.0</td>\n",
       "      <td>5878099</td>\n",
       "      <td>5859.831790</td>\n",
       "      <td>1787448</td>\n",
       "      <td>4420</td>\n",
       "      <td>2652</td>\n",
       "      <td>850.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-04</th>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1088</td>\n",
       "      <td>7733300</td>\n",
       "      <td>489668.0</td>\n",
       "      <td>7243632</td>\n",
       "      <td>6890.301874</td>\n",
       "      <td>2199936</td>\n",
       "      <td>5440</td>\n",
       "      <td>4352</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-05</th>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "      <td>3754750</td>\n",
       "      <td>339780.0</td>\n",
       "      <td>3414970</td>\n",
       "      <td>4843.365530</td>\n",
       "      <td>1069638</td>\n",
       "      <td>2645</td>\n",
       "      <td>2645</td>\n",
       "      <td>514.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ORD_QTY  CANCEL_QTY  RET_QTY  REAL_ORD_QTY  SALE_PRICE  \\\n",
       "H_YMD                                                                \n",
       "2022-05-01        0           0        0             0           0   \n",
       "2022-05-02     1138           0        0          1138     8018400   \n",
       "2022-05-03      884           0        0           884     6330800   \n",
       "2022-05-04     1088           0        0          1088     7733300   \n",
       "2022-05-05      529           0        0           529     3754750   \n",
       "\n",
       "            DISCOUNT_AMT  FINAL_PRICE  SALE_PERCETANGE     year  month   day  \\\n",
       "H_YMD                                                                          \n",
       "2022-05-01           0.0            0         0.000000        0      0     0   \n",
       "2022-05-02      820060.0      7198340     11229.558757  2301036   5690  2276   \n",
       "2022-05-03      452701.0      5878099      5859.831790  1787448   4420  2652   \n",
       "2022-05-04      489668.0      7243632      6890.301874  2199936   5440  4352   \n",
       "2022-05-05      339780.0      3414970      4843.365530  1069638   2645  2645   \n",
       "\n",
       "            PKG_GOODS_NM_단품  PKG_GOODS_NM_세트  STD_GSGR_NO_LEV1_NM_국  \\\n",
       "H_YMD                                                                 \n",
       "2022-05-01              0.0              0.0                    0.0   \n",
       "2022-05-02           1070.0             68.0                   33.0   \n",
       "2022-05-03            850.0             34.0                   36.0   \n",
       "2022-05-04           1036.0             52.0                   34.0   \n",
       "2022-05-05            514.0             15.0                   15.0   \n",
       "\n",
       "            STD_GSGR_NO_LEV1_NM_메인요리  STD_GSGR_NO_LEV1_NM_반찬  \n",
       "H_YMD                                                         \n",
       "2022-05-01                       0.0                     0.0  \n",
       "2022-05-02                     338.0                   767.0  \n",
       "2022-05-03                     280.0                   568.0  \n",
       "2022-05-04                     375.0                   679.0  \n",
       "2022-05-05                     160.0                   354.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)</th>\n",
       "      <th>GOODS_NM_가정집 오징어불고기/셀프(380g)</th>\n",
       "      <th>GOODS_NM_고사리나물볶음(150g)</th>\n",
       "      <th>GOODS_NM_건표고버섯볶음</th>\n",
       "      <th>GOODS_NM_고구마 품은 라자냐(450g)</th>\n",
       "      <th>GOODS_NM_고소한도토리묵무침(360g)</th>\n",
       "      <th>GOODS_NM_꼬막무침 (260g)</th>\n",
       "      <th>GOODS_NM_두메산나물비빔밥재료</th>\n",
       "      <th>GOODS_NM_메밀소바(2인분)</th>\n",
       "      <th>GOODS_NM_셀프두부조림(600g)</th>\n",
       "      <th>GOODS_NM_소고기유니짜장소스(1인분, 200g)</th>\n",
       "      <th>GOODS_NM_수제계란말이(350g)</th>\n",
       "      <th>GOODS_NM_숙주나물(300g)</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_YMD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>-3.323747</td>\n",
       "      <td>4.902326</td>\n",
       "      <td>3.929882</td>\n",
       "      <td>1.598089</td>\n",
       "      <td>-6.187740</td>\n",
       "      <td>-3.841505</td>\n",
       "      <td>4.359101</td>\n",
       "      <td>12.192710</td>\n",
       "      <td>1.575499</td>\n",
       "      <td>7.775922</td>\n",
       "      <td>0.081905</td>\n",
       "      <td>4.011942</td>\n",
       "      <td>7.221901</td>\n",
       "      <td>-1.509480</td>\n",
       "      <td>-0.510482</td>\n",
       "      <td>-0.665521</td>\n",
       "      <td>7.307149</td>\n",
       "      <td>-3.891459</td>\n",
       "      <td>7.039653</td>\n",
       "      <td>-5.940625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-02</th>\n",
       "      <td>29.090149</td>\n",
       "      <td>39.570312</td>\n",
       "      <td>36.028679</td>\n",
       "      <td>43.886730</td>\n",
       "      <td>29.762568</td>\n",
       "      <td>38.169857</td>\n",
       "      <td>45.339245</td>\n",
       "      <td>257.052917</td>\n",
       "      <td>29.616510</td>\n",
       "      <td>86.233109</td>\n",
       "      <td>-0.035455</td>\n",
       "      <td>62.845581</td>\n",
       "      <td>65.270683</td>\n",
       "      <td>21.957586</td>\n",
       "      <td>36.047886</td>\n",
       "      <td>22.553192</td>\n",
       "      <td>108.310516</td>\n",
       "      <td>29.546734</td>\n",
       "      <td>66.679207</td>\n",
       "      <td>57.559574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-03</th>\n",
       "      <td>14.812090</td>\n",
       "      <td>34.757912</td>\n",
       "      <td>30.621239</td>\n",
       "      <td>34.555138</td>\n",
       "      <td>20.184031</td>\n",
       "      <td>27.343336</td>\n",
       "      <td>45.028343</td>\n",
       "      <td>200.216263</td>\n",
       "      <td>19.277702</td>\n",
       "      <td>68.441727</td>\n",
       "      <td>-0.011165</td>\n",
       "      <td>47.137886</td>\n",
       "      <td>53.644920</td>\n",
       "      <td>14.542019</td>\n",
       "      <td>27.781942</td>\n",
       "      <td>14.552979</td>\n",
       "      <td>109.450554</td>\n",
       "      <td>20.007505</td>\n",
       "      <td>51.697525</td>\n",
       "      <td>31.437349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-04</th>\n",
       "      <td>16.199709</td>\n",
       "      <td>41.857468</td>\n",
       "      <td>36.859493</td>\n",
       "      <td>41.328133</td>\n",
       "      <td>24.735624</td>\n",
       "      <td>34.339436</td>\n",
       "      <td>54.049549</td>\n",
       "      <td>246.847794</td>\n",
       "      <td>25.992548</td>\n",
       "      <td>80.058578</td>\n",
       "      <td>-0.031097</td>\n",
       "      <td>55.076309</td>\n",
       "      <td>63.350075</td>\n",
       "      <td>17.386120</td>\n",
       "      <td>33.843971</td>\n",
       "      <td>19.813726</td>\n",
       "      <td>143.427307</td>\n",
       "      <td>23.733780</td>\n",
       "      <td>59.995457</td>\n",
       "      <td>37.052238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-05</th>\n",
       "      <td>11.633127</td>\n",
       "      <td>21.892282</td>\n",
       "      <td>19.330257</td>\n",
       "      <td>21.880045</td>\n",
       "      <td>11.716072</td>\n",
       "      <td>15.573275</td>\n",
       "      <td>27.654034</td>\n",
       "      <td>123.339012</td>\n",
       "      <td>10.867863</td>\n",
       "      <td>45.676643</td>\n",
       "      <td>0.027204</td>\n",
       "      <td>31.641563</td>\n",
       "      <td>35.305054</td>\n",
       "      <td>9.364319</td>\n",
       "      <td>17.284084</td>\n",
       "      <td>7.287759</td>\n",
       "      <td>56.524788</td>\n",
       "      <td>12.770199</td>\n",
       "      <td>35.112343</td>\n",
       "      <td>21.851955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)  GOODS_NM_가정집 오징어불고기/셀프(380g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01                            -3.323747                      4.902326   \n",
       "2022-05-02                            29.090149                     39.570312   \n",
       "2022-05-03                            14.812090                     34.757912   \n",
       "2022-05-04                            16.199709                     41.857468   \n",
       "2022-05-05                            11.633127                     21.892282   \n",
       "\n",
       "            GOODS_NM_고사리나물볶음(150g)  GOODS_NM_건표고버섯볶음  \\\n",
       "H_YMD                                                  \n",
       "2022-05-01                3.929882          1.598089   \n",
       "2022-05-02               36.028679         43.886730   \n",
       "2022-05-03               30.621239         34.555138   \n",
       "2022-05-04               36.859493         41.328133   \n",
       "2022-05-05               19.330257         21.880045   \n",
       "\n",
       "            GOODS_NM_고구마 품은 라자냐(450g)  GOODS_NM_고소한도토리묵무침(360g)  \\\n",
       "H_YMD                                                             \n",
       "2022-05-01                  -6.187740                 -3.841505   \n",
       "2022-05-02                  29.762568                 38.169857   \n",
       "2022-05-03                  20.184031                 27.343336   \n",
       "2022-05-04                  24.735624                 34.339436   \n",
       "2022-05-05                  11.716072                 15.573275   \n",
       "\n",
       "            GOODS_NM_꼬막무침 (260g)  GOODS_NM_두메산나물비빔밥재료  GOODS_NM_메밀소바(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01              4.359101            12.192710            1.575499   \n",
       "2022-05-02             45.339245           257.052917           29.616510   \n",
       "2022-05-03             45.028343           200.216263           19.277702   \n",
       "2022-05-04             54.049549           246.847794           25.992548   \n",
       "2022-05-05             27.654034           123.339012           10.867863   \n",
       "\n",
       "            GOODS_NM_셀프두부조림(600g)  GOODS_NM_소고기유니짜장소스(1인분, 200g)  \\\n",
       "H_YMD                                                              \n",
       "2022-05-01               7.775922                       0.081905   \n",
       "2022-05-02              86.233109                      -0.035455   \n",
       "2022-05-03              68.441727                      -0.011165   \n",
       "2022-05-04              80.058578                      -0.031097   \n",
       "2022-05-05              45.676643                       0.027204   \n",
       "\n",
       "            GOODS_NM_수제계란말이(350g)  GOODS_NM_숙주나물(300g)  \\\n",
       "H_YMD                                                    \n",
       "2022-05-01               4.011942             7.221901   \n",
       "2022-05-02              62.845581            65.270683   \n",
       "2022-05-03              47.137886            53.644920   \n",
       "2022-05-04              55.076309            63.350075   \n",
       "2022-05-05              31.641563            35.305054   \n",
       "\n",
       "            GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  GOODS_NM_열무비빔밥재료믹스(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01               -1.509480     -0.510482                -0.665521   \n",
       "2022-05-02               21.957586     36.047886                22.553192   \n",
       "2022-05-03               14.542019     27.781942                14.552979   \n",
       "2022-05-04               17.386120     33.843971                19.813726   \n",
       "2022-05-05                9.364319     17.284084                 7.287759   \n",
       "\n",
       "            GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  GOODS_NM_채소계란찜(340g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01             7.307149               -3.891459              7.039653   \n",
       "2022-05-02           108.310516               29.546734             66.679207   \n",
       "2022-05-03           109.450554               20.007505             51.697525   \n",
       "2022-05-04           143.427307               23.733780             59.995457   \n",
       "2022-05-05            56.524788               12.770199             35.112343   \n",
       "\n",
       "            GOODS_NM_한돈 제육볶음(700g)  \n",
       "H_YMD                               \n",
       "2022-05-01               -5.940625  \n",
       "2022-05-02               57.559574  \n",
       "2022-05-03               31.437349  \n",
       "2022-05-04               37.052238  \n",
       "2022-05-05               21.851955  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터에 대해서 결과를 출력한다.\n",
    "\n",
    "xgb_test_pred = xgb_model.predict(X_test_s)\n",
    "df = y_test.copy()\n",
    "#xgb_test_pred = pd.DataFrame(xgb_test_pred)\n",
    "df[['GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)', 'GOODS_NM_가정집 오징어불고기/셀프(380g)',\n",
    "       'GOODS_NM_고사리나물볶음(150g)', 'GOODS_NM_건표고버섯볶음',\n",
    "       'GOODS_NM_고구마 품은 라자냐(450g)', 'GOODS_NM_고소한도토리묵무침(360g)',\n",
    "       'GOODS_NM_꼬막무침 (260g)', 'GOODS_NM_두메산나물비빔밥재료', 'GOODS_NM_메밀소바(2인분)',\n",
    "       'GOODS_NM_셀프두부조림(600g)', 'GOODS_NM_소고기유니짜장소스(1인분, 200g)',\n",
    "       'GOODS_NM_수제계란말이(350g)', 'GOODS_NM_숙주나물(300g)',\n",
    "       'GOODS_NM_순살코다리강정(180g)', 'GOODS_NM_양장피', 'GOODS_NM_열무비빔밥재료믹스(2인분)',\n",
    "       'GOODS_NM_옛날잡채(500g)', 'GOODS_NM_우삼겹숙주볶음(250g)', 'GOODS_NM_채소계란찜(340g)',\n",
    "       'GOODS_NM_한돈 제육볶음(700g)']] = xgb_test_pred\n",
    "\n",
    "xgb_test_pred = df.copy()\n",
    "xgb_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)</th>\n",
       "      <th>GOODS_NM_가정집 오징어불고기/셀프(380g)</th>\n",
       "      <th>GOODS_NM_고사리나물볶음(150g)</th>\n",
       "      <th>GOODS_NM_건표고버섯볶음</th>\n",
       "      <th>GOODS_NM_고구마 품은 라자냐(450g)</th>\n",
       "      <th>GOODS_NM_고소한도토리묵무침(360g)</th>\n",
       "      <th>GOODS_NM_꼬막무침 (260g)</th>\n",
       "      <th>GOODS_NM_두메산나물비빔밥재료</th>\n",
       "      <th>GOODS_NM_메밀소바(2인분)</th>\n",
       "      <th>GOODS_NM_셀프두부조림(600g)</th>\n",
       "      <th>GOODS_NM_소고기유니짜장소스(1인분, 200g)</th>\n",
       "      <th>GOODS_NM_수제계란말이(350g)</th>\n",
       "      <th>GOODS_NM_숙주나물(300g)</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_YMD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-02</th>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-03</th>\n",
       "      <td>36.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-04</th>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-05</th>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)  GOODS_NM_가정집 오징어불고기/셀프(380g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01                                  0.0                           0.0   \n",
       "2022-05-02                                 33.0                          34.0   \n",
       "2022-05-03                                 36.0                          31.0   \n",
       "2022-05-04                                 34.0                          31.0   \n",
       "2022-05-05                                 15.0                          20.0   \n",
       "\n",
       "            GOODS_NM_고사리나물볶음(150g)  GOODS_NM_건표고버섯볶음  \\\n",
       "H_YMD                                                  \n",
       "2022-05-01                     0.0               0.0   \n",
       "2022-05-02                    23.0              55.0   \n",
       "2022-05-03                    16.0              40.0   \n",
       "2022-05-04                    22.0              49.0   \n",
       "2022-05-05                    21.0              28.0   \n",
       "\n",
       "            GOODS_NM_고구마 품은 라자냐(450g)  GOODS_NM_고소한도토리묵무침(360g)  \\\n",
       "H_YMD                                                             \n",
       "2022-05-01                        0.0                       0.0   \n",
       "2022-05-02                       10.0                      48.0   \n",
       "2022-05-03                       11.0                      41.0   \n",
       "2022-05-04                       14.0                      65.0   \n",
       "2022-05-05                        9.0                      27.0   \n",
       "\n",
       "            GOODS_NM_꼬막무침 (260g)  GOODS_NM_두메산나물비빔밥재료  GOODS_NM_메밀소바(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01                   0.0                  0.0                 0.0   \n",
       "2022-05-02                  48.0                208.0                 0.0   \n",
       "2022-05-03                  35.0                154.0                 0.0   \n",
       "2022-05-04                  46.0                183.0                 0.0   \n",
       "2022-05-05                  18.0                123.0                 0.0   \n",
       "\n",
       "            GOODS_NM_셀프두부조림(600g)  GOODS_NM_소고기유니짜장소스(1인분, 200g)  \\\n",
       "H_YMD                                                              \n",
       "2022-05-01                    0.0                            0.0   \n",
       "2022-05-02                   88.0                           75.0   \n",
       "2022-05-03                   71.0                           40.0   \n",
       "2022-05-04                   69.0                           76.0   \n",
       "2022-05-05                   39.0                           21.0   \n",
       "\n",
       "            GOODS_NM_수제계란말이(350g)  GOODS_NM_숙주나물(300g)  \\\n",
       "H_YMD                                                    \n",
       "2022-05-01                    0.0                  0.0   \n",
       "2022-05-02                   47.0                 63.0   \n",
       "2022-05-03                   31.0                 61.0   \n",
       "2022-05-04                   39.0                 70.0   \n",
       "2022-05-05                   22.0                 25.0   \n",
       "\n",
       "            GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  GOODS_NM_열무비빔밥재료믹스(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01                     0.0           0.0                      0.0   \n",
       "2022-05-02                    52.0          70.0                      0.0   \n",
       "2022-05-03                    22.0          45.0                      0.0   \n",
       "2022-05-04                    26.0          64.0                      0.0   \n",
       "2022-05-05                    18.0          20.0                      0.0   \n",
       "\n",
       "            GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  GOODS_NM_채소계란찜(340g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01                  0.0                     0.0                   0.0   \n",
       "2022-05-02                126.0                    15.0                  93.0   \n",
       "2022-05-03                100.0                    22.0                  76.0   \n",
       "2022-05-04                150.0                    24.0                  75.0   \n",
       "2022-05-05                 69.0                    11.0                  28.0   \n",
       "\n",
       "            GOODS_NM_한돈 제육볶음(700g)  \n",
       "H_YMD                               \n",
       "2022-05-01                     0.0  \n",
       "2022-05-02                    50.0  \n",
       "2022-05-03                    52.0  \n",
       "2022-05-04                    51.0  \n",
       "2022-05-05                    15.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.1653333615390844\n",
      "RMSE:  22.72569617812494\n"
     ]
    }
   ],
   "source": [
    "# 모델의 성능을 점검하는 지표로 r2와 RMSE를 사용한다.\n",
    "# r2는 회귀모델에서 독립변수가 종속변수를 얼마만큼 설명해주는지 가리키는 지표이기에 사용했다.\n",
    "# 회귀 예측에 대한 정확도는 accuracy로 판단할 수 없기 때문에 rmse를 사용했다.\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "r2 = r2_score(y_test, xgb_test_pred)\n",
    "RMSE = mean_squared_error(y_test, xgb_test_pred, squared=False)\n",
    "\n",
    "print('r2: ', r2)\n",
    "print('RMSE: ', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 한글깨짐 방지\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel =['돼지짜글이',\n",
    "       '오징어불고기', '건고사리나물볶음',\n",
    "       '건표고버섯볶음', '고구마 라자냐',\n",
    "       '고소한도토리묵무침', '꼬막무침',\n",
    "       '두메산나물비빔밥재료', '메밀소바', '셀프두부조림',\n",
    "       '소고기유니짜장소스', '수제계란말이',\n",
    "       '숙주나물', '순살코다리강정', '양장피',\n",
    "       '열무비빔밥재료', '옛날잡채',\n",
    "       '우삼겹숙주볶음', '채소계란찜',\n",
    "       '한돈 제육볶음'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3208\\3540726441.py:5: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  chart.set_xticklabels(xlabel, rotation=45, size=8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f50117b820>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "chart = fig.add_subplot(1,1,1)\n",
    "chart.plot(y_test.sum(), marker='o', color='blue', label='실제값')\n",
    "chart.plot(xgb_test_pred.sum(), marker='^', color='red', label='예측값')\n",
    "chart.set_xticklabels(xlabel, rotation=45, size=8)\n",
    "plt.xlabel('예측 대상', size=20)\n",
    "plt.ylabel('오더 건수', size=20)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.13287e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+05, tolerance: 9.557e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.669e+04, tolerance: 3.175e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+04, tolerance: 1.614e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.749e+04, tolerance: 3.250e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+05, tolerance: 4.793e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.733e+04, tolerance: 3.843e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e+05, tolerance: 8.563e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.528e+05, tolerance: 8.814e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.763e+05, tolerance: 1.125e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.799e+04, tolerance: 6.385e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.044e+04, tolerance: 4.297e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.668e+04, tolerance: 4.466e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Ridge ###\n",
      "RMSE : 217.77911 | MAE : 127.02903 | r2 : -65.27276 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.212e+04, tolerance: 1.610e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+05, tolerance: 4.396e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+05, tolerance: 5.777e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+06, tolerance: 7.018e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+05, tolerance: 4.029e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.530e+04, tolerance: 4.530e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e+04, tolerance: 1.563e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+05, tolerance: 9.557e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.663e+04, tolerance: 3.175e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+04, tolerance: 1.614e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.743e+04, tolerance: 3.250e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+05, tolerance: 4.793e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.731e+04, tolerance: 3.843e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Lasso ###\n",
      "RMSE : 43.96126 | MAE : 25.00483 | r2 : -0.51332 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.578e+05, tolerance: 8.563e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.525e+05, tolerance: 8.814e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.761e+05, tolerance: 1.125e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.791e+04, tolerance: 6.385e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.037e+04, tolerance: 4.297e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.664e+04, tolerance: 4.466e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.208e+04, tolerance: 1.610e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+05, tolerance: 4.396e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.803e+05, tolerance: 5.777e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+06, tolerance: 7.018e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+05, tolerance: 4.029e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.523e+04, tolerance: 4.530e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.957e+04, tolerance: 1.563e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ElasticNet ###\n",
      "RMSE : 43.9898 | MAE : 25.02831 | r2 : -0.51377 \n",
      "### DecisionTreeRegressor ###\n",
      "RMSE : 34.20045 | MAE : 18.64211 | r2 : -1.27537 \n",
      "### RandomForestRegressor ###\n",
      "RMSE : 26.86807 | MAE : 15.5147 | r2 : 0.05649 \n"
     ]
    }
   ],
   "source": [
    "def evaluate_regr(y, pred):\n",
    "    mse = mean_squared_error(y, pred)\n",
    "    rmse_val = np.sqrt(mse)\n",
    "    mae_val = mean_absolute_error(y, pred)\n",
    "    r2 = r2_score(y, pred)\n",
    "    print('RMSE : {} | MAE : {} | r2 : {} '.format(round(rmse_val,5),round(mae_val,5),round(r2,5)))\n",
    "\n",
    "# 여러 모델의 성능 확인 함수 \n",
    "def get_model_predict(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    print('###', model.__class__.__name__,'###')\n",
    "    evaluate_regr(y_test, pred)\n",
    "#--------------------------------------------------------------------\n",
    "#모델별로 평가 확인 \n",
    "\n",
    "ridge_reg = Ridge(alpha=0.5)      # best alpha = 0.5\n",
    "lasso_reg = Lasso(alpha=1)        # best alpha = 1\n",
    "en_reg = ElasticNet(alpha=1)\n",
    "tree_reg = DecisionTreeRegressor(random_state=13)\n",
    "forest_reg = RandomForestRegressor(n_estimators=100,random_state=13)\n",
    "\n",
    "for model in [ridge_reg, lasso_reg, en_reg, tree_reg, forest_reg]:\n",
    "# for model in [forest_reg]:\n",
    "    get_model_predict(model, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD_QTY</td>\n",
       "      <td>0.034318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CANCEL_QTY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RET_QTY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REAL_ORD_QTY</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SALE_PRICE</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DISCOUNT_AMT</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FINAL_PRICE</td>\n",
       "      <td>-0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SALE_PERCETANGE</td>\n",
       "      <td>-0.025117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>year</td>\n",
       "      <td>-0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>month</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>day</td>\n",
       "      <td>-0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PKG_GOODS_NM_단품</td>\n",
       "      <td>0.003917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PKG_GOODS_NM_세트</td>\n",
       "      <td>-0.293085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>STD_GSGR_NO_LEV1_NM_국</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>STD_GSGR_NO_LEV1_NM_메인요리</td>\n",
       "      <td>0.031841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>STD_GSGR_NO_LEV1_NM_반찬</td>\n",
       "      <td>-0.024787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0         1\n",
       "0                    ORD_QTY  0.034318\n",
       "1                 CANCEL_QTY       0.0\n",
       "2                    RET_QTY       0.0\n",
       "3               REAL_ORD_QTY  0.000107\n",
       "4                 SALE_PRICE  0.000059\n",
       "5               DISCOUNT_AMT  0.000317\n",
       "6                FINAL_PRICE -0.000046\n",
       "7            SALE_PERCETANGE -0.025117\n",
       "8                       year -0.000066\n",
       "9                      month  0.000493\n",
       "10                       day  -0.00002\n",
       "11           PKG_GOODS_NM_단품  0.003917\n",
       "12           PKG_GOODS_NM_세트 -0.293085\n",
       "13     STD_GSGR_NO_LEV1_NM_국       0.0\n",
       "14  STD_GSGR_NO_LEV1_NM_메인요리  0.031841\n",
       "15    STD_GSGR_NO_LEV1_NM_반찬 -0.024787"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([X_train.columns , en_reg.coef_[0]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 모델 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_:  {'alpha': 0}\n",
      "-92.25580836080238 {'alpha': 0}\n",
      "-534.6914733438919 {'alpha': 0.05}\n",
      "-611.8417937213484 {'alpha': 0.1}\n",
      "-915.3829718379775 {'alpha': 0.5}\n",
      "-1072.728476483984 {'alpha': 1}\n",
      "-1525.372177443583 {'alpha': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Ridge - alpha값이 클수록(penalty 증가) 계수의 크기가 줄어듬\n",
    "# 영향력이 큰 계수의 영향력을 줄임 / 변수를 축소, 다중공선성을 방지\n",
    "param_grid = [\n",
    "    {'alpha': [0, 0.05, 0.1, 0.5, 1, 5]},\n",
    "]\n",
    "\n",
    "ridge_grid_search = GridSearchCV(ridge_reg, param_grid, cv=5,\n",
    "                           scoring='r2',\n",
    "                           return_train_score=True)\n",
    "ridge_grid_search.fit(X_train_s, y_train)\n",
    "\n",
    "print('best_params_: ', ridge_grid_search.best_params_)\n",
    "\n",
    "cvres = ridge_grid_search.cv_results_\n",
    "for mean_test_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_test_score, params)\n",
    "    \n",
    "# best_params_:  {'alpha': 0.1}, 그러나 alpha 값에 따른 score 변동 거의 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+05, tolerance: 8.644e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.123e+04, tolerance: 1.943e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+04, tolerance: 1.112e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.399e+04, tolerance: 2.046e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.519e+04, tolerance: 3.943e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.305e+04, tolerance: 2.445e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.249e+04, tolerance: 5.997e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.583e+05, tolerance: 6.383e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.025e+05, tolerance: 1.019e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+04, tolerance: 3.974e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.035e+04, tolerance: 2.755e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.921e+04, tolerance: 3.055e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+04, tolerance: 1.218e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.010e+04, tolerance: 3.372e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+05, tolerance: 4.882e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.909e+05, tolerance: 4.751e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.909e+04, tolerance: 3.465e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.341e+04, tolerance: 2.705e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.131e+04, tolerance: 1.213e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+05, tolerance: 8.644e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.907e+04, tolerance: 2.411e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e+04, tolerance: 1.201e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.307e+04, tolerance: 2.406e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.016e+04, tolerance: 3.943e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.409e+04, tolerance: 2.998e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.328e+04, tolerance: 6.207e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e+05, tolerance: 7.228e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+05, tolerance: 5.979e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.727e+04, tolerance: 4.219e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.423e+04, tolerance: 2.972e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+04, tolerance: 3.104e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.316e+04, tolerance: 1.154e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.677e+04, tolerance: 3.296e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.506e+04, tolerance: 3.992e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.303e+05, tolerance: 5.119e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+04, tolerance: 3.465e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.746e+04, tolerance: 2.932e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.772e+04, tolerance: 1.213e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+05, tolerance: 8.644e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.430e+04, tolerance: 2.148e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+04, tolerance: 1.036e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.360e+04, tolerance: 1.723e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.912e+04, tolerance: 3.372e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.662e+04, tolerance: 2.568e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.483e+04, tolerance: 4.484e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.431e+05, tolerance: 6.681e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+05, tolerance: 9.925e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.428e+04, tolerance: 3.667e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.441e+04, tolerance: 2.568e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.940e+04, tolerance: 2.487e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+04, tolerance: 1.151e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.929e+04, tolerance: 2.952e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.998e+04, tolerance: 4.823e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.203e+05, tolerance: 3.484e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.082e+04, tolerance: 1.616e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.471e+04, tolerance: 2.710e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.659e+04, tolerance: 1.219e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.447e+04, tolerance: 3.067e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.368e+04, tolerance: 2.400e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+04, tolerance: 1.152e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.643e+04, tolerance: 2.206e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.513e+04, tolerance: 2.728e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.370e+04, tolerance: 2.686e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+04, tolerance: 5.709e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.793e+05, tolerance: 6.349e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.887e+05, tolerance: 1.019e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.433e+04, tolerance: 3.781e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.146e+04, tolerance: 2.691e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.084e+04, tolerance: 2.898e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.717e+04, tolerance: 8.022e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.661e+04, tolerance: 2.576e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+05, tolerance: 4.882e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.603e+05, tolerance: 3.732e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.863e+04, tolerance: 3.088e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.411e+04, tolerance: 2.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.228e+04, tolerance: 1.023e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.509e+04, tolerance: 6.538e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.324e+04, tolerance: 2.617e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+04, tolerance: 1.245e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.501e+04, tolerance: 2.522e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.079e+04, tolerance: 3.757e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.255e+04, tolerance: 2.671e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.600e+04, tolerance: 5.525e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.824e+05, tolerance: 5.519e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+05, tolerance: 6.370e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+04, tolerance: 4.193e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.842e+04, tolerance: 2.520e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e+04, tolerance: 2.944e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.176e+04, tolerance: 1.031e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.224e+04, tolerance: 3.501e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.646e+04, tolerance: 1.758e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.726e+05, tolerance: 5.237e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.466e+04, tolerance: 3.693e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.699e+04, tolerance: 2.970e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.337e+04, tolerance: 5.010e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.123e+04, tolerance: 1.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+04, tolerance: 1.112e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.400e+04, tolerance: 2.046e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.519e+04, tolerance: 3.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.305e+04, tolerance: 2.445e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.250e+04, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.583e+05, tolerance: 6.383e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.025e+05, tolerance: 1.019e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+04, tolerance: 3.974e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.036e+04, tolerance: 2.755e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+04, tolerance: 3.055e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+04, tolerance: 1.218e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.010e+04, tolerance: 3.372e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+05, tolerance: 4.882e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.910e+05, tolerance: 4.751e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.910e+04, tolerance: 3.465e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.342e+04, tolerance: 2.705e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.131e+04, tolerance: 1.213e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.908e+04, tolerance: 2.411e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e+04, tolerance: 1.201e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.307e+04, tolerance: 2.406e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.017e+04, tolerance: 3.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.409e+04, tolerance: 2.998e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.329e+04, tolerance: 6.207e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e+05, tolerance: 7.228e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+05, tolerance: 5.979e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.728e+04, tolerance: 4.219e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.424e+04, tolerance: 2.972e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+04, tolerance: 3.104e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.316e+04, tolerance: 1.154e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.678e+04, tolerance: 3.296e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.507e+04, tolerance: 3.992e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.304e+05, tolerance: 5.119e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.112e+04, tolerance: 3.465e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.747e+04, tolerance: 2.932e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.773e+04, tolerance: 1.213e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.430e+04, tolerance: 2.148e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+04, tolerance: 1.036e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.360e+04, tolerance: 1.723e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.913e+04, tolerance: 3.372e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.662e+04, tolerance: 2.568e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.484e+04, tolerance: 4.484e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.431e+05, tolerance: 6.681e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+05, tolerance: 9.925e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.428e+04, tolerance: 3.667e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.441e+04, tolerance: 2.568e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.941e+04, tolerance: 2.487e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+04, tolerance: 1.151e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.929e+04, tolerance: 2.952e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.999e+04, tolerance: 4.823e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.203e+05, tolerance: 3.484e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.082e+04, tolerance: 1.616e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.471e+04, tolerance: 2.710e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.659e+04, tolerance: 1.219e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.448e+04, tolerance: 3.067e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.368e+04, tolerance: 2.400e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+04, tolerance: 1.152e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.644e+04, tolerance: 2.206e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.514e+04, tolerance: 2.728e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.370e+04, tolerance: 2.686e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.457e+04, tolerance: 5.709e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.793e+05, tolerance: 6.349e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.887e+05, tolerance: 1.019e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e+04, tolerance: 3.781e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.146e+04, tolerance: 2.691e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.085e+04, tolerance: 2.898e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.717e+04, tolerance: 8.022e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.661e+04, tolerance: 2.576e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+05, tolerance: 4.882e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.603e+05, tolerance: 3.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.864e+04, tolerance: 3.088e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.412e+04, tolerance: 2.701e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.229e+04, tolerance: 1.023e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.509e+04, tolerance: 6.538e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.325e+04, tolerance: 2.617e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+04, tolerance: 1.245e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.502e+04, tolerance: 2.522e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.080e+04, tolerance: 3.757e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.255e+04, tolerance: 2.671e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.601e+04, tolerance: 5.525e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.824e+05, tolerance: 5.519e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+05, tolerance: 6.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+04, tolerance: 4.193e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.843e+04, tolerance: 2.520e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e+04, tolerance: 2.944e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+04, tolerance: 1.031e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.224e+04, tolerance: 3.501e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.647e+04, tolerance: 1.758e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.726e+05, tolerance: 5.237e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.467e+04, tolerance: 3.693e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.700e+04, tolerance: 2.970e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.338e+04, tolerance: 5.010e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.123e+04, tolerance: 1.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+04, tolerance: 1.112e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.400e+04, tolerance: 2.046e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e+04, tolerance: 3.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.305e+04, tolerance: 2.445e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.252e+04, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.583e+05, tolerance: 6.383e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.025e+05, tolerance: 1.019e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+04, tolerance: 3.974e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.037e+04, tolerance: 2.755e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+04, tolerance: 3.055e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+04, tolerance: 1.218e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.011e+04, tolerance: 3.372e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+05, tolerance: 4.882e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.910e+05, tolerance: 4.751e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.910e+04, tolerance: 3.465e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.342e+04, tolerance: 2.705e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.132e+04, tolerance: 1.213e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.908e+04, tolerance: 2.411e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e+04, tolerance: 1.201e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.308e+04, tolerance: 2.406e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.018e+04, tolerance: 3.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.409e+04, tolerance: 2.998e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.330e+04, tolerance: 6.207e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.335e+05, tolerance: 7.228e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+05, tolerance: 5.979e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.728e+04, tolerance: 4.219e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.424e+04, tolerance: 2.972e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+04, tolerance: 3.104e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.316e+04, tolerance: 1.154e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.678e+04, tolerance: 3.296e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.509e+04, tolerance: 3.992e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.304e+05, tolerance: 5.119e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.112e+04, tolerance: 3.465e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.748e+04, tolerance: 2.932e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.774e+04, tolerance: 1.213e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.430e+04, tolerance: 2.148e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+04, tolerance: 1.036e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.361e+04, tolerance: 1.723e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.913e+04, tolerance: 3.372e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.662e+04, tolerance: 2.568e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.484e+04, tolerance: 4.484e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.432e+05, tolerance: 6.681e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.226e+05, tolerance: 9.925e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e+04, tolerance: 3.667e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.442e+04, tolerance: 2.568e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.941e+04, tolerance: 2.487e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+04, tolerance: 1.151e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.930e+04, tolerance: 2.952e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.999e+04, tolerance: 4.823e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.204e+05, tolerance: 3.484e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.083e+04, tolerance: 1.616e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+04, tolerance: 2.710e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.660e+04, tolerance: 1.219e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.448e+04, tolerance: 3.067e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.369e+04, tolerance: 2.400e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+04, tolerance: 1.152e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.644e+04, tolerance: 2.206e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.514e+04, tolerance: 2.728e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.370e+04, tolerance: 2.686e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e+04, tolerance: 5.709e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.793e+05, tolerance: 6.349e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.887e+05, tolerance: 1.019e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e+04, tolerance: 3.781e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.147e+04, tolerance: 2.691e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.085e+04, tolerance: 2.898e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e+04, tolerance: 8.022e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.662e+04, tolerance: 2.576e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+05, tolerance: 4.882e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.603e+05, tolerance: 3.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.865e+04, tolerance: 3.088e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.413e+04, tolerance: 2.701e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.230e+04, tolerance: 1.023e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.509e+04, tolerance: 6.538e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.326e+04, tolerance: 2.617e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.527e+04, tolerance: 1.245e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.503e+04, tolerance: 2.522e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.081e+04, tolerance: 3.757e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.255e+04, tolerance: 2.671e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.602e+04, tolerance: 5.525e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.824e+05, tolerance: 5.519e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+05, tolerance: 6.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+04, tolerance: 4.193e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.843e+04, tolerance: 2.520e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+04, tolerance: 2.944e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+04, tolerance: 1.031e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.224e+04, tolerance: 3.501e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.649e+04, tolerance: 1.758e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.727e+05, tolerance: 5.237e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.468e+04, tolerance: 3.693e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.701e+04, tolerance: 2.970e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.339e+04, tolerance: 5.010e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.125e+04, tolerance: 1.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+04, tolerance: 1.112e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.402e+04, tolerance: 2.046e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.525e+04, tolerance: 3.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.307e+04, tolerance: 2.445e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.261e+04, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+05, tolerance: 6.383e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.027e+05, tolerance: 1.019e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+04, tolerance: 3.974e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.042e+04, tolerance: 2.755e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.925e+04, tolerance: 3.055e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+04, tolerance: 1.218e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.013e+04, tolerance: 3.372e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+05, tolerance: 4.882e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.913e+05, tolerance: 4.751e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.916e+04, tolerance: 3.465e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.346e+04, tolerance: 2.705e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.137e+04, tolerance: 1.213e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.566e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.913e+04, tolerance: 2.411e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.627e+04, tolerance: 1.201e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.313e+04, tolerance: 2.406e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.022e+04, tolerance: 3.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.411e+04, tolerance: 2.998e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.336e+04, tolerance: 6.207e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e+05, tolerance: 7.228e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+05, tolerance: 5.979e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e+04, tolerance: 4.219e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.430e+04, tolerance: 2.972e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.841e+04, tolerance: 3.104e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.318e+04, tolerance: 1.154e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.680e+04, tolerance: 3.296e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.519e+04, tolerance: 3.992e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.306e+05, tolerance: 5.119e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.118e+04, tolerance: 3.465e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.754e+04, tolerance: 2.932e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.779e+04, tolerance: 1.213e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.523e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.433e+04, tolerance: 2.148e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.527e+04, tolerance: 1.036e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.364e+04, tolerance: 1.723e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.916e+04, tolerance: 3.372e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.664e+04, tolerance: 2.568e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.489e+04, tolerance: 4.484e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.434e+05, tolerance: 6.681e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.226e+05, tolerance: 9.925e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.433e+04, tolerance: 3.667e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.445e+04, tolerance: 2.568e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.944e+04, tolerance: 2.487e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e+04, tolerance: 1.151e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.936e+04, tolerance: 2.952e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+05, tolerance: 4.823e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.205e+05, tolerance: 3.484e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.085e+04, tolerance: 1.616e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.476e+04, tolerance: 2.710e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.664e+04, tolerance: 1.219e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.452e+04, tolerance: 3.067e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+04, tolerance: 2.400e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+04, tolerance: 1.152e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.650e+04, tolerance: 2.206e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.519e+04, tolerance: 2.728e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.373e+04, tolerance: 2.686e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.464e+04, tolerance: 5.709e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.795e+05, tolerance: 6.349e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.889e+05, tolerance: 1.019e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.439e+04, tolerance: 3.781e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.151e+04, tolerance: 2.691e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e+04, tolerance: 2.898e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+04, tolerance: 8.022e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.664e+04, tolerance: 2.576e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+05, tolerance: 4.882e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.605e+05, tolerance: 3.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.871e+04, tolerance: 3.088e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.420e+04, tolerance: 2.701e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.235e+04, tolerance: 1.023e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.510e+04, tolerance: 6.538e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.331e+04, tolerance: 2.617e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+04, tolerance: 1.245e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.507e+04, tolerance: 2.522e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.088e+04, tolerance: 3.757e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.257e+04, tolerance: 2.671e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.608e+04, tolerance: 5.525e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.828e+05, tolerance: 5.519e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+05, tolerance: 6.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.475e+04, tolerance: 4.193e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.848e+04, tolerance: 2.520e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+04, tolerance: 2.944e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e+04, tolerance: 1.031e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.226e+04, tolerance: 3.501e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.660e+04, tolerance: 1.758e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.729e+05, tolerance: 5.237e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.476e+04, tolerance: 3.693e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.709e+04, tolerance: 2.970e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.344e+04, tolerance: 5.010e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.557e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.127e+04, tolerance: 1.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+04, tolerance: 1.112e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.404e+04, tolerance: 2.046e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.530e+04, tolerance: 3.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.309e+04, tolerance: 2.445e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.272e+04, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.587e+05, tolerance: 6.383e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.028e+05, tolerance: 1.019e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+04, tolerance: 3.974e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.049e+04, tolerance: 2.755e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.929e+04, tolerance: 3.055e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e+04, tolerance: 1.218e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.015e+04, tolerance: 3.372e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e+05, tolerance: 4.882e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.916e+05, tolerance: 4.751e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.923e+04, tolerance: 3.465e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.352e+04, tolerance: 2.705e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.142e+04, tolerance: 1.213e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.917e+04, tolerance: 2.411e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+04, tolerance: 1.201e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.318e+04, tolerance: 2.406e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.028e+04, tolerance: 3.943e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.414e+04, tolerance: 2.998e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.343e+04, tolerance: 6.207e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.340e+05, tolerance: 7.228e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+05, tolerance: 5.979e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+04, tolerance: 4.219e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.437e+04, tolerance: 2.972e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.844e+04, tolerance: 3.104e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e+04, tolerance: 1.154e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.683e+04, tolerance: 3.296e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.533e+04, tolerance: 3.992e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.309e+05, tolerance: 5.119e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.125e+04, tolerance: 3.465e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.761e+04, tolerance: 2.932e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.785e+04, tolerance: 1.213e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+05, tolerance: 8.644e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.436e+04, tolerance: 2.148e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+04, tolerance: 1.036e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.369e+04, tolerance: 1.723e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.920e+04, tolerance: 3.372e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.666e+04, tolerance: 2.568e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.494e+04, tolerance: 4.484e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+05, tolerance: 6.681e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+05, tolerance: 9.925e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.437e+04, tolerance: 3.667e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.450e+04, tolerance: 2.568e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.948e+04, tolerance: 2.487e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+04, tolerance: 1.151e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.943e+04, tolerance: 2.952e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+05, tolerance: 4.823e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+05, tolerance: 3.484e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e+04, tolerance: 1.616e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.481e+04, tolerance: 2.710e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.670e+04, tolerance: 1.219e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.457e+04, tolerance: 3.067e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.377e+04, tolerance: 2.400e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.540e+04, tolerance: 1.152e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.656e+04, tolerance: 2.206e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+04, tolerance: 2.728e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.375e+04, tolerance: 2.686e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.471e+04, tolerance: 5.709e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.798e+05, tolerance: 6.349e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.890e+05, tolerance: 1.019e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.444e+04, tolerance: 3.781e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.157e+04, tolerance: 2.691e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+04, tolerance: 2.898e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.720e+04, tolerance: 8.022e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.667e+04, tolerance: 2.576e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e+05, tolerance: 4.882e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.607e+05, tolerance: 3.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.878e+04, tolerance: 3.088e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.427e+04, tolerance: 2.701e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.241e+04, tolerance: 1.023e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.511e+04, tolerance: 6.538e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.337e+04, tolerance: 2.617e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.535e+04, tolerance: 1.245e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.512e+04, tolerance: 2.522e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.097e+04, tolerance: 3.757e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.259e+04, tolerance: 2.671e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.615e+04, tolerance: 5.525e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.832e+05, tolerance: 5.519e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+05, tolerance: 6.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+04, tolerance: 4.193e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.853e+04, tolerance: 2.520e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+04, tolerance: 2.944e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.186e+04, tolerance: 1.031e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.227e+04, tolerance: 3.501e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.674e+04, tolerance: 1.758e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.731e+05, tolerance: 5.237e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.485e+04, tolerance: 3.693e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.717e+04, tolerance: 2.970e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.352e+04, tolerance: 5.010e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e+05, tolerance: 9.041e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.025e+04, tolerance: 2.889e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.914e+04, tolerance: 1.438e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.865e+04, tolerance: 2.767e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+05, tolerance: 4.552e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.139e+04, tolerance: 3.430e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+05, tolerance: 7.088e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.020e+05, tolerance: 8.063e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.197e+05, tolerance: 1.088e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.257e+04, tolerance: 4.969e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.005e+04, tolerance: 3.393e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.567e+04, tolerance: 3.639e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_:  {'alpha': 1}\n",
      "-213.27813436928741 {'alpha': 0}\n",
      "-213.27118599002637 {'alpha': 0.05}\n",
      "-213.26424162507368 {'alpha': 0.1}\n",
      "-213.20898604594768 {'alpha': 0.5}\n",
      "-213.14032431096763 {'alpha': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.704e+04, tolerance: 1.381e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.970e+04, tolerance: 3.978e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+05, tolerance: 5.183e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.129e+05, tolerance: 5.596e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+05, tolerance: 3.911e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.628e+04, tolerance: 3.508e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.677e+04, tolerance: 1.343e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# 2. Lasso - alpha 조금만 키워도 계수가 완전히 0이 되는 변수 증가 \n",
    "# feaure selection, 중요한 변수만 택함\n",
    "param_grid = [\n",
    "    {'alpha': [0, 0.05, 0.1, 0.5, 1]},\n",
    "    ]\n",
    "\n",
    "lasso_grid_search = GridSearchCV(lasso_reg, param_grid, cv=5,\n",
    "                          scoring='r2',\n",
    "                          return_train_score=True)\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print ('best_params_: ', lasso_grid_search.best_params_)\n",
    "\n",
    "cvres = lasso_grid_search.cv_results_\n",
    "for mean_test_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_test_score, params)  \n",
    "# best_params_:  {'alpha': 0} : 이 데이터로는 Lasso는 하지 않는 것이 바람직.\n",
    "# alpha 값 감소에 따라 mean_test_score 급격히 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Dongwon\\Dongwon_Project\\더반찬_예측과제_rf_rd_ls_성능비교.ipynb 셀 84\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000086?line=1'>2</a>\u001b[0m param_grid \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000086?line=2'>3</a>\u001b[0m     {\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m30\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m70\u001b[39m, \u001b[39m100\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mmax_features\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m2\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m8\u001b[39m]},\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000086?line=3'>4</a>\u001b[0m     {\u001b[39m'\u001b[39m\u001b[39mbootstrap\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39mFalse\u001b[39;00m], \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m3\u001b[39m, \u001b[39m10\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mmax_features\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m] }\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000086?line=4'>5</a>\u001b[0m     ]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000086?line=6'>7</a>\u001b[0m forest_reg \u001b[39m=\u001b[39m RandomForestRegressor(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, max_features\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m2022\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000086?line=7'>8</a>\u001b[0m rf_grid_search \u001b[39m=\u001b[39m GridSearchCV(forest_reg, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000086?line=8'>9</a>\u001b[0m                           scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000086?line=9'>10</a>\u001b[0m                           return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000086?line=10'>11</a>\u001b[0m rf_grid_search\u001b[39m.\u001b[39mfit(X_train_s, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000086?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mbest_params_: \u001b[39m\u001b[39m'\u001b[39m, rf_grid_search\u001b[39m.\u001b[39mbest_params_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. Randomforest - 가장 복잡한 모델로, 예측 성능은 좋으나 모델이 복잡하고, 가역성이 좋지않음.\n",
    "param_grid = [\n",
    "    {'n_estimators': [30, 50, 70, 100], 'max_features':[2,4,6,8]},\n",
    "    {'bootstrap':[False], 'n_estimators': [3, 10], 'max_features':[2,3,4] }\n",
    "    ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, max_features=4, random_state=2022)\n",
    "rf_grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          return_train_score=True)\n",
    "rf_grid_search.fit(X_train_s, y_train)\n",
    "\n",
    "print ('best_params_: ', rf_grid_search.best_params_)\n",
    "# best_params_: {'max_features': 8, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 k-fold 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Ridge ###\n",
      "점수: [19.76590634 13.37897381 15.30266163 30.97679298 14.24790581]\n",
      "평균: 18.734448111599917\n",
      "표준편차: 6.504248445773412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.500e+01, tolerance: 5.098e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.960e+02, tolerance: 4.371e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.544e+02, tolerance: 5.439e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e+02, tolerance: 5.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.532e+02, tolerance: 6.667e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.631e+02, tolerance: 1.833e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.530e+02, tolerance: 6.046e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+03, tolerance: 1.069e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.835e+02, tolerance: 1.756e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.051e+02, tolerance: 2.370e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.537e+02, tolerance: 1.142e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.175e+02, tolerance: 9.437e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.507e+03, tolerance: 1.063e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.078e+03, tolerance: 1.975e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.452e+02, tolerance: 1.010e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e+03, tolerance: 1.434e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.752e+02, tolerance: 4.775e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+02, tolerance: 2.576e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+03, tolerance: 2.659e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.226e+02, tolerance: 1.153e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.573e+01, tolerance: 4.346e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.300e+02, tolerance: 4.034e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.930e+02, tolerance: 5.791e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.008e+02, tolerance: 6.397e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.856e+02, tolerance: 5.727e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.352e+02, tolerance: 2.007e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.832e+02, tolerance: 6.628e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+03, tolerance: 1.189e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+03, tolerance: 1.807e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.166e+02, tolerance: 2.531e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.032e+02, tolerance: 1.294e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.128e+02, tolerance: 9.317e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.537e+03, tolerance: 1.065e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.820e+03, tolerance: 1.664e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.027e+02, tolerance: 1.437e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+03, tolerance: 1.481e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.791e+02, tolerance: 6.234e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.515e+02, tolerance: 2.955e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.953e+02, tolerance: 2.655e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+03, tolerance: 2.039e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+01, tolerance: 5.338e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.540e+02, tolerance: 3.901e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.146e+02, tolerance: 4.914e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.159e+02, tolerance: 6.596e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.139e+02, tolerance: 8.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.688e+02, tolerance: 2.037e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.961e+02, tolerance: 7.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+03, tolerance: 1.142e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.195e+02, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.226e+02, tolerance: 2.506e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.339e+02, tolerance: 1.439e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.995e+02, tolerance: 8.213e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e+03, tolerance: 1.070e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+03, tolerance: 1.106e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.389e+02, tolerance: 1.400e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.955e+02, tolerance: 1.547e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.070e+02, tolerance: 6.142e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.694e+02, tolerance: 2.633e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+03, tolerance: 2.391e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+03, tolerance: 2.066e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.622e+01, tolerance: 5.474e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e+02, tolerance: 4.391e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.977e+02, tolerance: 4.740e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.191e+02, tolerance: 6.472e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.451e+02, tolerance: 8.528e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.742e+02, tolerance: 2.351e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.031e+02, tolerance: 7.177e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+03, tolerance: 1.170e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.177e+02, tolerance: 1.300e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.414e+02, tolerance: 2.510e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.411e+02, tolerance: 1.338e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.121e+02, tolerance: 9.317e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.700e+02, tolerance: 1.816e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+03, tolerance: 2.062e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.890e+02, tolerance: 1.190e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.782e+02, tolerance: 8.297e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.816e+02, tolerance: 5.708e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.181e+02, tolerance: 2.751e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.999e+02, tolerance: 2.612e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.418e+02, tolerance: 1.851e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+01, tolerance: 5.013e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.577e+02, tolerance: 4.420e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.211e+02, tolerance: 5.190e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.734e+02, tolerance: 7.003e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.846e+02, tolerance: 8.834e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.661e+02, tolerance: 2.260e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.489e+02, tolerance: 7.183e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+03, tolerance: 1.197e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.352e+02, tolerance: 1.096e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.999e+02, tolerance: 2.698e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.951e+02, tolerance: 1.431e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.540e+02, tolerance: 9.706e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.369e+03, tolerance: 1.066e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.552e+03, tolerance: 1.968e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.658e+02, tolerance: 1.448e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e+03, tolerance: 1.251e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.978e+02, tolerance: 6.349e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.026e+02, tolerance: 2.770e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+03, tolerance: 2.727e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+03, tolerance: 2.065e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Lasso ###\n",
      "점수: [22.61621454 12.90611449 14.51834441 30.35426099 13.30477365]\n",
      "평균: 18.739941618020985\n",
      "표준편차: 6.8016818363291796\n",
      "### DecisionTreeRegressor ###\n",
      "점수: [21.4292857  15.71649876 17.6295207  34.47946249 23.16588728]\n",
      "평균: 22.48413098486595\n",
      "표준편차: 6.554899770267142\n",
      "### RandomForestRegressor ###\n",
      "점수: [18.92762194 14.4283555  12.90710428 31.96319164 16.19417038]\n",
      "평균: 18.884088746905636\n",
      "표준편차: 6.83927467847018\n"
     ]
    }
   ],
   "source": [
    "def display_socres(model):\n",
    "    scores = cross_val_score(model, X_test, y_test,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=5)\n",
    "    model_rmse_scores = np.sqrt(-scores)\n",
    "    print('###', model.__class__.__name__, '###')\n",
    "    print(\"점수:\", model_rmse_scores)\n",
    "    print(\"평균:\", model_rmse_scores.mean())\n",
    "    print(\"표준편차:\", model_rmse_scores.std())\n",
    "\n",
    "\n",
    "for model in [ridge_reg, lasso_reg, tree_reg, forest_reg]:\n",
    "    display_socres(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.595e+00, tolerance: 1.172e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.612e+00, tolerance: 1.621e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.246e+00, tolerance: 1.765e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+01, tolerance: 6.536e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+01, tolerance: 1.220e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 7.009e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.168e+00, tolerance: 3.256e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.523e+00, tolerance: 5.205e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.842e+00, tolerance: 6.014e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.959e+00, tolerance: 3.798e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.435e+00, tolerance: 1.143e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.463e+00, tolerance: 1.434e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e+01, tolerance: 3.330e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.391e+00, tolerance: 7.687e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.427e+01, tolerance: 8.059e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.750e+00, tolerance: 3.028e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.717e+01, tolerance: 1.213e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.243e+01, tolerance: 4.285e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e+01, tolerance: 6.810e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e+00, tolerance: 5.033e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+01, tolerance: 7.156e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+01, tolerance: 5.012e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.837e+00, tolerance: 1.530e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.833e+00, tolerance: 1.516e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+00, tolerance: 1.329e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+01, tolerance: 1.758e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.840e+00, tolerance: 6.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+01, tolerance: 9.074e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.972e+00, tolerance: 3.135e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e+01, tolerance: 5.761e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+01, tolerance: 4.922e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.459e+00, tolerance: 7.490e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.251e+00, tolerance: 5.037e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.254e+00, tolerance: 1.560e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e+00, tolerance: 1.225e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.672e+00, tolerance: 3.404e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.924e+00, tolerance: 1.781e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.514e+00, tolerance: 6.885e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.726e+00, tolerance: 1.272e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.575e+00, tolerance: 3.356e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e+01, tolerance: 7.063e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+01, tolerance: 5.182e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.827e+00, tolerance: 1.564e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.629e-01, tolerance: 4.891e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.187e+00, tolerance: 4.652e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e+00, tolerance: 2.704e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.601e+00, tolerance: 4.299e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.787e+00, tolerance: 1.179e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.731e-01, tolerance: 6.939e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e+01, tolerance: 9.625e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.601e+01, tolerance: 9.036e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+00, tolerance: 2.049e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.345e+00, tolerance: 5.973e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.427e+01, tolerance: 5.011e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.069e+01, tolerance: 3.328e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.446e+00, tolerance: 8.003e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+01, tolerance: 7.749e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e+01, tolerance: 3.217e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+00, tolerance: 4.428e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.186e+00, tolerance: 5.759e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.841e+00, tolerance: 4.119e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Ridge ###\n",
      "점수: [29.6025605        nan        nan        nan        nan]\n",
      "평균: nan\n",
      "표준편차: nan\n",
      "### Lasso ###\n",
      "점수: [9.88199838        nan        nan        nan        nan]\n",
      "평균: nan\n",
      "표준편차: nan\n",
      "### DecisionTreeRegressor ###\n",
      "점수: [6.69793278        nan        nan        nan        nan]\n",
      "평균: nan\n",
      "표준편차: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### RandomForestRegressor ###\n",
      "점수: [5.18719051        nan        nan        nan        nan]\n",
      "평균: nan\n",
      "표준편차: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "\n",
    "def display_socres(model):\n",
    "    scores = cross_val_score(model, X_test, y_test,\n",
    "                             scoring=\"r2\", cv=5)\n",
    "    model_rmse_scores = np.sqrt(-scores)\n",
    "    print('###', model.__class__.__name__, '###')\n",
    "    print(\"점수:\", model_rmse_scores)\n",
    "    print(\"평균:\", model_rmse_scores.mean())\n",
    "    print(\"표준편차:\", model_rmse_scores.std())\n",
    "\n",
    "\n",
    "for model in [ridge_reg, lasso_reg, tree_reg, forest_reg]:\n",
    "    display_socres(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test data 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)</th>\n",
       "      <th>GOODS_NM_가정집 오징어불고기/셀프(380g)</th>\n",
       "      <th>GOODS_NM_고사리나물볶음(150g)</th>\n",
       "      <th>GOODS_NM_건표고버섯볶음</th>\n",
       "      <th>GOODS_NM_고구마 품은 라자냐(450g)</th>\n",
       "      <th>GOODS_NM_고소한도토리묵무침(360g)</th>\n",
       "      <th>GOODS_NM_꼬막무침 (260g)</th>\n",
       "      <th>GOODS_NM_두메산나물비빔밥재료</th>\n",
       "      <th>GOODS_NM_메밀소바(2인분)</th>\n",
       "      <th>GOODS_NM_셀프두부조림(600g)</th>\n",
       "      <th>GOODS_NM_소고기유니짜장소스(1인분, 200g)</th>\n",
       "      <th>GOODS_NM_수제계란말이(350g)</th>\n",
       "      <th>GOODS_NM_숙주나물(300g)</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_YMD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-08</th>\n",
       "      <td>117.079529</td>\n",
       "      <td>443.753387</td>\n",
       "      <td>289.190674</td>\n",
       "      <td>273.632446</td>\n",
       "      <td>113.341621</td>\n",
       "      <td>226.346893</td>\n",
       "      <td>577.739929</td>\n",
       "      <td>1019.421143</td>\n",
       "      <td>91.517235</td>\n",
       "      <td>573.306213</td>\n",
       "      <td>32.566288</td>\n",
       "      <td>434.569275</td>\n",
       "      <td>398.142303</td>\n",
       "      <td>160.843964</td>\n",
       "      <td>206.819611</td>\n",
       "      <td>196.089874</td>\n",
       "      <td>622.418274</td>\n",
       "      <td>181.906952</td>\n",
       "      <td>413.975677</td>\n",
       "      <td>283.378662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-15</th>\n",
       "      <td>129.003983</td>\n",
       "      <td>439.674072</td>\n",
       "      <td>322.822235</td>\n",
       "      <td>319.736755</td>\n",
       "      <td>120.675552</td>\n",
       "      <td>276.592804</td>\n",
       "      <td>577.362122</td>\n",
       "      <td>941.227966</td>\n",
       "      <td>108.846497</td>\n",
       "      <td>629.806335</td>\n",
       "      <td>28.582481</td>\n",
       "      <td>450.000763</td>\n",
       "      <td>474.128021</td>\n",
       "      <td>174.374771</td>\n",
       "      <td>193.932617</td>\n",
       "      <td>208.935684</td>\n",
       "      <td>617.234192</td>\n",
       "      <td>207.146835</td>\n",
       "      <td>447.663422</td>\n",
       "      <td>262.877258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-22</th>\n",
       "      <td>90.961327</td>\n",
       "      <td>410.684296</td>\n",
       "      <td>281.477631</td>\n",
       "      <td>269.530243</td>\n",
       "      <td>95.045937</td>\n",
       "      <td>237.611053</td>\n",
       "      <td>551.627197</td>\n",
       "      <td>816.825562</td>\n",
       "      <td>70.697929</td>\n",
       "      <td>566.473877</td>\n",
       "      <td>-3.213213</td>\n",
       "      <td>400.708160</td>\n",
       "      <td>409.677612</td>\n",
       "      <td>137.036377</td>\n",
       "      <td>174.266006</td>\n",
       "      <td>163.114410</td>\n",
       "      <td>605.447144</td>\n",
       "      <td>177.747711</td>\n",
       "      <td>386.426025</td>\n",
       "      <td>242.915283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-29</th>\n",
       "      <td>110.905624</td>\n",
       "      <td>391.216003</td>\n",
       "      <td>288.009338</td>\n",
       "      <td>273.577820</td>\n",
       "      <td>116.387978</td>\n",
       "      <td>257.851410</td>\n",
       "      <td>517.738464</td>\n",
       "      <td>626.707520</td>\n",
       "      <td>94.547836</td>\n",
       "      <td>545.195557</td>\n",
       "      <td>-12.622774</td>\n",
       "      <td>371.142273</td>\n",
       "      <td>409.479156</td>\n",
       "      <td>134.894730</td>\n",
       "      <td>177.251022</td>\n",
       "      <td>163.080490</td>\n",
       "      <td>621.065308</td>\n",
       "      <td>186.907791</td>\n",
       "      <td>351.616669</td>\n",
       "      <td>257.025452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-05</th>\n",
       "      <td>30.174109</td>\n",
       "      <td>106.817978</td>\n",
       "      <td>84.218506</td>\n",
       "      <td>80.277481</td>\n",
       "      <td>37.121563</td>\n",
       "      <td>77.706673</td>\n",
       "      <td>147.756577</td>\n",
       "      <td>183.147812</td>\n",
       "      <td>29.043568</td>\n",
       "      <td>159.341202</td>\n",
       "      <td>-7.161743</td>\n",
       "      <td>105.407333</td>\n",
       "      <td>120.925575</td>\n",
       "      <td>37.088886</td>\n",
       "      <td>53.184841</td>\n",
       "      <td>41.770962</td>\n",
       "      <td>208.497131</td>\n",
       "      <td>54.824734</td>\n",
       "      <td>100.267868</td>\n",
       "      <td>62.017426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)  GOODS_NM_가정집 오징어불고기/셀프(380g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-08                           117.079529                    443.753387   \n",
       "2022-05-15                           129.003983                    439.674072   \n",
       "2022-05-22                            90.961327                    410.684296   \n",
       "2022-05-29                           110.905624                    391.216003   \n",
       "2022-06-05                            30.174109                    106.817978   \n",
       "\n",
       "            GOODS_NM_고사리나물볶음(150g)  GOODS_NM_건표고버섯볶음  \\\n",
       "H_YMD                                                  \n",
       "2022-05-08              289.190674        273.632446   \n",
       "2022-05-15              322.822235        319.736755   \n",
       "2022-05-22              281.477631        269.530243   \n",
       "2022-05-29              288.009338        273.577820   \n",
       "2022-06-05               84.218506         80.277481   \n",
       "\n",
       "            GOODS_NM_고구마 품은 라자냐(450g)  GOODS_NM_고소한도토리묵무침(360g)  \\\n",
       "H_YMD                                                             \n",
       "2022-05-08                 113.341621                226.346893   \n",
       "2022-05-15                 120.675552                276.592804   \n",
       "2022-05-22                  95.045937                237.611053   \n",
       "2022-05-29                 116.387978                257.851410   \n",
       "2022-06-05                  37.121563                 77.706673   \n",
       "\n",
       "            GOODS_NM_꼬막무침 (260g)  GOODS_NM_두메산나물비빔밥재료  GOODS_NM_메밀소바(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-08            577.739929          1019.421143           91.517235   \n",
       "2022-05-15            577.362122           941.227966          108.846497   \n",
       "2022-05-22            551.627197           816.825562           70.697929   \n",
       "2022-05-29            517.738464           626.707520           94.547836   \n",
       "2022-06-05            147.756577           183.147812           29.043568   \n",
       "\n",
       "            GOODS_NM_셀프두부조림(600g)  GOODS_NM_소고기유니짜장소스(1인분, 200g)  \\\n",
       "H_YMD                                                              \n",
       "2022-05-08             573.306213                      32.566288   \n",
       "2022-05-15             629.806335                      28.582481   \n",
       "2022-05-22             566.473877                      -3.213213   \n",
       "2022-05-29             545.195557                     -12.622774   \n",
       "2022-06-05             159.341202                      -7.161743   \n",
       "\n",
       "            GOODS_NM_수제계란말이(350g)  GOODS_NM_숙주나물(300g)  \\\n",
       "H_YMD                                                    \n",
       "2022-05-08             434.569275           398.142303   \n",
       "2022-05-15             450.000763           474.128021   \n",
       "2022-05-22             400.708160           409.677612   \n",
       "2022-05-29             371.142273           409.479156   \n",
       "2022-06-05             105.407333           120.925575   \n",
       "\n",
       "            GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  GOODS_NM_열무비빔밥재료믹스(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-08              160.843964    206.819611               196.089874   \n",
       "2022-05-15              174.374771    193.932617               208.935684   \n",
       "2022-05-22              137.036377    174.266006               163.114410   \n",
       "2022-05-29              134.894730    177.251022               163.080490   \n",
       "2022-06-05               37.088886     53.184841                41.770962   \n",
       "\n",
       "            GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  GOODS_NM_채소계란찜(340g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-08           622.418274              181.906952            413.975677   \n",
       "2022-05-15           617.234192              207.146835            447.663422   \n",
       "2022-05-22           605.447144              177.747711            386.426025   \n",
       "2022-05-29           621.065308              186.907791            351.616669   \n",
       "2022-06-05           208.497131               54.824734            100.267868   \n",
       "\n",
       "            GOODS_NM_한돈 제육볶음(700g)  \n",
       "H_YMD                               \n",
       "2022-05-08              283.378662  \n",
       "2022-05-15              262.877258  \n",
       "2022-05-22              242.915283  \n",
       "2022-05-29              257.025452  \n",
       "2022-06-05               62.017426  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)</th>\n",
       "      <th>GOODS_NM_가정집 오징어불고기/셀프(380g)</th>\n",
       "      <th>GOODS_NM_고사리나물볶음(150g)</th>\n",
       "      <th>GOODS_NM_건표고버섯볶음</th>\n",
       "      <th>GOODS_NM_고구마 품은 라자냐(450g)</th>\n",
       "      <th>GOODS_NM_고소한도토리묵무침(360g)</th>\n",
       "      <th>GOODS_NM_꼬막무침 (260g)</th>\n",
       "      <th>GOODS_NM_두메산나물비빔밥재료</th>\n",
       "      <th>GOODS_NM_메밀소바(2인분)</th>\n",
       "      <th>GOODS_NM_셀프두부조림(600g)</th>\n",
       "      <th>GOODS_NM_소고기유니짜장소스(1인분, 200g)</th>\n",
       "      <th>GOODS_NM_수제계란말이(350g)</th>\n",
       "      <th>GOODS_NM_숙주나물(300g)</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_YMD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>-3.408059e+00</td>\n",
       "      <td>4.908775e+00</td>\n",
       "      <td>3.938695e+00</td>\n",
       "      <td>1.582588e+00</td>\n",
       "      <td>-6.335828e+00</td>\n",
       "      <td>-3.922750e+00</td>\n",
       "      <td>4.309053e+00</td>\n",
       "      <td>1.216588e+01</td>\n",
       "      <td>1.639506e+00</td>\n",
       "      <td>7.788737e+00</td>\n",
       "      <td>0.074703</td>\n",
       "      <td>4.000901e+00</td>\n",
       "      <td>7.271940e+00</td>\n",
       "      <td>-1.565956e+00</td>\n",
       "      <td>-5.743577e-01</td>\n",
       "      <td>-6.604602e-01</td>\n",
       "      <td>7.359269e+00</td>\n",
       "      <td>-3.970186e+00</td>\n",
       "      <td>7.089391e+00</td>\n",
       "      <td>-6.053726e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-02</th>\n",
       "      <td>3.663521e+08</td>\n",
       "      <td>1.367208e+08</td>\n",
       "      <td>1.262098e+08</td>\n",
       "      <td>1.116101e+08</td>\n",
       "      <td>2.342410e+08</td>\n",
       "      <td>1.446795e+08</td>\n",
       "      <td>1.551520e+08</td>\n",
       "      <td>8.823402e+08</td>\n",
       "      <td>-1.179860e+07</td>\n",
       "      <td>2.175174e+08</td>\n",
       "      <td>-412970.437500</td>\n",
       "      <td>1.212046e+08</td>\n",
       "      <td>1.770610e+08</td>\n",
       "      <td>1.693196e+08</td>\n",
       "      <td>3.019169e+08</td>\n",
       "      <td>4.442162e+07</td>\n",
       "      <td>1.085601e+09</td>\n",
       "      <td>7.009550e+07</td>\n",
       "      <td>1.064827e+08</td>\n",
       "      <td>5.515721e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-03</th>\n",
       "      <td>2.680930e+08</td>\n",
       "      <td>1.142665e+08</td>\n",
       "      <td>1.037424e+08</td>\n",
       "      <td>8.798554e+07</td>\n",
       "      <td>1.792637e+08</td>\n",
       "      <td>1.128820e+08</td>\n",
       "      <td>1.358854e+08</td>\n",
       "      <td>7.103931e+08</td>\n",
       "      <td>-6.684520e+06</td>\n",
       "      <td>1.711161e+08</td>\n",
       "      <td>-330552.093750</td>\n",
       "      <td>9.180453e+07</td>\n",
       "      <td>1.427437e+08</td>\n",
       "      <td>1.287601e+08</td>\n",
       "      <td>2.362294e+08</td>\n",
       "      <td>3.686323e+07</td>\n",
       "      <td>9.006364e+08</td>\n",
       "      <td>5.064305e+07</td>\n",
       "      <td>8.244635e+07</td>\n",
       "      <td>4.079452e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-04</th>\n",
       "      <td>3.206750e+08</td>\n",
       "      <td>1.419420e+08</td>\n",
       "      <td>1.283105e+08</td>\n",
       "      <td>1.077067e+08</td>\n",
       "      <td>2.173172e+08</td>\n",
       "      <td>1.376871e+08</td>\n",
       "      <td>1.708385e+08</td>\n",
       "      <td>8.741988e+08</td>\n",
       "      <td>-7.169820e+06</td>\n",
       "      <td>2.093382e+08</td>\n",
       "      <td>-406254.000000</td>\n",
       "      <td>1.111964e+08</td>\n",
       "      <td>1.757581e+08</td>\n",
       "      <td>1.558048e+08</td>\n",
       "      <td>2.881632e+08</td>\n",
       "      <td>4.571128e+07</td>\n",
       "      <td>1.115792e+09</td>\n",
       "      <td>6.049195e+07</td>\n",
       "      <td>1.005470e+08</td>\n",
       "      <td>4.895463e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-05</th>\n",
       "      <td>1.667621e+08</td>\n",
       "      <td>6.544178e+07</td>\n",
       "      <td>6.001378e+07</td>\n",
       "      <td>5.221765e+07</td>\n",
       "      <td>1.084115e+08</td>\n",
       "      <td>6.744437e+07</td>\n",
       "      <td>7.568148e+07</td>\n",
       "      <td>4.162134e+08</td>\n",
       "      <td>-4.924924e+06</td>\n",
       "      <td>1.016886e+08</td>\n",
       "      <td>-194300.968750</td>\n",
       "      <td>5.586176e+07</td>\n",
       "      <td>8.355769e+07</td>\n",
       "      <td>7.816793e+07</td>\n",
       "      <td>1.408880e+08</td>\n",
       "      <td>2.119958e+07</td>\n",
       "      <td>5.181467e+08</td>\n",
       "      <td>3.177320e+07</td>\n",
       "      <td>4.946804e+07</td>\n",
       "      <td>2.520538e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)  GOODS_NM_가정집 오징어불고기/셀프(380g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01                        -3.408059e+00                  4.908775e+00   \n",
       "2022-05-02                         3.663521e+08                  1.367208e+08   \n",
       "2022-05-03                         2.680930e+08                  1.142665e+08   \n",
       "2022-05-04                         3.206750e+08                  1.419420e+08   \n",
       "2022-05-05                         1.667621e+08                  6.544178e+07   \n",
       "\n",
       "            GOODS_NM_고사리나물볶음(150g)  GOODS_NM_건표고버섯볶음  \\\n",
       "H_YMD                                                  \n",
       "2022-05-01            3.938695e+00      1.582588e+00   \n",
       "2022-05-02            1.262098e+08      1.116101e+08   \n",
       "2022-05-03            1.037424e+08      8.798554e+07   \n",
       "2022-05-04            1.283105e+08      1.077067e+08   \n",
       "2022-05-05            6.001378e+07      5.221765e+07   \n",
       "\n",
       "            GOODS_NM_고구마 품은 라자냐(450g)  GOODS_NM_고소한도토리묵무침(360g)  \\\n",
       "H_YMD                                                             \n",
       "2022-05-01              -6.335828e+00             -3.922750e+00   \n",
       "2022-05-02               2.342410e+08              1.446795e+08   \n",
       "2022-05-03               1.792637e+08              1.128820e+08   \n",
       "2022-05-04               2.173172e+08              1.376871e+08   \n",
       "2022-05-05               1.084115e+08              6.744437e+07   \n",
       "\n",
       "            GOODS_NM_꼬막무침 (260g)  GOODS_NM_두메산나물비빔밥재료  GOODS_NM_메밀소바(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01          4.309053e+00         1.216588e+01        1.639506e+00   \n",
       "2022-05-02          1.551520e+08         8.823402e+08       -1.179860e+07   \n",
       "2022-05-03          1.358854e+08         7.103931e+08       -6.684520e+06   \n",
       "2022-05-04          1.708385e+08         8.741988e+08       -7.169820e+06   \n",
       "2022-05-05          7.568148e+07         4.162134e+08       -4.924924e+06   \n",
       "\n",
       "            GOODS_NM_셀프두부조림(600g)  GOODS_NM_소고기유니짜장소스(1인분, 200g)  \\\n",
       "H_YMD                                                              \n",
       "2022-05-01           7.788737e+00                       0.074703   \n",
       "2022-05-02           2.175174e+08                 -412970.437500   \n",
       "2022-05-03           1.711161e+08                 -330552.093750   \n",
       "2022-05-04           2.093382e+08                 -406254.000000   \n",
       "2022-05-05           1.016886e+08                 -194300.968750   \n",
       "\n",
       "            GOODS_NM_수제계란말이(350g)  GOODS_NM_숙주나물(300g)  \\\n",
       "H_YMD                                                    \n",
       "2022-05-01           4.000901e+00         7.271940e+00   \n",
       "2022-05-02           1.212046e+08         1.770610e+08   \n",
       "2022-05-03           9.180453e+07         1.427437e+08   \n",
       "2022-05-04           1.111964e+08         1.757581e+08   \n",
       "2022-05-05           5.586176e+07         8.355769e+07   \n",
       "\n",
       "            GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  GOODS_NM_열무비빔밥재료믹스(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01           -1.565956e+00 -5.743577e-01            -6.604602e-01   \n",
       "2022-05-02            1.693196e+08  3.019169e+08             4.442162e+07   \n",
       "2022-05-03            1.287601e+08  2.362294e+08             3.686323e+07   \n",
       "2022-05-04            1.558048e+08  2.881632e+08             4.571128e+07   \n",
       "2022-05-05            7.816793e+07  1.408880e+08             2.119958e+07   \n",
       "\n",
       "            GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  GOODS_NM_채소계란찜(340g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01         7.359269e+00           -3.970186e+00          7.089391e+00   \n",
       "2022-05-02         1.085601e+09            7.009550e+07          1.064827e+08   \n",
       "2022-05-03         9.006364e+08            5.064305e+07          8.244635e+07   \n",
       "2022-05-04         1.115792e+09            6.049195e+07          1.005470e+08   \n",
       "2022-05-05         5.181467e+08            3.177320e+07          4.946804e+07   \n",
       "\n",
       "            GOODS_NM_한돈 제육볶음(700g)  \n",
       "H_YMD                               \n",
       "2022-05-01           -6.053726e+00  \n",
       "2022-05-02            5.515721e+08  \n",
       "2022-05-03            4.079452e+08  \n",
       "2022-05-04            4.895463e+08  \n",
       "2022-05-05            2.520538e+08  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 테스트 데이터에 대해서 결과를 출력한다.\n",
    "\n",
    "# lasso_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# lasso_test_pred = pd.DataFrame(lasso_test_pred)\n",
    "\n",
    "# lasso_test_pred.columns = ['GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)', 'GOODS_NM_가정집 오징어불고기/셀프(380g)',\n",
    "#        'GOODS_NM_고사리나물볶음(150g)', 'GOODS_NM_건표고버섯볶음',\n",
    "#        'GOODS_NM_고구마 품은 라자냐(450g)', 'GOODS_NM_고소한도토리묵무침(360g)',\n",
    "#        'GOODS_NM_꼬막무침 (260g)', 'GOODS_NM_두메산나물비빔밥재료', 'GOODS_NM_메밀소바(2인분)',\n",
    "#        'GOODS_NM_셀프두부조림(600g)', 'GOODS_NM_소고기유니짜장소스(1인분, 200g)',\n",
    "#        'GOODS_NM_수제계란말이(350g)', 'GOODS_NM_숙주나물(300g)',\n",
    "#        'GOODS_NM_순살코다리강정(180g)', 'GOODS_NM_양장피', 'GOODS_NM_열무비빔밥재료믹스(2인분)',\n",
    "#        'GOODS_NM_옛날잡채(500g)', 'GOODS_NM_우삼겹숙주볶음(250g)', 'GOODS_NM_채소계란찜(340g)',\n",
    "#        'GOODS_NM_한돈 제육볶음(700g)']\n",
    "\n",
    "# lasso_test_pred.insert(0, 'H_YMD', pd.DataFrame(H_YMD)[-31:])\n",
    "\n",
    "# 테스트 데이터에 대해서 결과를 출력한다.\n",
    "\n",
    "lasso_test_pred = xgb_model.predict(X_test)\n",
    "df = y_test.copy()\n",
    "\n",
    "df[['GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)', 'GOODS_NM_가정집 오징어불고기/셀프(380g)',\n",
    "       'GOODS_NM_고사리나물볶음(150g)', 'GOODS_NM_건표고버섯볶음',\n",
    "       'GOODS_NM_고구마 품은 라자냐(450g)', 'GOODS_NM_고소한도토리묵무침(360g)',\n",
    "       'GOODS_NM_꼬막무침 (260g)', 'GOODS_NM_두메산나물비빔밥재료', 'GOODS_NM_메밀소바(2인분)',\n",
    "       'GOODS_NM_셀프두부조림(600g)', 'GOODS_NM_소고기유니짜장소스(1인분, 200g)',\n",
    "       'GOODS_NM_수제계란말이(350g)', 'GOODS_NM_숙주나물(300g)',\n",
    "       'GOODS_NM_순살코다리강정(180g)', 'GOODS_NM_양장피', 'GOODS_NM_열무비빔밥재료믹스(2인분)',\n",
    "       'GOODS_NM_옛날잡채(500g)', 'GOODS_NM_우삼겹숙주볶음(250g)', 'GOODS_NM_채소계란찜(340g)',\n",
    "       'GOODS_NM_한돈 제육볶음(700g)']] = lasso_test_pred\n",
    "\n",
    "lasso_test_pred = df.copy()\n",
    "lasso_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)</th>\n",
       "      <th>GOODS_NM_가정집 오징어불고기/셀프(380g)</th>\n",
       "      <th>GOODS_NM_고사리나물볶음(150g)</th>\n",
       "      <th>GOODS_NM_건표고버섯볶음</th>\n",
       "      <th>GOODS_NM_고구마 품은 라자냐(450g)</th>\n",
       "      <th>GOODS_NM_고소한도토리묵무침(360g)</th>\n",
       "      <th>GOODS_NM_꼬막무침 (260g)</th>\n",
       "      <th>GOODS_NM_두메산나물비빔밥재료</th>\n",
       "      <th>GOODS_NM_메밀소바(2인분)</th>\n",
       "      <th>GOODS_NM_셀프두부조림(600g)</th>\n",
       "      <th>GOODS_NM_소고기유니짜장소스(1인분, 200g)</th>\n",
       "      <th>GOODS_NM_수제계란말이(350g)</th>\n",
       "      <th>GOODS_NM_숙주나물(300g)</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_YMD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-02</th>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-03</th>\n",
       "      <td>36.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-04</th>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-05</th>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)  GOODS_NM_가정집 오징어불고기/셀프(380g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01                                  0.0                           0.0   \n",
       "2022-05-02                                 33.0                          34.0   \n",
       "2022-05-03                                 36.0                          31.0   \n",
       "2022-05-04                                 34.0                          31.0   \n",
       "2022-05-05                                 15.0                          20.0   \n",
       "\n",
       "            GOODS_NM_고사리나물볶음(150g)  GOODS_NM_건표고버섯볶음  \\\n",
       "H_YMD                                                  \n",
       "2022-05-01                     0.0               0.0   \n",
       "2022-05-02                    23.0              55.0   \n",
       "2022-05-03                    16.0              40.0   \n",
       "2022-05-04                    22.0              49.0   \n",
       "2022-05-05                    21.0              28.0   \n",
       "\n",
       "            GOODS_NM_고구마 품은 라자냐(450g)  GOODS_NM_고소한도토리묵무침(360g)  \\\n",
       "H_YMD                                                             \n",
       "2022-05-01                        0.0                       0.0   \n",
       "2022-05-02                       10.0                      48.0   \n",
       "2022-05-03                       11.0                      41.0   \n",
       "2022-05-04                       14.0                      65.0   \n",
       "2022-05-05                        9.0                      27.0   \n",
       "\n",
       "            GOODS_NM_꼬막무침 (260g)  GOODS_NM_두메산나물비빔밥재료  GOODS_NM_메밀소바(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01                   0.0                  0.0                 0.0   \n",
       "2022-05-02                  48.0                208.0                 0.0   \n",
       "2022-05-03                  35.0                154.0                 0.0   \n",
       "2022-05-04                  46.0                183.0                 0.0   \n",
       "2022-05-05                  18.0                123.0                 0.0   \n",
       "\n",
       "            GOODS_NM_셀프두부조림(600g)  GOODS_NM_소고기유니짜장소스(1인분, 200g)  \\\n",
       "H_YMD                                                              \n",
       "2022-05-01                    0.0                            0.0   \n",
       "2022-05-02                   88.0                           75.0   \n",
       "2022-05-03                   71.0                           40.0   \n",
       "2022-05-04                   69.0                           76.0   \n",
       "2022-05-05                   39.0                           21.0   \n",
       "\n",
       "            GOODS_NM_수제계란말이(350g)  GOODS_NM_숙주나물(300g)  \\\n",
       "H_YMD                                                    \n",
       "2022-05-01                    0.0                  0.0   \n",
       "2022-05-02                   47.0                 63.0   \n",
       "2022-05-03                   31.0                 61.0   \n",
       "2022-05-04                   39.0                 70.0   \n",
       "2022-05-05                   22.0                 25.0   \n",
       "\n",
       "            GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  GOODS_NM_열무비빔밥재료믹스(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01                     0.0           0.0                      0.0   \n",
       "2022-05-02                    52.0          70.0                      0.0   \n",
       "2022-05-03                    22.0          45.0                      0.0   \n",
       "2022-05-04                    26.0          64.0                      0.0   \n",
       "2022-05-05                    18.0          20.0                      0.0   \n",
       "\n",
       "            GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  GOODS_NM_채소계란찜(340g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01                  0.0                     0.0                   0.0   \n",
       "2022-05-02                126.0                    15.0                  93.0   \n",
       "2022-05-03                100.0                    22.0                  76.0   \n",
       "2022-05-04                150.0                    24.0                  75.0   \n",
       "2022-05-05                 69.0                    11.0                  28.0   \n",
       "\n",
       "            GOODS_NM_한돈 제육볶음(700g)  \n",
       "H_YMD                               \n",
       "2022-05-01                     0.0  \n",
       "2022-05-02                    50.0  \n",
       "2022-05-03                    52.0  \n",
       "2022-05-04                    51.0  \n",
       "2022-05-05                    15.0  "
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)</th>\n",
       "      <th>GOODS_NM_가정집 오징어불고기/셀프(380g)</th>\n",
       "      <th>GOODS_NM_고사리나물볶음(150g)</th>\n",
       "      <th>GOODS_NM_건표고버섯볶음</th>\n",
       "      <th>GOODS_NM_고구마 품은 라자냐(450g)</th>\n",
       "      <th>GOODS_NM_고소한도토리묵무침(360g)</th>\n",
       "      <th>GOODS_NM_꼬막무침 (260g)</th>\n",
       "      <th>GOODS_NM_두메산나물비빔밥재료</th>\n",
       "      <th>GOODS_NM_메밀소바(2인분)</th>\n",
       "      <th>GOODS_NM_셀프두부조림(600g)</th>\n",
       "      <th>GOODS_NM_소고기유니짜장소스(1인분, 200g)</th>\n",
       "      <th>GOODS_NM_수제계란말이(350g)</th>\n",
       "      <th>GOODS_NM_숙주나물(300g)</th>\n",
       "      <th>GOODS_NM_순살코다리강정(180g)</th>\n",
       "      <th>GOODS_NM_양장피</th>\n",
       "      <th>GOODS_NM_열무비빔밥재료믹스(2인분)</th>\n",
       "      <th>GOODS_NM_옛날잡채(500g)</th>\n",
       "      <th>GOODS_NM_우삼겹숙주볶음(250g)</th>\n",
       "      <th>GOODS_NM_채소계란찜(340g)</th>\n",
       "      <th>GOODS_NM_한돈 제육볶음(700g)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_YMD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>0.543901</td>\n",
       "      <td>0.331515</td>\n",
       "      <td>0.718077</td>\n",
       "      <td>0.565495</td>\n",
       "      <td>-3.768790</td>\n",
       "      <td>-3.078161</td>\n",
       "      <td>-2.635706</td>\n",
       "      <td>-3.640343</td>\n",
       "      <td>-2.322604</td>\n",
       "      <td>1.870694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418082</td>\n",
       "      <td>4.677436</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.393099</td>\n",
       "      <td>-2.249822</td>\n",
       "      <td>9.047145</td>\n",
       "      <td>-2.680414</td>\n",
       "      <td>1.689498</td>\n",
       "      <td>-0.252219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-02</th>\n",
       "      <td>-14.340244</td>\n",
       "      <td>30.428644</td>\n",
       "      <td>15.711487</td>\n",
       "      <td>-34.364974</td>\n",
       "      <td>-26.732917</td>\n",
       "      <td>-35.020764</td>\n",
       "      <td>79.951424</td>\n",
       "      <td>20.283039</td>\n",
       "      <td>37.999414</td>\n",
       "      <td>1.983329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.517338</td>\n",
       "      <td>-8.281828</td>\n",
       "      <td>-27.204663</td>\n",
       "      <td>-4.355658</td>\n",
       "      <td>4.994889</td>\n",
       "      <td>34.417130</td>\n",
       "      <td>-27.393540</td>\n",
       "      <td>5.388354</td>\n",
       "      <td>-47.299845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-03</th>\n",
       "      <td>-10.823351</td>\n",
       "      <td>23.328858</td>\n",
       "      <td>12.174877</td>\n",
       "      <td>-26.125632</td>\n",
       "      <td>-21.317116</td>\n",
       "      <td>-27.489816</td>\n",
       "      <td>60.484940</td>\n",
       "      <td>14.651677</td>\n",
       "      <td>28.479640</td>\n",
       "      <td>1.955788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.122563</td>\n",
       "      <td>-5.227462</td>\n",
       "      <td>-20.702023</td>\n",
       "      <td>-3.233291</td>\n",
       "      <td>3.274160</td>\n",
       "      <td>28.445857</td>\n",
       "      <td>-21.565022</td>\n",
       "      <td>4.512354</td>\n",
       "      <td>-36.208114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-04</th>\n",
       "      <td>-13.484329</td>\n",
       "      <td>28.705965</td>\n",
       "      <td>14.853883</td>\n",
       "      <td>-32.367286</td>\n",
       "      <td>-25.425037</td>\n",
       "      <td>-33.199178</td>\n",
       "      <td>75.244066</td>\n",
       "      <td>18.943318</td>\n",
       "      <td>35.686271</td>\n",
       "      <td>1.971730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.188736</td>\n",
       "      <td>-7.545903</td>\n",
       "      <td>-25.632304</td>\n",
       "      <td>-4.082292</td>\n",
       "      <td>4.566899</td>\n",
       "      <td>33.000200</td>\n",
       "      <td>-25.985155</td>\n",
       "      <td>5.168954</td>\n",
       "      <td>-44.621907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-05</th>\n",
       "      <td>-6.274709</td>\n",
       "      <td>14.128156</td>\n",
       "      <td>7.591086</td>\n",
       "      <td>-15.446912</td>\n",
       "      <td>-14.293809</td>\n",
       "      <td>-17.722372</td>\n",
       "      <td>35.232045</td>\n",
       "      <td>7.326832</td>\n",
       "      <td>16.154379</td>\n",
       "      <td>1.923345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.304055</td>\n",
       "      <td>-1.263647</td>\n",
       "      <td>-12.268977</td>\n",
       "      <td>-1.781721</td>\n",
       "      <td>1.063637</td>\n",
       "      <td>20.676342</td>\n",
       "      <td>-14.007176</td>\n",
       "      <td>3.384302</td>\n",
       "      <td>-21.820394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)  GOODS_NM_가정집 오징어불고기/셀프(380g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01                             0.543901                      0.331515   \n",
       "2022-05-02                           -14.340244                     30.428644   \n",
       "2022-05-03                           -10.823351                     23.328858   \n",
       "2022-05-04                           -13.484329                     28.705965   \n",
       "2022-05-05                            -6.274709                     14.128156   \n",
       "\n",
       "            GOODS_NM_고사리나물볶음(150g)  GOODS_NM_건표고버섯볶음  \\\n",
       "H_YMD                                                  \n",
       "2022-05-01                0.718077          0.565495   \n",
       "2022-05-02               15.711487        -34.364974   \n",
       "2022-05-03               12.174877        -26.125632   \n",
       "2022-05-04               14.853883        -32.367286   \n",
       "2022-05-05                7.591086        -15.446912   \n",
       "\n",
       "            GOODS_NM_고구마 품은 라자냐(450g)  GOODS_NM_고소한도토리묵무침(360g)  \\\n",
       "H_YMD                                                             \n",
       "2022-05-01                  -3.768790                 -3.078161   \n",
       "2022-05-02                 -26.732917                -35.020764   \n",
       "2022-05-03                 -21.317116                -27.489816   \n",
       "2022-05-04                 -25.425037                -33.199178   \n",
       "2022-05-05                 -14.293809                -17.722372   \n",
       "\n",
       "            GOODS_NM_꼬막무침 (260g)  GOODS_NM_두메산나물비빔밥재료  GOODS_NM_메밀소바(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01             -2.635706            -3.640343           -2.322604   \n",
       "2022-05-02             79.951424            20.283039           37.999414   \n",
       "2022-05-03             60.484940            14.651677           28.479640   \n",
       "2022-05-04             75.244066            18.943318           35.686271   \n",
       "2022-05-05             35.232045             7.326832           16.154379   \n",
       "\n",
       "            GOODS_NM_셀프두부조림(600g)  GOODS_NM_소고기유니짜장소스(1인분, 200g)  \\\n",
       "H_YMD                                                              \n",
       "2022-05-01               1.870694                            0.0   \n",
       "2022-05-02               1.983329                            0.0   \n",
       "2022-05-03               1.955788                            0.0   \n",
       "2022-05-04               1.971730                            0.0   \n",
       "2022-05-05               1.923345                            0.0   \n",
       "\n",
       "            GOODS_NM_수제계란말이(350g)  GOODS_NM_숙주나물(300g)  \\\n",
       "H_YMD                                                    \n",
       "2022-05-01               0.418082             4.677436   \n",
       "2022-05-02              -5.517338            -8.281828   \n",
       "2022-05-03              -4.122563            -5.227462   \n",
       "2022-05-04              -5.188736            -7.545903   \n",
       "2022-05-05              -2.304055            -1.263647   \n",
       "\n",
       "            GOODS_NM_순살코다리강정(180g)  GOODS_NM_양장피  GOODS_NM_열무비빔밥재료믹스(2인분)  \\\n",
       "H_YMD                                                                       \n",
       "2022-05-01                0.373500      0.393099                -2.249822   \n",
       "2022-05-02              -27.204663     -4.355658                 4.994889   \n",
       "2022-05-03              -20.702023     -3.233291                 3.274160   \n",
       "2022-05-04              -25.632304     -4.082292                 4.566899   \n",
       "2022-05-05              -12.268977     -1.781721                 1.063637   \n",
       "\n",
       "            GOODS_NM_옛날잡채(500g)  GOODS_NM_우삼겹숙주볶음(250g)  GOODS_NM_채소계란찜(340g)  \\\n",
       "H_YMD                                                                           \n",
       "2022-05-01             9.047145               -2.680414              1.689498   \n",
       "2022-05-02            34.417130              -27.393540              5.388354   \n",
       "2022-05-03            28.445857              -21.565022              4.512354   \n",
       "2022-05-04            33.000200              -25.985155              5.168954   \n",
       "2022-05-05            20.676342              -14.007176              3.384302   \n",
       "\n",
       "            GOODS_NM_한돈 제육볶음(700g)  \n",
       "H_YMD                               \n",
       "2022-05-01               -0.252219  \n",
       "2022-05-02              -47.299845  \n",
       "2022-05-03              -36.208114  \n",
       "2022-05-04              -44.621907  \n",
       "2022-05-05              -21.820394  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_test_pred = ridge_reg.predict(X_test_s)\n",
    "df = y_test.copy()\n",
    "\n",
    "df[['GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)',\n",
    "       'GOODS_NM_가정집 오징어불고기/셀프(380g)', 'GOODS_NM_고사리나물볶음(150g)',\n",
    "       'GOODS_NM_건표고버섯볶음', 'GOODS_NM_고구마 품은 라자냐(450g)',\n",
    "       'GOODS_NM_고소한도토리묵무침(360g)', 'GOODS_NM_꼬막무침 (260g)',\n",
    "       'GOODS_NM_두메산나물비빔밥재료', 'GOODS_NM_메밀소바(2인분)', 'GOODS_NM_셀프두부조림(600g)',\n",
    "       'GOODS_NM_소고기유니짜장소스(1인분, 200g)', 'GOODS_NM_수제계란말이(350g)',\n",
    "       'GOODS_NM_숙주나물(300g)', 'GOODS_NM_순살코다리강정(180g)', 'GOODS_NM_양장피',\n",
    "       'GOODS_NM_열무비빔밥재료믹스(2인분)', 'GOODS_NM_옛날잡채(500g)',\n",
    "       'GOODS_NM_우삼겹숙주볶음(250g)', 'GOODS_NM_채소계란찜(340g)',\n",
    "       'GOODS_NM_한돈 제육볶음(700g)']] = ridge_test_pred\n",
    "\n",
    "ridge_test_pred = df.copy()\n",
    "ridge_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'GridSearchCV' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Dongwon\\Dongwon_Project\\더반찬_예측과제_rf_rd_ls_성능비교.ipynb 셀 94\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000100?line=0'>1</a>\u001b[0m rf_test_pred \u001b[39m=\u001b[39m rf_grid_search(X_test_s)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000100?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m y_test\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000100?line=3'>4</a>\u001b[0m df[[\u001b[39m'\u001b[39m\u001b[39mGOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGOODS_NM_가정집 오징어불고기/셀프(380g)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000100?line=4'>5</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mGOODS_NM_고사리나물볶음(150g)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGOODS_NM_건표고버섯볶음\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000100?line=5'>6</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mGOODS_NM_고구마 품은 라자냐(450g)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGOODS_NM_고소한도토리묵무침(360g)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000100?line=10'>11</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mGOODS_NM_옛날잡채(500g)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGOODS_NM_우삼겹숙주볶음(250g)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGOODS_NM_채소계란찜(340g)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Dongwon/Dongwon_Project/%EB%8D%94%EB%B0%98%EC%B0%AC_%EC%98%88%EC%B8%A1%EA%B3%BC%EC%A0%9C_rf_rd_ls_%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb#ch0000100?line=11'>12</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mGOODS_NM_한돈 제육볶음(700g)\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m rf_test_pred\n",
      "\u001b[1;31mTypeError\u001b[0m: 'GridSearchCV' object is not callable"
     ]
    }
   ],
   "source": [
    "rf_test_pred = rf_grid_search(X_test_s)\n",
    "df = y_test.copy()\n",
    "\n",
    "df[['GOODS_NM__심방골주부X더반찬_ 시골 돼지짜글이(600g)', 'GOODS_NM_가정집 오징어불고기/셀프(380g)',\n",
    "       'GOODS_NM_고사리나물볶음(150g)', 'GOODS_NM_건표고버섯볶음',\n",
    "       'GOODS_NM_고구마 품은 라자냐(450g)', 'GOODS_NM_고소한도토리묵무침(360g)',\n",
    "       'GOODS_NM_꼬막무침 (260g)', 'GOODS_NM_두메산나물비빔밥재료', 'GOODS_NM_메밀소바(2인분)',\n",
    "       'GOODS_NM_셀프두부조림(600g)', 'GOODS_NM_소고기유니짜장소스(1인분, 200g)',\n",
    "       'GOODS_NM_수제계란말이(350g)', 'GOODS_NM_숙주나물(300g)',\n",
    "       'GOODS_NM_순살코다리강정(180g)', 'GOODS_NM_양장피', 'GOODS_NM_열무비빔밥재료믹스(2인분)',\n",
    "       'GOODS_NM_옛날잡채(500g)', 'GOODS_NM_우삼겹숙주볶음(250g)', 'GOODS_NM_채소계란찜(340g)',\n",
    "       'GOODS_NM_한돈 제육볶음(700g)']] = rf_test_pred\n",
    "\n",
    "rf_test_pred = df.copy()\n",
    "rf_test_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 평가 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  -39504552421621.48\n",
      "RMSE:  152204865.1628976\n",
      "r2:  -5.792250852242641\n",
      "RMSE:  55.505811450300016\n"
     ]
    }
   ],
   "source": [
    "# 모델의 성능을 점검하는 지표로 r2와 RMSE를 사용한다.\n",
    "# r2는 회귀모델에서 독립변수가 종속변수를 얼마만큼 설명해주는지 가리키는 지표이기에 사용했다.\n",
    "# 회귀 예측에 대한 정확도는 accuracy로 판단할 수 없기 때문에 rmse를 사용했다.\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lasso_r2 = r2_score(y_test, lasso_test_pred)\n",
    "lasso_RMSE = mean_squared_error(y_test, lasso_test_pred, squared=False)\n",
    "\n",
    "print('r2: ', lasso_r2)\n",
    "print('RMSE: ', lasso_RMSE)\n",
    "\n",
    "ridge_r2 = r2_score(y_test, ridge_test_pred)\n",
    "ridge_RMSE = mean_squared_error(y_test, ridge_test_pred, squared=False)\n",
    "\n",
    "print('r2: ', ridge_r2)\n",
    "print('RMSE: ', ridge_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10156\\2119176278.py:6: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  chart.set_xticklabels(xlabel, rotation=45, size=8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2786f61bd60>"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4YAAAKWCAYAAAAV0ociAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAADIbElEQVR4nOzdd3Rc1dXG4XfLvdvYEhaY3nszHyWhG9t0EiCB0ALBBELoCSR0YkiAhEAISQglFEMoadihY8A0U2Ji0yF0YmHJvRfJ0vn+2HMj2ZasMuXeO/N71tIaaWY0cyxLM/e9e59zLIQgAAAAAEDpKot7AAAAAACAeBEMAQAAAKDEEQwBAAAAoMQRDAEAAACgxBEMAQAAAKDEEQwBAAAAoMSVVDA0s3Izu9rMRrdyv3XN7BYz+36T63Y3sxfM7BUzOyfvgwUAAACAAimpYCjpeknLJHVp6Q5m1jVzv8WSLHOdSbpO0mGSvi7pSDNbK++jBQAAAIACKKlgGEI4QdIL0ddmtpmZPWVmz5nZ7zP3qQ0hHCXprSbfuqGkT0IIc0II9ZIekfR/hRw7AAAAAORLSQXDZvxG0vdCCPtIWmhme7RwvwpJM5p8PUvSgHwPDgAAAAAKoXPcA4jZDpLGeKeoekt6o4X7zdOKQXCApPfyOzQAAAAAKIxSD4ZvSzoyhDDXzLpJWt7C/T6StK2Z9ZHPPRwu6bYCjREAAAAA8qrUg+Elkh4xs2XyVtGTJC1Z+U4hhDozu1LSM5nbbwkhzCnoSAEAAAAgTyyEEPcYAAAAAAAxKvXFZwAAAACg5BEMAQAAAKDElcwcw0GDBoX1118/7mEAAAAAQCzeeOONmSGE8uZuK5lguP7662vSpElxDwMAAAAAYmFmX7R0G62kAAAAAFDiCIYAAAAAUOIIhgAAAABQ4kpmjiEAAACAZKurq9PUqVO1dOnSuIeSat27d9eQIUPUpUuXNn8PwRAAAABAIkydOlV9+vTR+uuvLzOLezipFELQrFmzNHXqVG2wwQZt/j5aSQEAAAAkwtKlSzVw4EBCYRbMTAMHDmx31ZVgCAAAACAxkhwKn376aT377LOrvc+CBQv03HPPtfpYJ510Uq6GtYqO/AwJhgAAAADQjGHDhq3wdVVVlb766qv/3bbTTjtpk0020bBhw/Tmm29q5MiRmjVrlu67777/fc/555+vYcOGadiwYdp444310EMPSZI+++yzwv1D2oBgCAAAACCV7rtPWn99qazML5vksaxNmzZNEydO1PTp05u9ffz48br++uv1ve99T+PHj9d2223X7P2uv/56jR8/Xo8//rg22GADDR8+XJLU0NCgKVOmaObMmbkbdBYIhgAAAABS5777pFNPlb74QgrBL089NTfhcMGCBTrrrLP0l7/8Raeeeqq+/PLLZu83a9YszZ07V++8847uvfdezZ8/v9n7zZw5U0cffbROPfVU9e/fX5IHw3feeUezZ8/OfsA5wKqkAAAAABLnnHOkKVNavv3VV6Vly1a8bvFi6Xvfk267rfnv2X576cYbV/+88+fP11lnnaWrrrpKm222mXbccUdde+21uuaaa1a57+TJk/XOO++orKxMnTt3XmVu34wZM/Tzn/9cTz/9tH7xi1/okEMO+d9tnTt31nHHHbf6wRQQFUMAAAAAqbNyKGzt+rbq27ev7rrrLs2aNUtXXXWV7rjjDg0aNEi/+tWvNHXqVG2//faSpOXLl2vy5Mlad9111bt3bx199NHq06fPCo/Vr18/bbXVVnrttddWCIWSNGHChOwGmmNUDAEAAAAkTmuVvfXX9/bRla23npSLzLXhhhuqa9euK1z3+OOPa8qUKdp66631m9/8Rscdd5y22247XXTRRbr33ntXeYyuXbtqv/3203XXXacrr7xSJ5xwgu655x4999xz+vDDD3XaaadlP9AcIRgCAAAASJ2rr/Y5hYsXN17Xs6dfnwsTJkzQ7bffvsJ11dXV+slPfqIvvvhCkyZN0v333y9J2mOPPfT22283+zj19fX605/+pOeff15z5syRJP3nP//R+++/n5uB5gjBEAAAAEDqHHusX158sfTll9K663oojK7P1ueff65LLrlEe++9d7O3//nPf/7f59///vdX+1jf/va39atf/UqHH3645s2bp+eee04DBgzQhx9+qM022yw3A84SwRAAAABAKh17bO6CYHPOP/98DRgwYIXrDjzwQJ133nnt2kT+wQcf1KRJkzRnzhyde+65uuyyyzRkyBCde+65+v3vf69u3brleujtZiGEuMdQEEOHDg2TJk2KexgAAAAAWvD+++9riy22iHsYRaG5n6WZvRFCGNrc/RNRMTSzcknnSGoIIVza5PrbJW2c+bKvpM9DCN80szskbSGpVtLrIYQLCjxkAAAAACgaiQiGkq6X9LGknk2vDCGcEn1uZjdJGpP5sr+kA0II8wo1QAAAAAAoVonYxzCEcIKkF1q63czWk1QRQvhX5qo+kuYXYmwAAAAAUOwSEQzb4DxJv2nydZA0wcyeMrM9YhoTACTXtGnSXntJ1dVxjwQAAKRA4oOhmXWXtH0I4ZXouhDCiBDCXpK+J+l3q/neU81skplNmjFjRgFGCwAJMXq09NJLfgkAAFJj0aJFeuaZZ5q97ZVXXtELL7TYaJmVxAdDSQdIGt/0CjOL5kbOkVTX0jeGEG4NIQwNIQwtLy/P4xABIEGmTZPuuENqaJD+9CeqhgAAJNA777yjPfbYQ7vvvrsmTpwoSRo2bJjmzJmjMWPG/O9+EyZM0LBhwzRs2DAdc8wxOv744//3dUsBsiMSGQzN7Foz65r5cm9JL690lyfMbIKkxyVdVMChAUDyjR4t1df75/X1VA0BAMUth9MnPv/8cx199NE5GFTrrrjiCj344IN67LHHdOWVV7Z4v7333lvjx4/X5Zdfro033lgbb7yxfvazn2n8+PHab7/9cjaexATDEMKEEMJPMp9fGEKozXx+dgjh2ZXuOyyEsHcIYY8QwpNxjBcAEmnaNOnOOxuDYV2df03VEABQrFI6faK2tlZrrbWW+vfvrx49emj58uXN3u/mm2/WSSedpNdff12PPPKIxo4dqyeeeEKHHXaYrr322pyNJynbVQAAcmH0aG8hbSqqGv6uxSnZAAAkzznnSFOmrP4+y5ZJr7/u73233CJNnix17dry/bffXrrxxjY9/WOPPabrr79eCxcu1IgRI/Szn/1M48aN0zXXXKOysjKdf/752mOPPXTCCSdowYIF2myzzXT77bfrgw8+0DnnnKNly5apvr5eN9xwg3baaafVPlevXr30zW9+U+++++4K18+cOVNDhw7V0KG+J/2UzM/jwAMP1IEHHqhFixZpxowZysW0OYIhABSTV16RamtXvK62VsrMXQAAoKh88YUUgn8egn+9ySY5eeidd95ZzzzzjOrr67Xtttvqiiuu0J133qkxY8Zoo402UkNDg/75z39qp5120ujRo9WQOTH7wx/+UL///e+16aab6osvvtBxxx2nF198cZXHD9G4Jc2bN0/jxo3T8OHDV7jPggUL9PHHH692nBtssAHBEACwksmT/XLAAGnuXK8UXnJJrEMCAKBDWqvsTZsmbbjhisFwzhzpgQekwYOzfvpHH31Ub7/9trp27arFixertrZWN954o26++Wb16NFD5513ng4++GB99tlnOvvss3XMMcdo11131aJFi7TppptKktZbb70WW0TXXHNNvf322+rdu7e6deumsrJVZ/ltsMEG6tmzp4499thVbuvdu7cefvjhrP+dEYIhABSbxYs9FEoSW/UAAIpVnqdP/Pa3v9Ubb7yhhQsX6u6775YkVVRU6Je//KWefPJJjR49WldddZXOOecc1dfXa8cdd9Sbb76prl276uOPP9bGG2+s//73v+rbt2+zj3/NNdfovPPO09KlS3XDDTe0OI4111xT48ePX+X6YcOGZf1vbIpgCADFpqqq8XOCIQCgWOV5+sSuu+6qoUOHaqeddtK6664rSTrvvPP07rvvqlOnTrr66qs1YcIEXXHFFerVq5cOP/xwSb5YzKmnnqoQgnr06KGbbrqp2ccfNGiQ7rnnnpyMNRcIhgBQbKJgaCZNnx7vWAAAyJdo+kQOrb/++nrggQckSb9rpur4hz/8YZXrDjjggBW+3mabbfTss8+ucr9cO+KII3L6eARDACg2UTDcbDMqhgAApEjUMnrXXXe1et/TTz89p8+dmH0MAQA5MnWqX263HcEQAAC0CcEQAIpNVZXUt6+v1DZjRuNqbQAAAC0gGAJAsamqktZeWyovl5Yvb1yhFAAAoAUEQwAoNk2DoUQ7KQAAaBXBEACKTRQMKyr8a1YmBQAgVRYtWqRnnnmm2dteeeUVvfDCCzl/ToIhABST+npp2jQqhgAApMA777yjPffcU7vssoteeuklSb5x/Zw5czRmzJj/3W/ChAkaNmyYhg0bpmOOOUbHH3/8/75uKUC2F9tVAEAxmT7dwyHBEACArN1zzz3afvvtte22265w/RVXXKFdd91VI0eOzOrxr7jiCv31r39V9+7ddcABB2j//ffX559/vsr99t57b+2999568cUXdeWVVyqEoJ/97Gfafffds3r+pqgYAkAxifYwbBoMaSUFABSxaQumaa+79lL1wuqcPm4IQSeccMIqoTCX6urqVFFRob59+2rgwIE66qijVBFNBWni5ptv1kknnaTXX39djzzyiMaOHasnnnhChx12mK699tqcjIWKIQAUk6bBsFs337aCiiEAoIiNfmG0XvryJY1+frR+d9Dvsnqszz//XGeffbY6d+6sPffcU3PmzPlfZfDmm2/WvffeqwEDBqhHjx7addddJUk33nij7r//fg0aNEg9e/bU9773PY0cOVK33nqrxowZo4aGBl1yySU64IADVnm+0GRLqT59+mjIkCHq2bPnCveZOXOmhg4dqqFDh0qSpkyZIkk68MADdeCBB2rRokWaMWOGyqMTwh1EMASAYtI0GEpeNSQYAgBS6JwnztGU6imrvc+y5cv0+levqyE06JY3btHk6snq2qlri/fffvD2unHkjat9zHfeeUfvvvuuunfvriuuuEKS9J///EePP/64Xn75ZZWVlemQQw6RJH344Yd66qmnNHHixGavf+GFF1RXV6fhw4c3GwzN7H+fz5gxQ/fdd5+++uqrFe6zYMECffzxx6sd8wYbbEAwBAA0UVUlderUuCIpwRAAUMS+mPfF/6puIQR9MfcLbTJwk6wec4cddlD37t1XuG7KlCkaNmyYOnXqJEnaaaedJElvvvmm9t9///9dv+OOO/7v+jfffFP77LOPJKmmpkbLly9X584rxq+1115bkyZNUt++fdWtWzdtueWWq1QMN9hgA/Xs2VPHHnvsKmPt3bu3Hn744az+vRGCIQAUk6oqqbLSw6HkAbGZSewAACRda5W9aQumacObNlRQJhgqaM7SOXrgyAc0uPfgDj/vyuFNktZbbz099NBDOvfcc1VfX68XX3xRu+22m9Zdd109+OCDOuecc1RfX68XXnhBu+++uzbddFPttddeuv322yVJixcvbvZxr7nmGl1yySVauHChbrnlFq299trq37//Kvdbc801NX78+FWuHzZsWIf/nSsjGAJAMYn2MIyUl0v/+ld84wEAIE9GvzBaDaFhhevqQ31O5hqubJdddtG6666rnXfeWYMHD9Z6660nSdp111213nrraeedd9baa6+tyspKde/eXdtvv73WXXdd7bbbburbt68OPvhgnXnmmas8bt++fXXTTTfldKwdRTAEgGJSVSVtsUXj11EraQhSk3kMAACk3StTX1Ftfe0K19XW12ri1Ikdfsz1119fDzzwwP++juYYStKvf/3rZr/nuuuuU+fOnbVs2TINGzZMW265pSTpsssu02WXXdbhsbTFEUcckbPHIhgCQDGpqpKatpVUVEjLl0tz50oDBsQ2LAAAcm3y9yfHPQQtX75cBx10kGpra7Vs2TL94Ac/aHa7ifaIWkbvuuuuVu97+umnZ/VcTREMAaBYLFwozZ+/aiup5FVDgiEAADnVuXNnPfnkk3EPIyfY4B4AisXKW1VIKwZDAACAFhAMAaBYNBcMo3aW6dMLPx4AADqg6abv6JiO/AwJhgBQLKgYAgBSrnv37po1axbhMAshBM2aNWuVvRhbwxxDACgWBEMAQMoNGTJEU6dO1Qzet7LSvXt3DRkypF3fQzAEgGJRVSX16yf16tV4XbduUp8+tJICAFKhS5cu2mCDDeIeRkmilRQAisXKm9tHKiqoGAIAgNUiGAJAsWgpGEab3AMAALSAYAgAxaKqSmpuPgHBEAAAtIJgCADFoL5eqq5uuZWUOYYAAGA1CIYAUAxqajwcttRKOnOmxNLfAACgBQRDACgGU6f6ZUvBsK5OmjevsGMCAACpQTAEgGLQ3B6GkYoKv6SdFAAAtIBgCADFYHXBkE3uASBZpk2T9trL54YDCUEwBIBiUFUldenSGAKbIhgCQLKMHi299JJfAglBMASAYlBVJVVWSmXNvKzTSgoAyfHVV9If/yg1NEh33knVEIlBMASAYtDS5vYSFUMASJLLLvNQKPlq0lQNkRAEQwAoBqsLht26SX36EAwBIG7Tpkn33tv4dW0tVUMkBsEQAIrB6oKh5FVDWkkBIF6jRzdWCyNUDZEQBEMASLv586WFC1cfDCsqqBgCQNxeecX3lW2qtlaaODGe8QBNEAwBIO1Wt1VFpLycYAgAcZs8Wbr5Zv+8e3evHobg1wMxIxgCQNq1NRjSSgoA8YvmEy5dKs2bF+9YgCYIhgCQdm0JhhUV0syZfmYaABCfmprGz6dNi28cwEoIhgCQdm2tGNbVcXYaAOJGMERCEQwBIO2qqqQBA6QePVq+D3sZAkAyVFdL663nnxMMkSAEQwBIu9a2qpC8lVRiniEAxK2mRtp+e/+cYIgEIRgCQNq1JRhSMQSA+IXgFcNNNvEuD4IhEoRgCABpRzAEgHSYP19atkwaPFiqrCQYIlEIhgCQZsuXe1tSW4MhraQAEJ9oq4o11yQYInEIhgCQZtXVvkFya8Gwe3epTx8qhgAQp2hFUiqGSCCCIQCkWVu2qoiUlxMMASBOUTCkYogEIhgCQJq1NxjSSgoA8YlaSaOK4fz50uLF8Y4JyCAYAkCatScYVlRQMQSAONXUSJ06SQMHejCUqBoiMQiGAJBmVVVSly7SoEGt35dWUgCIV3W1n6QrK2sMhlEVEYgZwRAA0izaqqKsDS/nUTAMIf/jAgCsqqbG5xdKVAyROARDAEiztuxhGKmokOrqpHnz8jsmAEDzCIZIMIIhAKRZe4Ihm9wDQLyqq33hGcnnGXbuTDBEYhAMASCtQiAYAkBahLBixbCszEMiwRAJQTAEgLSaN09atKh9raQSW1YAQBzmzpVqaxsrhhJ7GSJRCIYAkFbt2apComIIAHFqurl9hIohEoRgCABpRTAEgPRourl9hIohEiQRwdDMys3sajMbvdL165jZV2Y2IfOxZeb6w83sRTN7zcy+Hc+oASBm7Q2G3btLffrQSgoAcWiuYlhZ6Sfr6uriGRPQROe4B5BxvaSPJfVc6fr+kh4MIZwbXWFmvST9SNJ+8vG/ZGZjQwhLCzRWAEiGKBiutVbbv4dN7gEgHi0Fw+i2IUMKPyagiURUDEMIJ0h6oZmb+kuas9J1u0p6JoSwLISwSNJrkjbP7wgBIIGqqny58+7d2/49BEMAiEd1tW9PscYajdexlyESJBHBcDV6SjrCzF42sxvNrIukCklNj2pmSRrQ3Deb2almNsnMJs3gQAhAsWnPVhWR8nJaSQEgDjU1vjp0WZPDb4IhEiTRwTCE8GQIYTtJe0haIGmUpHlaMQgO0IpBsen33xpCGBpCGFoeLboAAMWiI8GwooKKIQDEoenm9hGCIRIk0cHQzDpLUgihQV4ZlKTXJY00sy5m1lPS1pI+iGmIABCfjlYMZ8zwjZYBAIXTdHP7yJprSmaNK5YCMUpkMDSza82sq6SjzOwlM3te0g6S7gghzJR0l6SXJD0m6fIQwvL4RgsAMair85bQjgTDujpp3rz8jAsA0Lzq6lWDYZcu0qBBVAyRCElZlVQhhAmSJmQ+vzBz9f2Zj5Xve5uk2wo1NgBInGnTvOrXkVZSyauG/fvnfFgAgGaE4CfzVm4lldjLEImRyIohAKAV7d3DMMIm9wBQeHPmeLfGyhVDiWCIxCAYAkAaEQwBID2iOYRUDJFgBEMASKOOBsOolZQtKwCgcJrb3D4yeLAHx4aGwo4JWAnBEADSqKpK6tbNN7hvDyqGAFB4rVUMly+XZs1a9TaggAiGAJBGVVXSWmv5Muft0b271Ls3wRAACml1FUP2MkRCEAwBII06sodhpKKCVlIAKKSaGt+aYsCAVW8jGCIhCIYAkEbZBMNok3sAQGFEexg21+VBMERCEAwBIG1CIBgCQJrU1DTfRioRDJEYBEMASJu5c6UlS7ILhrSSAkDhVFc3v/CMJPXsKfXtSzBE7AiGAJA2Hd2qIlJR4RXDEHI3JgBAy1ZXMZTYyxCJQDAEgLTJNhiWl0t1ddL8+bkbEwCgeQ0NHgxbqhhKHgyjLS2AmBAMASBtchEMJdpJAaAQZs+W6uupGCLxCIYAkDZRMFxrrY59f0WFX7IADQDk3+r2MIxEwZAWf8SIYAgAaVNV5VW/bt069v1RxZBgCAD5F7WIttZKunixtGBBYcYENINgCABpk81WFRKtpABQSG2tGEq0kyJWBEMASJupU3MTDKkYAkD+taViGN1GMESMCIYAkDbZVgx79JB69yYYAkAh1NRIXbtK/fq1fB8qhkgAgiEApMmyZR7osgmGklcNCYYAkH/V1d5GatbyfQiGSACCIQCkSXTQkG0wrKhgjiEAFEJrexhKUv/+vqAYwRAxIhgCQJpku4dhhIohABRGTc3qF56RvJrIXoaIGcEQANKEYAgA6VJd3XrFUCIYInYEQwBIk1wGw+nT2UwZAPKpvt5PwrVWMZQIhogdwRAA0qSqSureXRowILvHqaiQ6uqk+fNzMy4AwKpmzfJwSMUQKUAwBIA0ibaqWN3qdm3BXoYAkH9t2dw+UlkpzZ0rLV2a1yEBLSEYAkCaZLuHYSQKhqxMCgD5095gKPmcRCAGBEMASJNcBcOKCr+kYggA+ROFvLa2kkq0kyI2BEMASIsQcl8xJBgCQP50pGJIMERMCIYAkBazZ0vLltFKCgBpUV3tC4b17dv6fQmGiBnBEADSIldbVUhSjx5S795UDAEgn6LN7duyYNigQVJZGcEQsSEYAkBa5DIYSmxyDwD51tbN7SWpUycPkQRDxIRgCABpQTAEgHSJKoZtxV6GiBHBEADSIgqG0TyUbFVUMMcQAPKJYIgUIRgCQFpUVXmY69o1N49HxRAA8qe+3l9j29pKKhEMESuCIQCkRa62qohEwTCE3D0mAMDNnCk1NLS/Yjh9urR8ef7GBbSAYAgAaZGPYFhbK82fn7vHBAC49mxuH6ms9JN1tPkjBgRDAEiLXAfDigq/pJ0UAHKvPZvbR9jLEDEiGAJAGixb5m1Jua4YSgRDAMiHqGLYkWAYfS9QQARDAEiDr77yy3wEQ1qWACD3oophe1tJJSqGiAXBEADSINd7GEq0kgJAPtXUSD16SL17t/17ohBJMEQMCIYAkAZRMBwyJHePSSspAORPdbUHPbO2f0/XrtLAgQRDxIJgCABpkI+KYY8eUq9etJICQD60d3P7CHsZIiYEQwBIg6lTpZ49pX79cvu4FRVUDAEgH6KKYXsNHkwwRCwIhgCQBtFWFe1pSWqLaJN7AEBuUTFEyhAMASANcr2HYaS8nFZSAMi15ct9i6GOBsPqat/oHigggiEApEG+giGtpACQezNmeLDrSCtpZaVUWyvNnp37cQGrQTAEgKQLwfcxzFfFMDqAAQDkRrSHYUcrhhLtpCg4giEAJN3MmX72OF/BsLZWWrAg948NAKWqutovO1oxlAiGKDiCIQAkXT62qohEexkyzxAAcoeKIVKIYAgASZfPYFhR4ZfMMwSA3IkqhgRDpAjBEACSrhAVQ4IhAOROTY3Uq5fUu3f7v7d3b/+IwiVQIARDAEi6qirfv7Ajc1VaQyspAOReR/cwjLCXIWJAMASApKuq8gOMLl1y/9hUDAEg96qrszuZRzBEDAiGAJB0+drDUJJ69vR2J4IhAOQOFUOkEMEQAJIun8FQ8qohraQAkDtUDJFCBEMASLp8B8OKCiqGAJArdXXSrFnZVQwHD5YWLvQPoEAIhgCQZEuWSLNn579iSDAEgNyIOjCybSWVqBqioAiGAJBkX33ll7SSAkA6RJvbZ9tKKhEMUVAEQwBIsnzuYRiJWklDyN9zAECpiIIhFUOkDMEQAJKsEMGwvFyqrZUWLMjfcwBAqYg2pqdiiJQhGAJAkhUqGErMMwSAXMhFxXCNNaSuXQmGKCiCIQAkWVWV7zPYt2/+niMKhswzBIDsVVdLffr4PrEdZeYVR4IhCohgCABJFm1VYZa/56io8EsqhgCQvWw3t4+wlyEKjGAIAEmW7z0MJVpJASCXqqtzFwyj+YpAASQiGJpZuZldbWajV7p+WzN7ysxeNLOHzKxr5vo7zGyimU0ws+viGTUAFEAhgyGtpACQvZqa7BaeiVAxRIElIhhKul7SMkldVro+SDokhLCHpC8kHZa5vr+kA0IIe4cQLijYKAGgkBoafB/DfAfDnj19HiMVQwDIXi5bSWfN8lWjgQJIRDAMIZwg6YVmrn87hLAs8+UcSYsyn/eRNL9AwwOAeMycKdXVSUOG5P+5yssJhgCQrdpaafbs3FUMJdpJUTCJCIatMbOvSdpK0pOZq4KkCZk20z1W832nmtkkM5s0gwMeAGlTiK0qIuXltJICQLai19FcVQwl2klRMJ3jHsDqmJlJulDeYnpCCKFekkIIIzK3ryPpUUnbNvf9IYRbJd0qSUOHDg2FGDMA5MzUqX5ZiGBYUeFtqwCAjsvF5vaR6DEIhiiQpFcMT5M0LYQwOgqFkmRmUaCdI6kulpEBQL4VumJIZwUAZCcXm9tHqBiiwBJZMTSzayVdKukQSf3N7KTMTeNCCL+W9EQmHHaSdFFMwwSA/KqqksrKcnOA0ZqolTSE/O6ZCADFLJfBsKLCX48JhiiQxATDEMIESRMyn1+YufrAFu47rDCjAoAYVVV5K1HnArxUV1T4ogkLFkh9++b/+QCgGEWtpLkIhp07+2szwRAFkvRWUgAoXYXYwzDCJvcAkL2aGj+51qNHbh6PvQxRQARDAEgqgiEApEt1dW4WnokQDFFABEMASKo4giFbVgBAx+Vqc/sIwRAFRDAEgCRavFiaO7dwwbCiwi+pGAJAx1VX5z4Y1tRI9fWt3xfIEsEQAJKokFtVSLSSAkAu1NTkvpW0oUGaOTN3jwm0gGAIAElU6GDYs6d/0EoKAB2zbJl3euS6YijRToqCIBgCQBIVOhhK3k5KxRAAOibawzDXFUOJYIiCIBgCQBLFEQzLywmGANBRudzcPkIwRAERDAEgiaqqpD59/KNQystpJQWAjoo2t89lxTB6LIIhCoBgCABJVMitKiK0kgJAx+WjYti9u9S/P8EQBUEwBIAkiiMYRq2kIRT2eQGgGEQVw2j7n1xhL0MUCMEQAJIormC4bJm0YEFhnxcAikFNjVf3unfP7eMSDFEgBEMASJqGBj8IiKOVVKKdFAA6oqYmt22kEYIhCoRgCABJM326tHx5PBVDiWAIAB1RXZ3bhWciUTCkzR95RjAEgKSJY6sKqTEYsjIpALRfPiuGy5ZJc+fm/rGBJgiGAJA0cQdDKoYA0H75rBhKtJMi7wiGAJA0BEMASJelS6X58/NXMZQIhsg7giEAJE1VldSpU34OMFanVy+pZ0+CIQC0Vz72MIwQDFEgBEMASJqqKm9H6tSp8M9dXs4cQwBor2gPw3y2kkbPAeQJwRAAkiaOPQwjFRVUDAGgvfJZMezTx7s5qBgizwiGAJA0cQbD8nKCIQC0Vz4rhmbsZYiCIBgCQNJUVUlDhsTz3LSSAkD7RRXDior8PD7BEAVAMASAJFm4UJo3L/5WUjZSBoC2q66WBgyQunbNz+MPHkwwRN4RDAEgSeLaqiJSXu4bKS9cGM/zA0Aa1dTkp400QsUQBUAwBIAkSUIwlGgnBYD2qKnJ7xZDlZW+T+Lixfl7DpQ8giEAJEncwTCaH8MCNADQdtXV+a8YSlQNkVcEQwBIkriDYVQxJBgCQNsVomIoEQyRVwRDAEiSqiqpXz+pV694np9WUgBon8WLpQULqBgi9QiGAJAkce5hKFExBID2yufm9hGCIQqAYAgASRJ3MOzVS+rZk2AIAG0VbW6fz2A4cKDUuTPBEHlFMASAJIk7GEpeNSQYAkDbRBXDfLaSlpWxlyHyjmAIAElRX+9nnpMQDJljCABtU4hWUsnbSaPqJJAHBEMASIqaGg+HcQfDigoqhgDQVlFYi7b7yRc2uUeeEQwBICni3qoiQispALRdTY3PAezSJb/PQzBEnhEMASApkhQMp0+XQoh3HACQBvne3D5SWekn7erq8v9cKEkEQwBIiqQEw4oKadkyaeHCeMcBAGmQ783tI1H4jOY0AjlGMASApKiq8uXI8z1PpTXsZQgAbVddXZhgyF6GyDOCIQAkRVWVv/GXxfzSHAVDViYFgNbV1BSulVQiGCJvCIYAkBRJ2MNQaqxYUjEEgNVbuFBatIiKIYoCwRAAkiIpwZBWUgBom0Jsbh9Zc03JjGCIvCEYAkBSJC0Y0koKAKtXqM3tJd8OY9AggiHyhmAIAEmwYIF/JCEY9uol9ehBxRAAWhNtbl+IYCixlyHyimAIAEmQlK0qIhUVBEMAaE0hW0klgiHyimAIAEmQtGBYXk4wBIDW1NT4vL+oBT/fCIbII4IhACRBEoMhcwwBYPWqq33eX+fOhXm+ykoPow0NhXk+lBSCIQAkQdKCIa2kANC6mprCzS+UPBguXy7NmlW450TJIBgCQBJUVUn9+0s9e8Y9Ehe1koYQ90gAILmqqws3v1BiL0PkFcEQAJKgqkoaMiTuUTQqL5eWLvXNmwEAzYujYigRDJEXBEMASIKpU5PTRip5K6lEOykAtCQErxgWMhhG1UmCIfKAYAgASZCUze0j0Qp7BEMAaN7ChdKSJbSSomgQDAEgbsuXeztSEoMhK5MCQPOiPQwLWTHs2VPq25dgiLwgGAJA3KqrfenxJAVDWkkBYPWqq/2ykBVDib0MkTcEQwCIW9K2qpBoJQWA1sRRMZQIhsgbgiEAxC2JwbBXL6lHD1pJAaAlVAxRZAiGABC3JAZDqXEvQwDAqmpqpLIyadCgwj5vFAzZZxY5RjAEgLhVVUlduhT+4KI1FRUEQwBoSXW1v2536lTY562s9NVQ588v7POi6BEMASBuVVXSWmv5meckKS+nlRQAWlJTU/g2UoktK5A3CTsKAYASlLQ9DCO0kgJAy2pqCr/wjNQYDKM5jkCOEAwBIG5JDYZRKynzWABgVdXVVAxRVAiGABCnEJIbDMvLpaVLpUWL4h4JACRLCPFXDAmGyDGCIQDEaf58D15JDYYS8wwBYGXz5/uJsziCYb9+UvfuBEPkXNbB0MyeMrMEHtEAQAokdasKyVtJJeYZAsDKos3t42glNfPnJRgix9odDM3sMjPbr8lVwyT1yt2QAKCEJDkYRhVDgiEArCgKhnFUDCU2uUdedKRiuI+k/Vq9VzuYWbmZXW1mo1e6vreZ3W9mL5jZw2bWN3P94Wb2opm9ZmbfzuVYAKCg0hAMaSUFgBVFK4LGUTGUCIbIi3YFQzPrKWlXSS/keBzXS1omqctK158r6Z8hhD0lPS3pdDPrJelH8krlvpJ+YmbdczweACiMKBiutVa842gOraQA0DwqhihC7a0YHiNpvqTncjmIEMIJaj5s7ivpL5nP/yZpN3kwfSaEsCyEsEjSa5I2z+V4AKBgqqqkNdaQevSIeySr6tXLx0UwBIAVVVdLnTpJAwfG8/yVldLcudKSJfE8P4pSm4OhmXWT9FNJN4UQluVvSCvoFkKoy3w+S9IASRWSmh6lRNevwsxONbNJZjZpBgc2AJIoqVtVRMrLaSUFgJXV1PjrY6dO8Tw/m9wjD9pTMfyVpB6SfpunsTSnwcyiMQ6QB8J5WjEIRtevIoRwawhhaAhhaHk0VwYAkiQNwZATawCwourq+NpIJfYyRF60GgzNrLuZ3SDpNEknhxDmN3O3kPORudckHZb5/AhJ4yW9LmmkmXXJzHncWtIHeXp+AMivpAfDigqCIQCsrKYmvoVnJIIh8qJzSzeY2WGSzpK0naSekr4XQniyhbvfbmaLWrjtxRDCL9ozKDO7VtKlkn4haYyZnS3pY0lnhBCWmdldkl6StETS5SGE5e15fABIhLo6P7hIcjAsL5feeSfuUQBAstTUSFtsEd/zEwyRBy0Gw8xtPSV1k1QvafFq7ttdUkMLt3Vty0BCCBMkTch8fmHm6pmSDmjmvrdJuq0tjwsAiVVdLYWQ/GA4Y4aP0yzu0QBA/ELw1+84K4bR/EbmGCKHWgyGIYS/SfpbZu/A30j6s5nNCCE838zdjw8h/CdfgwSAopTkPQwjFRXS0qXSokVS795xjwYA4jdvnlRbG+8cw7Iyf34qhsih1VUMJUmZOYUnmVlXeVvnFpltIgAA2UhDMIwW7poxg2AIAFL8m9tH2MsQOdaeVUm/n7n/WXkaCwCUljQFQ7asAAAX9+b2EYIhcqzNwTCEsFDSVZLONbME7sQMAClTVSV17SoNGhT3SFpWUeGXrEwKAC6qGMYdDAcPJhgip9pTMZSkuyX1knRgHsYCAKVl6lSvFiZ5UZemraQAgMaKYRJaSadPl5azOD9yo13BMISwRNJzIhgCQPaSvoehRCspAKyspsZXBF1jjXjHUVnpK6Ty+owcaW/FUPJg+HiuBwIAJScNwbBXL6lHDyqGABCprvY20rKOHEbnEHsZIsfa/RsdQrg+hPDXJlc9r9XvcQgAWFkI6QiGZo17GQIAvGIY9/xCiWCInGt1u4rWhBD2ycVAAKCkzJ0rLVmS/GAoeTCkVQkAXFQxjBvBEDkWcw0cAEpUGraqiFAxBIBGNTXxLzwjNY6BYIgcIRgCQBzSFAwrKgiGACD5NICktJJ27SoNHEgwRM7kLRiaWT8zOzVfjw8AqZamYBi1koYQ90gAIF5z5kh1dcmoGEpsco+canGOoZl9Jqm9RwGTQwhHZD4fLOkPkm7t4NgAoHhFwXCtteIdR1uUl0tLl0qLFkm9e8c9GgCIT7SHYRIqhpIHw+rquEeBIrG6xWeeVPPB8EhJn0ua1Mxtn+ZgTABQ/KqqpEGDpG7d4h5J6yoq/HLGDIIhgNIWhbAkVQw//DDuUaBItBgMQwinNXe9me0q6Z8hhJ/lbVQAUOzSsFVFpOkm9xtsEO9YACBOSa0YhuDbCwFZYPEZAIhDGoMhC9AAKHVRxTBJwbC2Vpo9O+6RoAgQDAEgDmkKhk1bSQGglNXUSF26SAMGxD0Sx5YVyKHVBkMz28DMuqx09RxJi/M3JAAocrW13paZlmBIxRAAXE2NnywrS0hthU3ukUOrW3xGkh6StI2ZTZB0t6QHQgj75n1UAFDMojfwtATDXr2k7t09zAJAKauuTs7CMxLBEDnVltMd/5IHyDGS3jWzr+d3SABQ5NK0h6HkCxqwyT0AJGdz+wjBEDnUlmD4XAhhmKStJH0i6Tkz+1F+hwUARSxtwVDydlKCIYBSl7SKYe/e/kEwRA60uUE6hPBhCOEQST+WdI2ZsV0FAHREWoMhraQASllDg78OJqliKHnVkGCIHGhtjuEqQgg3mtkCSbeZ2echhD9JkpndK2nbJnftmqMxAkBxqaryje3XWCPukbRdebn03ntxjwIA4jN7trR8OcEQRavdwVCSQgh3mNlmkn5nZi+HED6U9IGkupXu+kq2AwSAohNtVZGmzYijOYZsogygVEWb2yeplVTyYPjGG3GPAkWgQ8Ew42JJB0i6TdKeIYSrcjMkAChyadrDMFJeLi1ZIi1a5PNZAKDURMGQiiGKVIc3YQkh1Ek6X9LXzOyg3A0JAIpcWoOhxAI0AEpXdbVfJrFiuGiRtHBh3CNByrUWDPeWdHVLN4YQnpI0RdJ6uRsSABSxENIZDCsq/JJgCKBUJbliKFE1RNZW20oaQljUhscYHkKYlaPxAEBxmzNHWro0fcEwqhiyMimAUlVdLXXtKvXvH/dIVtQ0GG6ySbxjQap1uJU0QigEgHZI41YVEq2kABBtbp+0Bbii1lYqhshS1sEQANAOUTAcMiTecbQXraQASl11dfLaSCVaSZEzBEMAKKSpU/0ybRXDXr2k7t0JhgBKV01N8haekXxP3K5dCYbIGsEQAAopqhhGZ3jTwszbSZljCKBURa2kSWPmgZVgiCwRDAGgkKqqvC2za9e4R9J+0Sb3AFBqGhr8xFgSK4YSexkiJwiGAFBIadyqIlJeTjAEUJpmzZLq65NZMZQIhsgJgiEAFFLagyGtpABKUbS5PcEQRYxgCACFlPZgSMUQQCmKNrdPcivp7NnSsmVxjwQpRjAEgEJZtkyaOTO9wbCiQlqyRFq0KO6RAEBhRcEwyRVDqbGyCXQAwRAACuWrr/wyrcEw2uSedlIApSYKXEmuGEq0kyIrBEMAKJRoq4q0B0PaSQGUmpoaqVs3qW/fuEfSPCqGyIHOLd1gZs/m6Dm+DCF8N0ePBQDplfZgWFHhlwRDAKWmutqrhWZxj6R5VAyRAy0GQ0mLJYVmru8paW9JEzL3aU1b7gMAxS/twZBWUgClKqmb20cqKqSyMoIhstJiMAwhHNzc9Wa2saQPJY0KIXyar4EBQNGpqpJ69JD69497JB1DKymAUlVdLa23XtyjaFmnTv4aTTBEFjoyx7C5KqIkySyp9XUASIBoq4q0vlT27i11704wBFB6amqSu/BMhL0MkaVWg2Fbw56Z/UXSTVmPCACKVZr3MJQ80LKXIYBSU1/vr3tJbiWVCIbI2mqDoZldLunNNj7WfEnlWY8IAIpV2oOh5MGQOYYASsnMmVJDAxVDFL2OblfRXBVxsaSEruELADELwfcxTHswrKigYgigtCR9c/tIZaWPtb4+7pEgpToSDKsk7ZO5bKpWUo+sRwQAxWjWLGnZsvQHQ1pJAZSaaG/ANATDhgZeo9Fh7Q6GIYSlIYTnQwjLVrqpTlKX3AwLAIpM2reqiNBKCqDURBXDNLSSSrSTosM62kranPocPx4AFI9iCoZLlkiLFsU9EgAojDRVDCWCITosl0GuIcePBwDFo1iCYUWFX9KqBKBU1NT4HrR9+sQ9ktUjGCJLuQ5yKd2cCwDyrKrKt3uI3rjTKtrknnZSAKWipsarhUnfgzZqdSUYooM6t+E+/c3seLUe+rZpw30AoDRVVXm1rUvKp2JHwZCKIYBSUV2d/PmFktS9uzRgQGPrK9BObQmGQyTd3cbHm5TFWACgeBXDHoYSraQASk9NjbThhnGPom3YyxBZaC0YXifp5nY8Xl0WYwGA4lVVJa23XtyjyB6tpABKTXW1tNtucY+ibQiGyMJqg2EIYYmkJQUaCwAUr6oqaffd4x5F9nr3lrp1o2IIoDQsXy7NnJmOVlLJx/nyy3GPAinFKqIAkG9Ll/oG98XQSmrm7aQEQwClYOZMKYTkb1URiSqGIcQ9EqQQwRAA8i3aqmLIkHjHkStscg+gVEQLuaSlYlhZKS1bJs2dG/dIkEI5D4ZmNsTMnsr14wJAahXLHoaR8nIqhgBKQ02NX6apYigxzxAdko+KYS9J++XhcQEgnYotGNJKCqBUpLFiKBEM0SFt2a5CkmRm5ZK2k4fJt0IIbJICAG1RbMGQiiGAUkHFECWk1YqhmXUzszskfSXpSUlPSJpqZmPMrFe+BwgAqVdVJfXqJfXtG/dIcqO8XFq8WFq0KO6RAEB+VVdLPXv6isxpQDBEFtpSMXxA0v6Srpb0dOZ7DpF0pqRKM9s/BJY+AoAWRZvbm8U9ktxousl9L84PAihiNTXpaSOVpD59PMgSDNEBqw2GZjZSHgL3DSG80OSm581soqS/Sjpa0v35GyIApFwUDItFtMn9jBnS+uvHOhQAyKuamvS0kUp+ApJN7tFBrbWSflfSfSuFQklSCOHvkh6XdGIuBmJmo83seTN72cy2anL97WY2IfPxbzP7e+b6O8xsYub663IxBgDIi2INhmxZAaDYVVenq2IoEQzRYa21kv6fpPNWc/vDkq7NdhBmtoekNUMIe5nZ1pJ+KelASQohnNLkfjdJGpP5sr+kA0II87J9fgDIm4YG6auvijMYsgANgGJXUyPtsUfco2ifykrprbfiHgVSqLVgOFjSZ6u5/RNJ/c3saUnRPMOeHRjHcGXaUUMI75jZGivfwczWk1QRQvhX5qo+kuZ34LkAoHBmzpTq6oorGDadYwgAxaquzl/D09RKKnkwfPLJuEeBFGqtldTUGPhWp6ukLk0+2qtCUtMjjOVmtvLYzpP0myZfB0kTzOypTMVxFWZ2qplNMrNJMziAARCHYtuqQvLV+bp1o5UUQHGLjh3T2Eo6f76vHg20Q2sVw2pJG0hqqR69gaR5IYS9oivMbHNJ77ZzHPMkDWjydUMIoaHJY3aXtH0I4ezouhDCiMxt60h6VNK2Kz9oCOFWSbdK0tChQ1k5FUDhFWMwNGMvQwDFL9rcPm0VwyjITpsmbbRRvGNBqrRWMXxd0uGruf3QzH2a6kgAe1HSkZJkZltKmrrS7QdIGt/0CjOLQu0cSXUdeE4AyL9iDIaSt5MSDAEUs2hz+zRWDCUWoEG7tRYM75F0rJntsvINZjZC0kGS7svBOB6V1NXMXpT0K0kXmtm1ZtY1c/vekl5e6XueMLMJ8pVRL8rBGAAg96qqpLKy9B1YtKa8nFZSAMUtCoZpqxgSDNFBq20lDSE8amZPSHrSzH4mr9qVSTpY0k8kvSbp3mwHkWkbPX2lqy9scvvZK92mEMKwbJ8XAPKuqsoPKjq31rmfMuXl0gcfxD0KAMiftLaSEgzRQW05Uvm2pNvlW0hETNI4SSc1nQsIAFhJse1hGKGVFECxq6nxxbZ69Yp7JO0zcKCfjCQYop1aDYYhhCXydtILJe0orxi+GUJY3TYWAADJg2ExTv4vL/cV7xYtSt9BEwC0RXV1+qqFUuP0BYIh2qnNvU0hhKladVEYAMDqVFVJe+4Z9yhyr+km9wRDAMWopia988MrKwmGaLfWFp/piMWSXsjD4wJAuixZIs2ZU7ytpBLtpACKV01NOiuGEsEQHZLzYBhC+G8IYZ9cPy4ApE6xblUhrVgxBIBiVF1NxRAlJR8VQwCAVBrBkC0rABSj2lpp9ux0VwxnzvR/B9BGBEMAyJdSCIZUDAEUo+ikV5orhhIn79AuBEMAyJdiDoZ9+kjduhEMARSntG5uH2EvQ3QAwRAA8qWqyvfA6ts37pHknplXDTkbDaAYpXVz+wjBEB1AMASAfCnWze0j5eVUDAEUp6himNZW0mjcBEO0A8EQAPKl2INhRQXBEEBxSnsr6ZpremcHwRDtQDAEgHyZOlUaMiTuUeQPraQAilV1tU8D6NEj7pF0TJcu0qBBBEO0C8EQAPKhocHfkIu5YkgrKYBilebN7SPsZYh2IhgCQD5Mny4tX17cwbCiQlq8WFq0KO6RAEBuVVcTDFFyCIYAkA/FvFVFhL0MARSrmpr0LjwTIRiinQiGAJAPBEMASK9iqRjW1PjUBqANCIYAkA+lEAwrKvySYAigmCxbJs2dWxwVw+XLpZkz4x4JUoJgCAD5UFUldeqU/jPOq0PFEEAxilZbTvvrN5vco50IhgCQD1VVfra5U6e4R5I/UTBkywoAxaS62i+LoWIoEQzRZgRDAMiHYt/cXpL69JG6dqViCKC4pH1z+0gUDKOgC7SCYAgA+VAKwdDM5xkSDAEUkyhIFUswpGKINiIYAkA+lEIwlLydlFZSAMWkWCqGPXpI/foRDNFmBEMAyLVFi6R580onGFIxBFBMqqs9UHXvHvdIsjd4MMEQbUYwBIBcK4WtKiK0kgIoNsWwuX2ETe7RDgRDAMi1UgqGtJICKDY1NelvI40QDNEOBEMAyLVSC4aLF/sHABSD6uriqxiGEPdIkAIEQwDItVIKhhUVfkk7KYBiUWwVwyVLpPnz4x4JUoBgCAC5VlUl9e0r9e4d90jyj03uARSTpUt98bBiCoYS7aRoE4IhAORaqWxVITUGQyqGAIpBtFVFMbWSSgRDtAnBEAByrZSCIa2kAIpJsexhGCEYoh0IhgCQa6UUDKkYAigm1dV+ScUQJYhgCAC5VF/vb8ClEgz79JG6dmWOIYDiUGwVw379pO7dCYZoE4IhAOTS9OkeDkslGJp51ZCKIYBiEFUMozb5tDPzqmH07wJWg2AIALlUSltVRCoqCIYAikNNjTRggNStW9wjyR02uUcbEQwBIJdKMRiWl9NKCqA4VFcXTxtphGCINiIYAkAulWowpGIIoBjU1BTPwjORwYMJhmgTgiEA5FJVldSpU/HMT2kLWkkBFIuamuKsGM6dKy1ZEvdIkHAEQwDIpalT/U24U6e4R1I45eXSokXS4sVxjwQAslNdXXwVw2jLChagQSsIhgCQS1VV0pAhcY+isNjLEEAxWLxYWrCgOCuGEu2kaBXBEAByqZQ2t49EbbMEQwBpVmx7GEYIhmgjgiEA5FIpBsOoYsjKpADSLAqGxdpKSjAsnGnTpL32Sl37LsEQAHJlwQL/KNVgSMUQQJpFB/HFVjEsL/d57wTDwhk9WnrpJb9MEYIhAORKKW5VIdFKCqA4FGvFsKzMwy7BsDCmTZNuv11qaJDuvDNVVUOCIQDkSqkGwz59pK5dCYYA0i0KhsW43RCb3BfOxRdLdXX+eX19qqqGBEMAyJVSDYZm3qrEHEMAaVZdLQ0cKHXpEvdIco9gWBjTpkljxjR+XVubqqohwRAAcqVUg6HkwZCKIYA0K8bN7SOVlakJJ6n2059Ky5eveF2KqoYEQwDIlaoqqX9/qWfPuEdSeBUVBEMA6VZdXdzBcPr0VUMLcuvRR1e9rrZWmjix8GPpAIIhAORKKW5VEaGVFEDa1dQU38IzkcpKKQRep/Ppyy+l+fOlU07xn3XTj8mT4x5dmxAMASBXSj0YUjEEkGbF3EoaBV7mGeZP1C566aXxjiMLBEMAyJVSDoYVFdKiRdLixXGPBADab9EiaeHC4q4YSgTDfPnoI19k5rTTpHXXjXs0HUYwBIBcWL7c56eUajBkk3sAaRZtVVGsFUOCYX5dcYXUrZt00UVxjyQrBEMAyIWaGt/MlmAY7zgAoCOiFTuLNRjSSpo/77wj3X+/dNZZqf/9IRgCQC6U8lYVUuOG0ARDAGkUVQyLtZW0a1ffo5FgmHuXXir16SP9+MdxjyRrBEMAyIVSD4ZRxZAV7wCkUbFXDCU2uc+Hf/1Levhh6Uc/ktZYI+7RZI1gCAC5QDD0SyqGANKopkYya3wtK0YEw9y79FKvxJ59dtwjyQmCIQDkQlWV1KVLcR9UrE7fvt6qRDAEkEY1NX6A36VL3CPJH4Jhbr34ovTkk9JPfuLvgUWAYAgAuVBV5W+6ZSX6shqdaaeVFEAaVVcX7/zCSGWl/ztDiHsk6ReCdPHF/jM944y4R5MzJXoEAwA5Vsp7GEbY5B5AWhXz5vaRykqprk6aNSvukaTfU095xfCSS6QePeIeTc4QDAEgFwiGBEMA6VVdXRrBUGpcaAcdE4IHwvXXl045Je7R5BTBEABygWDoW1YQDAGkTQheMSyFVlKJeYbZevhhadIk6fLLfW59ESEYAkC25s+XFi4kGDLHEEAaLVwoLV5cOhVDgmHH1df7SqSbbSYdd1zco8k5giEAZKvUt6qIlJdLixZJS5bEPZLsTZsm7bUXLVdAKSj2ze0j0b+PYNhxDzwgvfuu9LOfSZ07xz2anEtMMDSz0Wb2vJm9bGZbNbl+HTP7yswmZD62zFx/uJm9aGavmdm34xs5gJJHMHQVFX5ZDO2ko0dLL73klwCKWxQMi71i2Lu3fxAMO6auzttHt9tOOvLIuEeTF4kIhma2h6Q1Qwh7Sfq+pF82ubm/pAdDCHtnPt4zs16SfiRpmKR9Jf3EzLoXetwAIIlgGIn2cEx7O+m0adKdd0oNDX5J1RAobtHfeLFXDCX2MszGXXdJn3wiXXVV0W5NlZR/1XBJ90tSCOEdSWs0ua2/pDkr3X9XSc+EEJaFEBZJek3S5gUYJwCsaupUvyQY+mXaK4ajR/uZYUlavpyqIVDsSqViKBEMO2rpUm8f3XVX6aCD4h5N3iQlGFZIanoksdzMorH1lHREpsX0RjPr0sz9Z0kaUJihAsBKqqqkNdYoqr2MOqQYWkmjamF9vX9dV0fVECh21dWSmTRoUNwjyT+CYcf88Y9+Evjqq/13pUglJRjO04rBriGE0CBJIYQnQwjbSdpD0gJJo5q5/wCtGBQlSWZ2qplNMrNJM9J8oAIg2diqwhVDK+no0d5C2lR9PVVDoJjV1PjrVxEuJrIKgmH7LVok/fzn0r77+kcRS0owfFHSkZKUWVxmanSDmXWWpExQnJW5+nVJI82si5n1lLS1pA9WftAQwq0hhKEhhKHl0QELAOQawdD17St16ZLuiuErr0i1tSteV1srTZwYz3gA5F9NTWm0kUoeDBctkhYsiHsk6XHTTX7C86qr4h5J3iUlGD4qqauZvSjpV5IuNLNrzayrpKPM7CUze17SDpLuCCHMlHSXpJckPSbp8hDC8pjGDqDUEQydWfo3uZ88Wfrud6UBA6SXX/br7rvPrwdQnKqrS2PhGYm9DNtr7lzpuut8XuFuu8U9mrxLRM08Uw08faWrL8xc3p/5WPl7bpN0W56HBgCrV1fnZ5sJhi7tm9zX10uPPCIdeKC0yy7SwIHSk09K3/lO3CMDkC81NdImm8Q9isJoGgw33TTesaTB9dd7OCyBaqGUnIohAKRTdbUUAsEwUl6e7orhxInSzJnSYYdJnTpJ++/vwXDleYcAikMI/jpeSq2kEhXDtpgxQ7rxRumoo6Ttt497NAVBMASAbLCH4YrSHgzHjZO6dpVGjvSvR470asJbb8U7LgD5sWCBb0VQaq2krLTcumuvlRYv9m0qSgTBEACyQTBcUZrnGIYgjR0r7bOP1KePXzd8uF8+8UR84wKQP1FAKpWK4YABUrduVAxb89VX0u9+Jx1/vLR56WyVTjAEgGwQDFdUXi4tXCgtWRL3SNrvww+ljz7yNtJIZaW03XbeTgqg+ESb25dKxdDM/60Ew9W76iqfc3755XGPpKAIhgCQjaoqbz0shY2R2yLaGiiNVcOxY/3ykENWvH7ECOmll1jeHShGUTAslYqhRDBszWefSbfdJp1yirTBBnGPpqAIhgCQjaoqaa21/CwsvJVUSm8w3GknaciQFa8fOVJavlx67rl4xgUgf6JW0lKpGEpsct+aK6+UOneWLrkk7pEUHMEQALLBHoYriiqGaduyoqZGevXVFdtII1/7mtSrF/MMgWJUUyOVlfnWNKWCYNiy99+XxoyRzjjDT/qWGIIhAGSDYLiitLaSPvKILz5z6KGr3ta1q7TvvswzBIpRdbW/bnXqFPdICqeyUpo9W1q2LO6RJM/ll0s9e0o/+UncI4kFwRAAOioEguHK0tpKOm6ctN560rbbNn/7iBHSp59KH39c2HEByK+amtJqI5XYsqIlkydLf/mLdO65JbtuAMEQADpq3jzf44hg2KhvX6lLl3S1ki5eLD39tLeRtjRXNNrXkHZSoLiU0ub2ETa5b96ll/p2HuefH/dIYkMwBICOYquKVZmlb5P7p5/27TWaayONbLSRf9BOChSXUq4YEgwbvfKK9Oij0gUXSP36xT2a2BAMAaCjCIbNS9sm9+PG+YHAnnuu/n4jRkjPPsu8HKBYhODBkIohLr7Yfw/OPDPukcSKYAgAHUUwbF55eXpaSevrpX/+UzrwQG+BXZ2RI73t9OWXCzM2APk1b56f6Cm1imFFha/ESjB0zzzj2xFddJGvQF3CCIYA0FFRMCzBJa1XK02tpK++6mNtbpuKle2zj4dH5hkCxaEUN7eXfAXWigqCoeRV44sv9v1rTz017tHEjmAIAB1VVeV7X3XvHvdIkiVNwXDcOA970eIyq9O7t/T1rzPPECgW0aqcpRYMJW8nZVVS36rotdekyy7jvVwEQwDoOLaqaF5FhbRwoS/oknRjx0p77932xQZGjJDeekv66qu8DgtAAUQVw1JrJZXY5F6SGhqkSy7xhcW++924R5MIBEMA6CiCYfPSssn9hx/6R1vaSCNRZfGpp/IzJgCFU+oVw1IPhn/5i5/ou/LK1ueYlwiCIQB0FMGweWkJhuPG+eUhh7T9e7bd1qsLzDNEqZs2Tdprr3S3I9bU+Hy7gQPjHknhDR7s//76+rhHEo/ly719dKutpKOPjns0iUEwBICOqKvzlTcJhquqqPDLpAfDsWOlHXaQ1l237d9j5u2kTz9dugdUgCSNHi299JJfplVNTeMKnaWmstJbKZP+Op0v994r/ec//vvbqVPco0mMEvxLAIAcmDbNVzMjGK4qqhgmecuKGTOkiRPb10YaGTFCmj1beuON3I8LSINPP5Vuu82DxZ13prdqWF1dmm2kUmnvZVhb6+2jQ4dKhx8e92gShWAIAB0xZYpf9ugR6zASKQ2tpI884sH+0EPb/7377++VQ9pJUaoOO8xb8SSvnKe1alhTU5oLz0ilHQxvv136/HPpqqv8tRz/QzAEgI743e/88p//jHccSdSvn0/kT3IwHDfOW0i337793ztokJ9pZtuKdCuGOXJx+POfpXfeafy6tja9VUMqhqUXDBcv9kC4xx7S8OFxjyZxCIYA0F7TpknPPuufjxuXzgOifDLzqmFSW0mXLPFVRQ89tONni0eMkF59VZozJ7djQ+EUwxy5QpsxQzrllFWvT2PVMAR/jSrVimH07y61YPj73/u/+eqrqRY2g2AIAO11wgmNbVQNDek7ICqEJG9yP368nzXuSBtpZORI/79/5pncjQuFM3WqdMcd6Z8jV0ghSN/7nrR06aq31db6nN00mTvXx12qFcPu3aUBA0orGM6fL11zjZ/Y22OPuEeTSARDAGiPe+7xYBFJcxtVPlVUJDcYjhsn9e3rbYQdtcsu3jLLPMP0+eQTaeed/W9XSme1Kw633uqt87/+tYfEEHwBGslD4eTJ8Y6vvaLX7FKtGEqlt5fhjTdKs2Z5KymaRTAEgLZ67jnppJNWbT/hwHJVSW0lbWjwg9sDDpC6du3443TuLA0b5vMMQ8jd+JA/DQ3eRrbNNiueyOHkTus++EA691yfk3XWWY3XH3201Lt3Y0BMk5oavyzViqFUWsFw9mzp+uulb3zD54ijWQTDODHxHUiP117zjdC7dFk1CKSxjSrfktpK+vrrfkDYkW0qVjZihLckvvde9o+F/PrySw81Z5zhm5mvfFJg+XJO7rSktlY69lipZ0/prrtW3POvd2/pmGOkBx/0Nr00iY69CIZxj6IwrrtOWrBA+tnP4h5JohEM43TZZUx8B9Lgrbe8wrTmmtJnnzW2UTX9SFsbVb6Vl0sLF/pCL0kydqxX+w44IPvHGjHCL1mdNLlCkP70J2nrrf3kzh//6KvKRm2kkbo6fz/Gqi6/XPr3v32J/2gly6ZGjfI5u3/+c+HHlo2oYljqraTV1cXf9VBdLd10k5/E2HrruEeTaATDuHz1lb9ZNTT4JVVDIJk++sgrDT17+tzC5g6MsKqKCr9MWtVw7Fjv1OjfP/vHWnddaYstmGeYVF99JR18sC+YsuOOfoLn1FP9JE7TkzrPPutVsK22Kv4D5PaaMEG69loPfy1tBD50qLTddulrJ62u9pNEAwbEPZL4VFZKy5b5QjzF7Oc/b9zUHqtFMIzL6NGN85SWLl2xZx9AMvz3vz6PrL7eQ+EGG8Q9ovRI4ib3H30kvf9+btpIIyNHSi+84BUTJEMIXr3aemufF/yb33j4a+nvd599/D35/vulP/yhsGNNsjlzfAXmjTeWbrih5fuZeXD897/9Iy1qarwLpKyED4VLYS/DL7/0ToGTTvLfZaxWCf81xGjaNO/Tr69vvO4vf/HVkgAkw/TpHgrnzvVWwc03j3tE6ZLEYDhunF9ms03FykaM8DPuL7yQu8dEx02fLh15pM+J22wzacoUP/Ha2sH/T34iHXSQdM45Pg+11IUgnX66H6/cd5/Uq9fq73/ssVKPHumqGkbBsJSVwl6G0ZzCSy+NdxwpQTCMw+jR3kLalJmv+PX97/tBBoD4zJnj7aP//a/06KPehob2SWIr6dix3vK23nq5e8w99/T9wGgnjd/f/+5Vwkce8fbHl16SNt20bd9bVuZb0ay9tnTUUb6kfSm7915fUObKK31rj9b07+8/t/vukxYtyvvwcqK6urTnF0rFXzH86CMvxJx2mrf+o1UEwzi88sqqE99D8AOpW2/1TTe//DKesQGlbuFCrxy89570j39IX/963CNKp6himJQtK2bOlF5+ObdtpJJXSfbaiwVo4jR7tlesjjhCWmcd6Y03pAsukDp1at/jrLGGd+9UV0vHH7/qCdxS8dlnvnrrHntIF17Y9u875RRf9fGhh/I3tlyiYlj8wfDyy6Vu3aSLLop7JKlBMIzDyhPfo4+aGj/j+cEHXqFouok2gPxbutT3OHrtNemBBxpXnUT79evnW3skpWL46KN+oJ/LNtLIiBH+uv3FF7l/bKzeY495lfChh7y69eqr2a06OHSor174+OPS1VfnbpxpsXy5h2IzacyY9oXrr3/dW+7T0E7a0EAwlKQ+fXxhtWIMhm+/7e/jZ53F/3M7EAyT5hvfkCZN8vaGESOkX/yidM9aAoW0fLkvZT1+vK8U/M1vxj2idDNL1l6G48Z5m2A+2oJHjvRLqoaFM2+erzZ60EG+L+Hrr/sWUF26ZP/Yp54qHXecVxtK7QTtL37hlfU//KH9LddmXjV85RXp3XfzM75cmTPHX/NLvZXUrHj3Mrz0Ug++P/5x3CNJFYJhEm26qZ/1POooL39/85v+JgggPxoafMWyhx+Wfvtb6cQT4x5RcSgvT0Yr6dKlHtoOPbRxNehc2nxzb2FknmFhjB8vbbONzx366U/9ZOoOO+Tu8c2kW26RttzSTxZNnZq7x06y117zqut3vuMfHXHCCR7Ok141ZHP7RsUYDP/1L59T/qMfeYs42oxgmFS9e/vS2Tfe6C1QQ4d6WRxAboUg/fCHvtjCVVf558iNpFQMn3nGF8TI9fzCiJlXDZ95xjdKR34sXOhz3/bf39vfJk70/cm6dcv9c/XqJf3tb35S4VvfKv7/1wULfJ7mkCHS737X8ccpL/fOpzFj/GeXVGxu36gYg+Ell0iDBvkqw2gXgmGSmUlnn+37Ly1cKO26q+/NBCB3LrrI26Z+/GMmqOdaRUUyguG4cd5StPfe+XuOESOk+fO92wO59+KLvqLsH/7gK3hPniztskt+n3OzzaQ77vDWyAsuyO9zxe2cc3zRmTFjfIXRbIwa5QsC/f3vuRhZfkTBkIph8QXDF16QnnrKt6Dp0yfu0aQOwTAN9tjDN43dcUc/o3fWWauuagqg/a65xj9OO82Xt89Hm2EpS0IraUODB8ORI/NTWYrst58v1ME8w9xaskQ6/3xf+TUEacIE6de/9tVgC+Fb3/L33BtvlP7618I8Z6H97W8+r/qnP/XjjWztu6+0wQbJbiellbRRZaVXjNOyzcjqhCBdfLG01lrSD34Q92hSiWCYFpWVXjk891yfA7XvvtJXX8U9KiC9fv97PxD6zne8dYpQmHvl5d7tEGdL2aRJfhCYrzbSSP/+3tXBPMPcef11PyH661/7yZu33vJ9Iwvtl7/0/9uTT5b+85/CP38+VVV5hW/nnX2xnVwoK/NFaCZM8H3kkqimxudCDhgQ90jiV0xbVjz5pO9fesklhTt5VGQIhmnSpYu/Qd5/v7fR7Lijl8wBtM+YMT5X6dBDfQGLMl4K8yLayzDOdtKxY72Sd+CB+X+ukSO9uyMJ7bNptmyZn/XfbTevYjz9tJ/I6d07nvF07erbYXTr5nslLl4czzhyraHBF9patsznWOdiRdfISSf5393tt+fuMXOputqrhZwQbAyGURU1rULwQLj++r5iMTqEo6E0OvpoP5Par59XDn/9a/+DANC6f/zDD1r23Vd68MHcHgxhRRUVfhlnO+nYsV5lKkRlYMQIfy1++un8P1exmjJF+r//80VlTjzRF10bNizuUfmqs/fd59swnH56cbzn3nijL5j0m9/4aui5VFkpHXywn3hL4tSXmhoWnokUS8XwH/+Q3njDK99du8Y9mtQiGKbVVlv5cryHHurzL779be8RB9Cyp5/2EytDh3pg6N497hEVt7grhp984gfy+W4jjey0k6+ERztp+9XVSaNHe0vj9OnSP//p89769Yt7ZI2GD/eDznvuSW4lrK3efNNb6Q8/PH/VlVGjGv8vk4bN7RtFATnNwbC+3vct3Gwz34MUHUYwTLO+fX3S+LXX+uUuu0gffBD3qIBkmjjRD4I231x67LH42tJKSdzBcNw4vzz00MI8X1mZb6Xw1FPepoe2efddbxu97DLfv/edd7zalESXXuqV4TPP9LbhNFqyxOdWDxzoC8Tkq51y5Ejf/iKJi9BUV1MxjAwcKHXunO5geP/90nvvST/7mf9b0GEEw7Qz82W0n35amjnTz7b+7W9xjwpIlilTfI7Z2mv7QTsb3hZG1EoaZzDcZhtfIbFQRozwasSbbxbuOdOqvt4XdtlxR+mLL3zVzz//2Q9Uk6qszOfjVVRIRx4pzZkT94ja74IL/CD6rru8wp0vnTr5gj1PPSV9/nn+nqe9Ghq8kknF0JWVeUhOazCsq/NK/nbb+d8kskIwLBb77uu91Vtu6X8YF1wgLV8e96iQZNOm+RLwaZ9w3poPPvAWsL59pfHjORgopH79fA5nHHMMZ8/2ve8K1UYaGT7cL9m2YvU++sjnfl5wgXTQQV41POKIuEfVNoMG+WI0U6f6PMg0VYcff1y6+WbftzD6Xc2nk0/2yz/9Kf/P1VazZvlJCd4LGqV5L8M775Q+/VS66ioWkssBfoLFZJ11fJXS00/3s7D779+4iSuwstGjfVnn0aPjHkn+fPGF/x2YeShcd924R1RazPwgOo6K4aOP+sFfodpII5WVfuaaeYbNa2jwLZe2286rVvfe610uUXU5LXbdVbr+ep8/d911cY+mbaZP94W3ttlG+sUvCvOc663nVfQ//Sk5J6uj4yJaSRulNRguXerHMLvu6ieYkDWCYbHp1s2X9b7rLunVV30xhFdfjXtUSJKGBumBB6Q//tE/v+026bPP4h5V7lVX+2qGCxd6K1OuV91D21RUxBMMx43zTY532qnwzz1ypPTyyywItrLPP/e/ybPOkvbZx6uExx6b3i0DfvhDX/jt4ot9z74kC8EXmZk719t1C7nw1qhRvl9iUk6WsLn9qtIYDKdNk7be2iv3V1+d3teRhCEYFqsTT5ReecWX7N1zTw+LxbC8Njpu+nRfqGiTTaRjjmlsf6qrk7bYwhdVSNsbQ0tmz/ZK4bRpvtDMdtvFPaLSVV5e+FbSZcv8IPSQQ+JpLRoxwqsjzz5b+OdOohD8BNQ220iTJvmKno884sE9zcz837Xppr7acZJfP//4R/+ZX3utH0wX0iGHeAhLyiI0VAxXVVnp61QkcWuRllx6qa88vfbaPp0KOUEwLGbbb+/zDocP9828TzyxeDbmRduE4Geyjz7aV4f7yU+8grPy3n11dd6fv9560vHH++9NWi1YIB1wgPSf//iWFLvtFveISlt5eeErhs8+65XiQs8vjHzta1KvXswznDbNW7z220869VTfn/Dtt71yVSxn9/v08UVzFizw6mFS2iWb+uAD6bzzGldTLbQuXaTvftfbu7/6qvDPv7IoGFIxbBTtZZiW6UfTpkl33+2fz5xZ/GslFBDBsNgNGOAtVVde6XM5dtvNz7CguM2eLd1wg1cC99nHD1DPOMPn9Oyww6oHZZ07e0vXD34gPfyw7/O3xx4+9yeJBzotWbLE55S98YYvDrHffnGPCHG0ko4b59uRxHUWuWtXf+4nnijtTo3jjpNee83nvt98s6+evd56cY8q97bayqthL74oXXRR3KNZUW2tv7b36uWLdMS1OMcpp/ic3zvvjOf5m6qu9mk3SdojM25p2+T+zDMbj01CKO61EgqMYFgKysp8f6hHH5X++1+fc5PEDWeRnRB8XtPxx3uL1nnn+bLvd9/tZ2mjoPjKK6u2i9TW+nyfG2/0fv0bbvA5IUceKW28sS+yMHduHP+qtqurk771Len55/3fHFe1CCsqL/dqytKlhXm+hgYPhiNG+MFfXEaO9Lm7H38c3xjidN99ja20Xbr4iqPFvGLgd77TuPDbww/HPZpGl13m+y3efnvjwX8cNt7YT1LecUf8q7hGm9sXS9U6F9IUDCdOXHFbttpaP+FA1TAnivhVGqs44ACvpGy4oVdVLr3Uz+Ah3ebO9bPx22wjff3rflB8yinSW295UDzhBKlHj8b7T57sIXLlj8mT/fZ+/Xwp848+kv7xD2n99aUf/chbUc88069Pmvp6/3c+8ojPpz322LhHhEihN7n/97/9REjcJwZGjPDLUm0n/fGPGz9vaCiNM/o33ODdFt/9bjI6cyZM8BVTTz01/r8HyReh+ewz6Zln4h1HdTVtpCtLSzCsqfGTbiurry+N15gCIBiWmg028LBw0kk+p+ygg3xPH6RLCNLrr/tcnbXW8sDWs6efFf7qq8agmI1OnaTDD/eDizfe8DP+f/yjtNlmvpjAM88ko00uBD9T/8ADvrDCaafFPSI0VehgOHas/+7GvXT5Rht5lSQpKzEW0j//ueIBZqmc0e/WTfrLX7wyeuSR3toelzlzvHtkk02kX/86vnE09Y1vSGusEf8iNDU1LDyzsqiCmuS/0YUL/XV94cJVb6ut9UoiskYwLEU9eng7x623Ss89562laV5spJQsWODhbMcdpV12kR58sHGxmCgo9uqV++fdcUdvz/zyS680v/aaLzu/7bb+uxTXAVAIXpm47Taf23PBBfGMAy2L9qcr1MqkY8d65XyNNQrzfKszYoS/xi5bFvdICuuss1a9rlTO6K+/vs/nnzIlnoVeJH9dPO00P8i/7778vCd0RPfu3tnx8MPxbGEToWK4qs6d/SReUiuGtbV+cnrKFD/xtLquJ2SFYFiqzLyt46WXvM3na1/zA3wk0+TJ/ka/1lp+GYL0hz94dTAKioUweLAvZPTll75hcVmZt62uu67PZSn0m8pVV/n8xx/+0D9H8hSyYvjZZ77qZRLa5iQPhosX++tsqXj/fd+vcGWldEb/wAN9b8M77ohnsZUxY3zxrZ/9zFtbk2TUKJ8PHq0oWWj19f5aRMVwVYMHJzMYhuDHGU895QWNuLtBihzBsNTtvLPPydljD//DGzWqcItEYPUWLfLwtcsuHvzuuUc66ijp1Vcbg2LfvvGMrXt3b0eeMsUXmNh998btLk44oTAV6N/8xsPoCSf45ywkkEyFDIbjxvnloYfm/7naYp99fOGVUppn+KtfeVfK9OmlfUb/yit9Zdof/EB6883CPe+nn/qJsj33TGYHxZZb+vvF7bfHMxVh1iw/GU7FcFVJ3eT+pz/1kx2jR0snnxz3aIoewRDSoEE+D+aii/zF+utfl774wl8g9tor2T3nxeidd7wFaa21vDV00SLpppu8OhgFxaSEIDM/+B071vcNPP10X7Bm6FA/MPn73/OzwNGdd/oCOd/4hp+VL+bVDtOuf39vUypEK+m4cb51wEYb5f+52qJ3b389LZV5hlVVfgB38smNJwRKVadO0v33e0vzkUdK8+bl/zmXL/ctQsrK/ERip075f86OGDVK+vBD396j0KLjGSqGq0piMPztbxvXDrj44rhHUxI4moLr1Em6+mrv/f/oI69QnXqqt0CVwryQuC1Z4gdUX/+6Lxpz221e9XjxRW+NO/NMP8BOso039srd1Km+2MF//+tzAjbe2L/O1YHRX//q1e399/cDr86dc/O4yA+zwmxyP2eOb1WSlDbSyMiR/jechI298+3GG70ac/75cY8kGSoqvKXzs888LOe7Qvbzn/t2RH/4Q7L3izzqKO92uf32wj83m9u3rLLSfz5xbycS+ctfpLPP9kXwbr45OSfEixzBECs67DBp0iQ/kHvkEX+BuO02P+Md5wprxeqDD3y/wbXX9pbIGTN8zlx05v3rX0/fi2G/ftK55/r+bX//u88/PP983+7irLOy2+7iiSd8v7DddvPKZJz71KHtChEMH3vMq9NJaSONlMq2FXPn+nznb33LV7+G+9rXfMuIv//dt7PIl1df9TmFxx4rHXNM/p4nF3r18nH+5S9+QqeQooohwXBVlZVedZ45M+6R+Groxx3nbcd//nNyq99FiGCIVW2yic85jNrz6up8D8TevaXNN5e+/W2vLj7yiC9CkoQtC9Jk2TLfWmGffXzD+ZtvloYP97l6UVAcODDuUWavUydv9Xz+eZ9z+M1vSrfc4ttdHHqo/3vb87vz4ov+GFtt5b97SVlpD62rqMh/MBw3ztvDdt45v8/TXttu6+Mq9mB4yy2+anLT/Qvhzj3XX7suuCA/CxEtWOBBa8gQ6Xe/y/3j50O0nsF99xX2eaOKIa2kq0rKXoZvv+1Vwo028tf1pvswI+8IhljVtGm+3HbTdoKuXf3NbYstvKJ4ySW+l9166/kcir328nbH22/3bRMWLYpv/Emx8hzNTz6RLrzQ37yPOcZD9TXXeOtlFBTTVh1sq5W3u3j1VWm//aTttvN5k60tePTGG74S2brr+gF20ttqsaLy8vzOMVy2THr8cX9NStp8UzOvGj71VH7m2ybB0qXeRjp8uLTDDnGPJnnM/HVugw28ohqFk1w5+2xfCfbee71jIw122MG3yrrttsKeXK6p8cXT+vQp3HOmRRKC4Zdfevt9797eIZSEbYdKTMLeQZEIo0c332O+ZIm3733yiTR/vvTyyz6X4eijvf3grrv8LOAuu/iL7mab+VyCq67ysz6ff15a1cXRo/3s8He/6wdMG2/sbaJ77unh5qOPPChG+7yVgpW3uzDzBXaa2+4iCtbPP+8H1musIY0fX1o/r2KR71bS55/3qknS5hdGRo70lrlJk+IeSX7cc48fcF94YdwjSa5+/aS//c1/D445JncnCf76V1+M66c/9akHaTJqlPTWW9K//lW456yu9vehYj0Jm424g+Hs2f5auWiRn+hbd914xlHiLCTkQN3MRkvaU1JnSaeGEN7NXL+tpF9J6iFpmqTjQgi1ZnaHpC0k1Up6PYSw2nWZhw4dGiYV65tyru2wg29DsLLtt1/9cuMNDR7+3nrLl+d+6y3/+Pjjxvv07eutVdtt55fbbuuLraSxLbC+3l/IZszwj+nTGz//7DOfIxgF7LXX9lW1Tj7ZVxuFC8HnEtx4o29a27mzn2g45xyvPt9yi7eR9O3rraQbbxzzgNEhV1/tXQZLlvjZ+lw74ww/MTVrVn4eP1uzZnk4vuIKPwFSTOrrfYpB//7eLcIB9+rddZdv9XPRRf53kY2pU/09dOON/URtly45GWLBzJ/vYeQ73/HKYSEMH+7P++qrhXm+NFmyROrZ038vL7qo8M89bJifPHvqKT8pjLwxszdCCM1ucpqI5fzMbA9Ja4YQ9jKzrSX9UtKBmZuDpENCCMvM7JeSDpP0F0n9JR0QQijAGtAlpqN7TZWVSRtu6B+HH954/cKFvgVDFBbffNPPMC9Y4LebeS9507C43Xbeprq6trBp0zxEPPhgbuYLNA16TUNeS59H+yE1p1u3xts6d/YWt0suyX6MxSba7mKfffwEwm9/65XEMWP8/z4E3yD80UcJhWnWdC/DddbJ7WOH4B0JI0YkMxRKPmd45529NarYguHDD/vf7kMPEQrb4rvf9RD385/7whod3ay7oUE68USpttbn6aUtFEp+wu/oo3116V//ujDtndXVLI7Ukh49vLJd6Iphfb2fHHjlFX8dIRTGKhHBUNJwSfdLUgjhHTP7X1NxCOHtJvebIymavNZH0vyCjRAd17u3tOuu/hEJwfdKbFpZfPNNX7ktqmL36ePVxCgwbredtPXWjW8eUavm6NHNT7iPgl5bQl5rQW+NNbyFsbzcz47vuad/Hn1Et5WX+xv1Zps1fu/y5T6/7vLLmfC+OtF2Fz/7mXTggdLEiX59ly6+et3ee8c6PGQhn8Fw8mSvnFx1VW4fN9dGjPAz8XPmSAMGxD2a3AjB9xjbeGNfXAVtc9NNXhk5/njp3/+W1l+//Y/x61/7Al633+4LxqXVqFF+MvCBB/zzfKup8VWt0bxC72UYgvTDH/oJpptu8j0/EaukBMMKSU0noCw3s7IQwv+O0s3sa5K2knRt5qogaYKZLZM0OoSwyk6pZnaqpFMlaV16lZPFzN8M119/xXlBixZ5dbFpWPzzn30uY2TDDT14Pf20B7lbb/Wq0sKFK4a+WbNantM4cGBjkNtii8ag1zTgRV8PHNi+vfJ+8INVA2Z9fcsBFitavNgPliJ1dT6H5tJLCdZp1TQY5trYsV5d7mjlpVBGjPDXgPHjfe51MZgwweeH3XILy8m3R48ePt9wxx39QPjll9u39c6UKd7q941v+PSENNtlFz/he9tt+Q+Gy5f7axBbVbSssrJxwbxCuPpqf/248EJfwBCxS0ownCep6SnUhigUmplJulBSF0knhBDqJSmEMCJz+zqSHpW07coPGkK4VdKtks8xzOc/ADnSq5e/UeyyS+N1IfhiJU3D4lNP+Yu85Jf33+/tIRUVjUGvachr+nl7g157vfKKVw2bqq1trIBh9Zpb/IhgnW7RgkH5WJl07FjfK27QoNw/di7tsou3aT35ZPEEw2uv9f/bE0+MeyTps+GGPqXisMN8TnXTk5+rs3ixt90NGuRhKu3tu2bSKaf4z+DNN70zKF9mzvTjCU4wtqyysnDzL++4w0/4nnCC9ItfFOY50aqkBMMXJR0p6UUz21LS1Ca3nSZpWgjh7qbfYGadQwjL5e2ldQUbKQrPzOcbrreez9WbNs3fVJsqK5Oeey4ZL/gdnaMJR7AuPvmqGEbt6L/6VW4fNx86d/bFFZ54wg9O035A/+abHnKvvjq5czuT7tBDfW/D667zkxvHHdf691xwgfT++35ytBj2u5W8pfbCCz3o3nxz/p4n2iaEimHLBg/2Y6x8v0Y9+qj0/e97J8Xtt6f/9bCIJGW7ikcldTWzF+UrkF5oZteaWVdJh0j6vplNyHycl/meJ8xsgqTHJRV4+STEanUVJaTf5Mn+prTyB4E7vfr392CU62A4bpxfHnpobh83X0aOlKqqpPfei3sk2bvuOp8/fvrpcY8k3a6+2jtcvv996d13V3/fxx7zrolzz5X2378w4yuENdaQjjjC92FcvDh/zxO1SCbhBHJSVVb6CqHz87iEx2uvedfE9tv7ditpXDipiCWiYphpG1353SXaEOlANSOEMCyvg0JyUVEC0sUsP5vcjxvnreNpWXxjxAi/fOIJaaut4h1LNj7/3FeDPuec4llIJy6dO/vCKzvs4OHoX/9qfnXO6dN9m4tttvEVTYvNqFG+nsBf/+qthflAxbB1Tfcy7Ncv94//n//4fPC11vKqYe/euX8OZCUpFUOg7agoAemT603u5871xU+Suql9c9ZZR9pyS2/BTLPrr/f2/XPOiXskxaGy0oP2Rx/5fLuVF00LwReZmTfPw1Mxtu7utZef4MnnfoZRxZBg2LJ8bnI/bZqfHCsr85Nj/D8kEsEQAJB/uQ6Gjz/uC0+lpY00MmKE9MIL+W2Zy6eZM33RiGOPlYYMiXs0xWOvvbwS+NBDq86zu+UWr65cd52v4FmMokVoXnrJ51DmQ02Nb+BOlapl+QqG8+f7NlQzZnhLNPsSJxbBEACQfxUVuQ2G48b5YzZdwTgNRo6Uli2Tnn8+7pF0zM03+xykCy6IeyTF58c/9hMd55/fuDLk++9L553nvzfFvpz/iSd6a+3tt+fn8aurvUrFQicty0cwrK31fU7fecdbhYcOzd1jI+cIhgCA/MvlHMPaWj/rfMgh3paUJnvs4a2ATzwR90jab9Ei6be/9fCyxRZxj6b4lJVJd93lldijjvL9XHfe2atcd95Z/IFmzTW9Nfzuu/3kSa7V1LDwTGv69fPXp1wFw4YGnxv7zDPeaTByZG4eF3mTsndUAEAqlZdLCxbk5oDvhRe8NSlN8wsjPXpIe++dznmGd9whzZ7tWwsgPwYM8KrKjBnS7rt7GN9ll9IJNKNGSbNmSQ8/nPvHrqlhXltrzLxqmKtgeMEFPi/2F7/I36JCyCmCIQAg/6JN7nPRTjp2rAesYSldnHrECOnDD311z7Soq/NFZ772NQ8syJ8dd/Ttl6KTKBMmNC6cUuz239/3LM7HIjTV1aUTsLORq2B4ww3+mvHDH3IyKUUIhgCA/Is2uc+2nTQED4bDh3s4TKNo24o0VQ0fekj68ksO8Arl008b93crpX16y8qk733PWw8/+SR3j1tX55VIKoaty0UwfOABnxt75JHSjTcWfxt0ESEYAgDyLwqG2VYM33xT+u9/09lGGtl8c2ndddMTDEPwFTG33NL3IEN+TZvmcw3r6vzr2lqfY1gqVcOTTvKAeMcduXvMGTP895hg2Lpsg+Gzz3rb6J57SmPGSJ065W5syDuCIQAg/3IVDMeO9bPPaQ4oZl41HD++8eA/yZ54QnrrLZ8vlLbFftJo9GhftKOpUqoaDhniWxvceWfu/j6ize1pJW1dZaXvmblkSfu/d8oU6fDDpc0289fqYtxzs8jxCg8AyL9ojmG2raTjxvkct+jx0mrkSF+MJ9qWIMmuu84P1o85Ju6RlIZXXvEqYVO1tdLEifGMJw6jRnmF9NFHc/N4bG7fdtGWFe2tUH/+uXTAAb6y6eOPS/3753pkKACCIQAg//r39z3KsqkY/ve/voR/mttII/vt5y1WSd+24vXXffGTc8+VunaNezSlYfJkb3tc+WPy5LhHVjgHHiittVbuFqGhYth20c+oPe2ks2b5ya6lS/01bciQ/IwNeUcwBADkn5k0aFB2wXDcOL889NDcjClO/fpJu+2W/HmG117roX7UqLhHglLSubPPNXziCT8hlK0oGFIxbF17N7lfvFg6+GDpiy+kf/5T2mqr/I0NeUcwBAAURkVFdq2k48b53JXNNsvdmOI0YoT0xhvZt9fmy4cfSv/4h3TGGVKfPnGPBqXme9/zuZZ/+lP2j1VdLfXq5R9YvfYEw+XLpW9/2zsL/vxn6etfz+/YkHcEQwBAYZSXd7xiOG+e9NxzxdFGGhk50i+ffjrecbTk+uu9ffTMM+MeCUrRBhv4voZ33OGL72SjpoY20rYqL/c299aCYQjS6adLjzwi3Xyz9I1vFGZ8yCuCIQCgMLIJhk884SsUFkMbaWTHHb29NonzDKdNk+6+29v5aL9DXEaN8lbSp57K7nGqq/k9bquyMv9ZtRYMr7xSuv126eKLPSCiKBAMAQCFUVHR8WA4bpwHy113ze2Y4lRWJg0f7ge9K29PELff/MbbxH70o7hHglJ22GH+d5/tIjRUDNuntb0M//hHD4Ynn1w626iUCIIhAKAwysul+fOlZcva9311ddJjj/kCB8W2WfKIET7H8M034x5Jo3nzpD/8QTrySGmjjeIeDUpZ167SiSf6oibt3T6hqZoaKobtsbpgOHas9IMf+Mqxt9ziC4uhaBAMAQCF0dFN7l98UZo7t7jmF0aGD/fLJLWT3nqrB/gLLoh7JIB0yilevb7rro59f12db6dAxbDtWgqGEydKRx8tDR0qPfSQ1KVL4ceGvCIYAgAKI9qUvr3BcOxYqXt3X4ii2AweLG2/fXK2rVi2TLrhBt9ncaed4h4N4KsQ77mnz2frSMt1tOovFcO2q6z01+nlyxuve/996ZBDpHXW8QVnWOG1KBEMAQCFEVUM27M9QwgeDPffX+rZMz/jituIEdLLL3uVLm733uuVggsvjHskQKNRo6RPPpEmTGj/90YtqATDtqus9NfeaP/Hr77yVZS7dPHuhui1HEWHYAgAKIyOtJK+/bZvnFyMbaSRkSP9zPxzz8U7joYG6Ze/lHbYQRo2LN6xAE0dcYTUv3/HFqGJwg2tpG3XdC/DefOkAw6QZs+WHn9c2nDDeMeGvCIYAgAKoyPBcOxYX9zg4IPzM6Yk2H13qXfv+OcZjhvnm9pfcAELSiBZevSQjj9e+vvfpZkz2/e9VAzbLwqGJ57oofC99/xnv8MO8Y4LeUcwBAAURv/+UufO7WslHTfOt6go5oO6rl2lfff1YBhCPGMIQbr2Wt9U/Mgj4xkDsDqjRkm1tdKYMe37vqhiWMyvIbkWBcP33pNeecUX/inGOd5YBcEQAFAYZWW+oXtbK4ZVVdKkScXdRhoZMUL6/HPpo4/ief4XX5RefdX3LezcOZ4xAKuzzTbSLrv4IjTtOYFSUyP16VO8c5TzoekiP126+GJUKAkEQwBA4ZSXtz0Yjhvnl4cemr/xJMXIkX4Z1+qk117r/zcnnRTP8wNtMWpUYxWrraqrmV/YXtde29hObsYm9iWEYAgAKJyKira3ko4bJ22yibT55vkdUxJsuKG08cbxzDN8+23pscekM8/0uVxAUn372z4ftz2L0LC5fftMmybdeWdjVba21r+O5mqiqBEMAQCF09aK4YIF0rPPerWwVBZCGTnSl+Nftqywz/vLX/qeZGecUdjnBdqrd2/pO9+RHnzQV8tsi+pqgmF7jB696n6R9fVUDUsEwRAAUDhtDYZPPulnqkthfmFkxAhp8WLppZcK95xffindf7+36K2xRuGeF+ioUaOkJUukP/+5bfevqaGVtD1eecVfe5uqrZUmToxnPCgogiEAoHAqKnwj99aqYmPHSgMH+lYOpWLvvRs3kC6UX//aL887r3DPCWRjp52k7bdvWzvpsmXSnDlUDNtj8mRvI135Y/LkuEeGAiAYAgAKpy17GdbVSY8+6nsXdupUmHElQe/e0h57FG4Bmlmz/OD6O9+R1lmnMM8JZMvMq4aTJ0tvvLH6+0bzmakYAm1CMAQAFE5bguHLL/tZ/lJqI42MGOGLwVRV5f+5fv97b1398Y/z/1xALn3nO75QUmtVQ/YwBNqFYAgAKJyKCr9cXTAcO1bq1k0aPrwwY0qSaNuKp57K7/MsXizddJN00EHS1lvn97mAXOvfXzrqKJ9nuHBhy/eLVtIkGAJtQjAEABROVDFsacuKEDwYDhvmK2WWmm22kSor8z/P8M47pZkzpQsvzO/zAPkyapSvXvzQQy3fJ6oY0koKtAnBEABQOK21kr77rvTZZ6XZRir5/KkRI6Snn/Yl4vNh+XLp+uul3XaTvv71/DwHkG9f+5q0xRarbyelYgi0C8EQAFA4/fv7gjItBcOxY/3y4IMLNqTEGTHC51j+61/5efy//tXD9wUXlM4ekSg+ZtIpp0ivviq9807z96mpkfr1k7p3L+zYgJQiGAIACqeszKuGLbWSjhsn7bKLt1OWqv3394PefKxOGoJ07bXS5ptLhx6a+8cHCumEE6SuXVuuGtbUUC0E2oFgCAAorJY2uf/qK+n110u3jTQycKC08875mWf49NPSlCm+EmkZhwBIuUGDpG98QxozRlq6dNXbq6uZXwi0A+8KAIDCaikY/vOffkkly1cnff11bynNpeuuk9ZaSzr22Nw+LhCXUaP87+Rvf1v1NiqGQLsQDAEAhVVR0Xwr6bhx0kYbSVtuWfgxJc2IEVJDgzR+fO4e8403pGeekc45x7cDAYrBPvtIG27YfDtpdTXBEGgHgiEAoLCaqxguXOih5dBDWRBFkv7v/3zRjFy2k157rT/m97+fu8cE4lZW5ovQPP+89J//NF6/dKk0bx6tpEA7EAwBAIVVXi7Nny8tW9Z43VNP+delPr8w0rmzL0Lz5JO+YEy2Pv7YW+1OP13q2zf7xwOS5Lvf9dWOb7+98bpoD0MqhkCbEQwBAIVVUeGXTauGY8dKa6zhe5PBjRghVVX53o7Zuv56D5tnn539YwFJU1kpHXKIdNddUm2tX8fm9kC7EQwBAIW18ib3y5dLjzwiHXSQhxe4ESP8MtttK2pqpDvvlE48kYNkFK9Ro/w1Zdw4/5qKIdBuBEMAQGGtHAwnTpRmz6aNdGXrrOML8WQ7z/Cmm7yK8qMf5WZcQBKNGOF/M9EiNNXVfsnJEKDNCIYAgMJauZV07FjfpDqqkKHRyJHSCy9IixZ17PsXLJB+/3vpm9+UNt00t2MDkqRTJ+nkk32vzs8/b6wYRq83AFpFMAQAFFZUMZw+3RdWGTtW2m8/qXfveMeVRCNGeLXv+ec79v233irNnStdeGFOhwUk0skn++Udd3jFsH9/tmYB2oFgCAAorP79/ez+jBnS++9Ln3xCG2lL9txT6tGjY/MMa2ulG26Q9t5b2nnnnA8NSJx11/Uq+5/+5As30UYKtAvBEABQWGVl0qBBHgzHjvXrDjkk3jElVffu0l57dWye4Z//7AfHVAtRSkaNkr76Snr8cRaeAdqJYAgAKLyKCm8lHTfOq1lrrRX3iJJr5EjfuPvzz9v+PQ0N0nXXSdttx9xNlJaDD/ZAuGyZ9N57jYvQAGgVwRAAUHjl5dI770ivvUYbaWs6sm3FI494m+4FF0hm+RkXkERdukgnneSfz5ghjR4d73iAFCEYAgAKr7xc+vRTX3zm0EPjHk2ybbaZz51qTzvpdddJ660nfetb+RsXkFRNX1PuvJOqIdBGBEMAQOH16uWX66wjbb11vGNJOjNvJ33mGamurvX7v/yyf5x/vtS5c/7HByTNmDFeOZSk+nqqhkAbEQwBAIX39tt+OWAArY5tMWKE70n4yiut3/faa6WBAxuX7gdKybRpXiWMTqLU1lI1BNqIYAgAKKxp06QpU/zzDz7ggK0t9tvPt/hobZ7hu+9K//yndOaZjVVZoJSMHu2LLzVF1RBoE4IhAKCwRo9esUrIAVvr+vWTdtut9XmGv/qV73t4xhmFGReQNK+84lXCpmprpYkT4xkPkCIEQwBA4URtXtGBG21ebTdypPTvf/s2H82ZOlW67z7plFN8n0igFE2e7ItarfwxeXLcIwMSj2AIACgc2rw6Ltq24qmnmr/9hhv8Z3veeYUbEwCgaBAMAQCFQ5tXx+24o1cCm5tnOGeOdOut0tFHS+uvX/ChAQDSj3WsAQCFQztXx5WVScOHezBsaPCvI3/4g7RwofTjH8c3PgBAqlExBAAgLUaOlGbMaFzVVZKWLJF+8xu/bbvtYhsaACDdCIYAAKTF8OF+2bSd9O67fUGaCy+MZ0wAgKJAMAQAIC3WXFPafvvGbSvq632Liv/7P2mvvWIdGgAg3QiGAACkyciRvljP/PnS3/8uffKJdMEFK+4NCQBAOyUmGJrZaDN73sxeNrOtmlzf28zuN7MXzOxhM+ubuf5wM3vRzF4zs2/HN/KOue8+acgW02Qn7aV1tqjWfffFPaIVMb7sML7sML7sML7sJH18T5eN0LTuyzXo7N307Pev0vzBm0iHHx73sFaQ9J8h48sO48sO48sO48ujEELsH5L2kHRr5vOtJT3W5LZLJX0n8/kZki6U1EvSS5K6ZT6fLKn76p5jp512Cklx770h9OwZgg46PeiysqADfxB69vTrk4DxZYfxZYfxZYfxZScN4+vXY1n43kGdQtllCj84UOEHXW9NzPhCSMfPkPF1HOPLDuPLDuPLnqRJoYW8ZH57vMxstKRnQwjPZb5+NYSwa+bz5yQNDyHUmdlgSbdI+q2kPUMIl2fuc4ukW0IIU1p6jqFDh4ZJkybl+V/SNuuvL30xa5p03jpSWb3UUCZV7aJO6qrKyrhHJ02bJtVrmbT261JZA+NjfIyP8TG+hI3P1n5VoSwzxKpd1EndEzE+KT0/Q8bH+Bgf48v7+Op6SL/5VOsNHKzPP497dM7M3gghDG3utqTsY1ghaUaTr5ebWVkIoUFStxBCXeb6WZIGNHP/6PoVmNmpkk6VpHXXXTcf4+6QL7+UdOBoSZlQbkHq94XqZ2+ir6bFOTLXUC9pjS98XBLjayfGlx3Glx3Gl500jM/W+EzKTCcMJlm/z1U/e/NEjE9Kx8+Q8XUc48sO48tO+sZXL+05Wl8+/rtYx9VWSQmG87RisGvIhEJJamgSEgfIA+E8SRs3uX90/QpCCLdKulXyimE+Bt4Ra202TVXb3+lnEiT/5ekxR0NefUD/fX9wvIOT90VXHbHhin90jK/NGF92GF92GF920jC+6Ueso7omwbBLj5laMyHjk9LxM2R8Hcf4ssP4spO68XWulXa4U2t/eqmk+MfXmqQsPvOipCMlycy2lDS1yW2vSTos8/kRksZLel3SSDPrYmY95fMSPyjccLOz+amjJWtY8Uqr12anjo5nQCthfNlhfNlhfNlhfNlJ+vi2OvEnMqtf4Tqzem114k9iGtGqkv4zZHzZYXzZYXzZYXz5lZRg+Kikrmb2oqRfSbrQzK41s66SfiHpVDObIGknSXeGEGZKuku+AM1jki4PISyPZeQdMKvnK34GoanOtZrVc2I8A1oJ48sO48sO48sO48tO0sc3feGjql2p16e2s1Sz8NF4BtSMpP8MGV92GF92GF92GF9+JWLxmUJI0uIzAAB0yA47SFOmrHr99ttLkycXejQAgJRJw+IzAACgNYQ/AECeJKWVFAAAAAAQE4IhAAAAAJQ4giEAAAAAlDiCIQAAAACUOIIhAAAAAJQ4giEAAAAAlDiCIQAAAACUOIIhAAAAAJQ4giEAAAAAlDiCIQAAAACUOIIhAAAAAJQ4giEAAAAAlDiCIQAAAACUOIIhAAAAAJQ4giEAAAAAlDiCIQAAAACUOIIhAAAAAJQ4giEAAAAAlDiCIQAAAACUOIIhAAAAAJQ4CyHEPYaCMLMZkr6IexzNGCRpZtyDWA3Glx3Glx3Glx3Glx3Gl72kj5HxZYfxZYfxZYfxdcx6IYTy5m4omWCYVGY2KYQwNO5xtITxZYfxZYfxZYfxZYfxZS/pY2R82WF82WF82WF8uUcrKQAAAACUOIIhAAAAAJQ4gmH8bo17AK1gfNlhfNlhfNlhfNlhfNlL+hgZX3YYX3YYX3YYX44xxxAAAAAAShwVQwAAAAAocQRDAO1iZjuYWde4x5EGZmZxjyHt0vIz5G8CSWEZ0edxjwcdx/9faYrz/51gmAJmtmncY2gLM/uemZ0e9ziQP2a2iaTtJO1vZsebWZe4x5REZra2mXUPIYRSeGPPx7/RzPZI2c9wDzM7Oe5BIHuZXLVZil/fhkg6x8y6FuLvp0kIPd7Mzsznc+WbmSXiuNjMvmtmPVP0+vc/ZjbUzEaY2baZr2Mbv5ltb2ZbxPX8HRVinOeXiD8AtMzM1pd0iZntGPdY2uBuSf3N7MS4B9JWmQOAw8xsczPrFfd4JH9jMrNfZN5kd8hcl4gDlBDCR5KmSNpcUndJFWY2ONZBtUPm//rIPD5+9Jq6laQrzaxXGt/Y28LM9jazw6Xcv4llfqeGSBqZuapnLh8/18xscAjhGUlrp+n1L2nM7GQzOy3mMZRJ+qek0yTtlLmuf5xj6oAaSZ9KutjMOuf7NajJ3//rkgab2an5eq58MjMLITRkjgtOiuu4y8x2k7StpB+ZWY80vYeY2f6Srpa0gaTtM1dvZGY9YhpSH0nnm1ni9xLMHPtdY2Y/igpCZtat0OMgGCZcCOFzST+XdGKSf7HN7JuSDpV0raQNzeyEmIfUqswBwL2SdpW0n6QyMxtsZgNjHtN9kqZLapC0gZltIGnzOF4gmhNCmCLpaUm1kkZLKo91QO3zuKStzexb+XjwEEJD5tOJkl6QdGkxhkMzO0R+Iuh7ZjYoD0+xqaRZkuaZ2W8kHZx53sT9DDMHQv8ws7NCCKMlrW9m321ye+LG3Bwz29DM9sx8vr+ZbRPDMO6VtGbTn18hZV5//yTp1czlIDO7XNJBcYynvTIHlndL2lvSU5IOk3RDIcJhJgxeJQ8FveIO+O1lZmVNfka/lXS9pD1iGk65/P9vgKSfp6VymKkQ/kjS0ZI+l/QNMztC0saS+mXuU5B/Q+Zv4RFJa0q6TNJxSS6wZF57xsh/btWSRprZVpK2KnSoJhgmmJl9w8z2kf8//ULSCUkMh2Z2kvzsamXmwPhqSRub2fHxjqxVf5D0fAjhp5L2l7+Y7SZ/IYnLhZLeDiHcIOkQSf8naQv5Wa/Y/l7NbE8z2zz6OoTwlqTXJD0jqZuZ9YlrbG1hZpVm9hNJx0r6paRdM+Emuj2rN6vMGebuZnagmT0n6eQQwqOS/i3pKGts6Ur9a66ZHSrpCklLJV0jPwg8KHNbrt7Aukg6XH7y4T1JQYq3vaY5ZraXpIskHSWp0sz2lXSHpOVm9nUpeWNuTuak00hJF5nZsZJ2l1SXuW3dQvzemtlGkuol/UxedTop38/ZjAck1YQQrpI0VNLZ8tffR5uMM5F/w5lx/V1SJ0n/knSEpEslPSJpiygc5um5j5efGP6XpMMy71+90nCCOBJVCuXvD4fKT37+zsy+aWZrSvkPNWZ2ppmdJam3/G9hprzy9uOUVA6D/OTrMEk/kfSYpA8k9ZC0vlSY18MmIatOUn9J3SRNknSQmVVm7pO0n+Npkj4IIdwiaYSktTIfBT/2S+QLHKTMWZZL5S1UZ0paT16NOz5J4dDMRsoPtk+TNNfMdgohRJWkLczsuFgH2AIz6yRpqqR3zeweSdPkLZKzJK1n8bWVvi1pppn9VdJcSX+TNE9+BnjnGF/MyiSdZ2abNbluF/mb1yaShiTwhVaSZGY9JV0sP1B6K4SwKIRwnqR6M9tPyv7NKvP9PSVdIGmRpDfMbPcQwkOSZkganakcNqzucZLOzHaSn/jpI/+7ny4/OdDTzHaRh+BOWTz+zmbWJdOW+ZE8cH0irxx+yxLSUi397+Bja0kny8+I7yapl6Ql8rH/wlIy3yqEsEx+QHdbCOG+EMKVIYQPzNuuL5T/u/LGzH4o6Xb5e94ZIYRr5EG7YMEic/D/pqSHzez78teLWkn3yM/an2s+5zWpf8M/kDRf/n7xmLzdf39Jx8srh9fm4zXavJ38Ekl/CCFcJ6mTmR0t6V1JO5rZKbl+zjw6T9IoSc9KOkbS+fKTYHVmdrZ8fn0+1Uo6UtKsEMLT8jDze/n77EVROMzzGLKxRF7xOkRe/Z8obye9TNIFZrZxgcbxkHwqwsOSNpP0fUlvyfcU/JGZ7ZrAn+Onkj41s7GSFspP8iyS/yy3z+Z9tb0IhglkZp3lrQQXZqoOl0o6KIRQJT8bfaz53MMkeFHSMSGET+XhqkySQgh1ki6XtDRzYJ40XeUvFAfJA9id8rNKo+QHvvvFFHQ+kofDd+T/193kb+wXy9/cC9ZOamb7mdmukhRCmCDpNklnmdnGZvZtSUtDCA9IeknS5wl8oY0cKA/Wz8v/X08ysy0lfV1+RjhXbWKHyP/fnpS3PpqZHSPpLHmIOjhHzxOnOknj5AdQC+UHLZfKK0zXSZoYQqjP4vF3lPTLTCB5Xv7muJWkKvnZ6O2zeOyciF4XMgHh9/Kz+7+S/41OllcbfiZpHWXap1JiF/nZdUmSmR0lP+F3cwhhQb6e1Hz+3raSDg8hXCHvQDha/vtUsJOLIYQa+Ym4IOkbkpbLD8xr5O9lpyth/5/m7XLrZL78QwjhBEl/kfSE/HVoE/nYJ8n/PZ1z8JyWqSKvn7nqbUnnZm7bQz4/c0f5PtnnSJqR0GMASZKZdc9cdpN3J/xJHgjPkYeKi+Vt8xtlplHkaxx9JH0h70D4lZn9QP6er8y4aiUdkrQTsObTbzaRpBDCxyGEh+V/R69L2kEesAdIejeE8HEBxtNFXi38vaSvyd+zXs10OZ0k6QRJ51pCpuY08R9Jb0h6WX7s11XexXae/KRPwU6KEgwTIvNiu4N5y9ly+QHmkWa2SQhhpqTqTMXhLflByJyYx7uJmZVnqi8zMlf3UOZ3yrxfvy6E8NcQwuL4RroiM9syM7YlIYSx8jfRv8v/6L4lb91cLOnfhQo6mQC2uSSFED6UVzIny0Pgd+Uvbs/JD9CWFmJMGWtIWsN8YZ4dQwj/kvRn+RyCziGEBzNj/m8IYUkBx9UmTV74X5dXc56V9GEI4U75G8S35S/Gb2XxHBubt8AphHB3COGH8jfxW+UtNMdI2lDSb6KfV9qY2UWZoBa1EL8gb697RN5695U8vJ3c0Tf+TPVNIYQ/SvpY/nN7S9JASZ+FEN6RB8V3svvXZMeazEMysyGZ14jP5G3VveSB4gR5KPxdpiUxkZoeYGYOjpfJK03K/H+fKukHIYT38/T8UchaKK+I7Jv5+ib5Safl8kpDXk8umtkw88U+FEL4QH7yYbH8ffZv8hNze0j6ViY8JkkfScMygSw6KO4hD7OL5YFmsDzo3Jk5YZutrpIGSdrdfM5W1xDCY/LXgcHy9tu3QgiPZ+4/LknHAE1l3nd/ZWYbZarmL8hPzv5UXmW6TH5S8Z0QwlmZ78lpMMt0SfyfPLi/EEJ4SV7p+ruk38mPBabLpxONTdIJWDPrLT+5voeZDclct668ar2u/KToUEk3hRAuzdyez3mue2eOO8fKq5WfyY9ZJpvZhfKA9aKkCzL/37Eys+HRzy1TXFmsxtbb78or/v+QdGkhj/2yPnuE7Fnj3ID/ytt5HgshvGRmCySdYWbvyM++LZKkTOUwNuaTyg+XdI+ZjQ8hTM/cVCn/xW66CEdimM8H2kH+R/dG5sAkOuA4WtKJ8gnf54YQphZoTJvKz65uYGbz5YG/hzwc/p+kb8rP9p4eQvhvIcaUGdfh8rmWn8r/r/uY2VshhJfN7NMQwrTM/SxJb1TS//6ebpD0ipk9G0L4ssn1X5gvZvIt+Zm5czv6czWz4fI5dreY2cAQwuuZm5bLF0+5Rt56dH5mzk0if16rk6ms9pNPhF8SQng0hPCkmU2TNEHScfKf5VkhhE86+jxNXy9CCDeb2SL5HOAXQghjMjfNiPNnlwmF0Tyk30t62sy+CiEsNLPz5X+3G8lDxCUhhF9mvi9x/+fmLWlLMp8PCiHMNLNHQwi1mWrdSZJ+GEL4T56ef2NJXzOzz+R/hxdLOjPzsy2XV0eizpO/5mMMmXH0lJ/MXMfM5spPEH4mfy9YKv8dPFnSTvmsFmVhDfmB7pHyhV9OkTQ+hFCXOWF1rDx4n5UJvVnJ/P+cLekV+XvVbfLqxvshhMnm82o/DyHcG90/ab/70grhZEv5cfBpZvaHEMKnZvaAvHL+kqTfSPoi+DoEOf33ZMZwoLzTai/5CYjR8mOoBfJg9a/MiajZmU6M5bl47lzInHjtLf87OV5SVzMbn7n5bfnf8SuSHg0h/DrzPXn7fcj8vg80bz+fLl9A6ll5S/NF8p/t35XFe34uZQLhfvLF8O6Ut+F2k+eAneXvI19IOqfQ4yUYxixzsHqHpPflZyh3NrObJL0eQrjXzH4pqSz6xYj7hdZ8QYCDJF0p/yXe2cxeyLQaPRBCWBjX2FbHvE2jXl7p2MTMlspfgL/IXP+hfK7Ujwv1R2i+JH8n+Vnf4+RvEFPlbwpT1Li4x0MFDoXfl7fU7px5U5onn+O6qZn9JwWh8G55b/4SSftIetB88/E3MteZ/IxmNqFwmLzV6Fx5m8wmkl43n4P3ZghhrpnNlLfHpSoUrjTONeUH7pvLl/zuH3wO2luZg8AdJJ3U0VBo3oK0kfxv75uSZoYQngkh3Glmk0IIbzczpoLLPH8UCm+TV7T+bmbbmtm8EMIXygQJM/sohDA+CeNuTiaUHWxmr8ur2b3N7I5MKNxWXq09J3j3Qq6f2+Qt1dPkK+99T1KXEMIzZvZr+QHyeyGEF3P93M0JISw2s1flv8fHSaoPIVyWGevgzDh3TFoozLzOPSjptRDCr8zsYfnfaENUFQwhfJJ5v14WctAKnHnOv8rbxV/MXNcgD56R8VGFOYm/+9IKJ3g6y9uGn5Iv9vEbMzsv+JZMs83nvX4aQvhx5vtyGQqjFdGfDCE8mvm72EB+IvFpeZVrYfR8Ibv2/Jwzs7XkXThLJG0jP3n4iaQK+ZT7jyXNMrNrQwhfZb4nL78PmZ/l1ZK+lIfBkZLWCyE8Ie/kkJldJ59z+KuEhMK1JPWVNFvSj+VTJT6TL3w1OXOSqq+kB+MYryXw77akmC8tPb3Ji8+v5OHlJ9FBUZP7xn1wdLS8vejoEMJ08zaMXUMId5nZ7pIWhxCmxD3OlZkvMNJZ3t51nPxA9175GbmJIYQF5kvu14UQ5hVoTAfKX6h6S9pTfgByjfwA5ZMmB8TdQgFbHsyX3r9efsbvHnlQ/VB+0F4rf6PscOtlPmXeXMfKV5q9PhNwP5CfZd1P3oo7O3PfgSGEWR18nu3kW4p8Vx7gj5W3PR4trz5cKH9zDE2+pywksIq+Opmf3zflQWF3+UH8Mkn3hhAeMbNvyFfQ7Wj7aCd5ZWakvPV2Q0ljQghLzOcvVYcQlibl9STz+/Un+ZncsfIDkbmSpoQQ3jSzrUII7za5fyL/z83b/86W9Ef5yb0JmRNAO8vP8v8rNE4PyOXzRmGmVt4q94W84tVd/jc7p+n/dSH/3zPVj93kqwBOCSG8l7m+a/DF1BIj83v4F/nv338l/TOE8LF5O+kiST2DtyPm+nnHqDG4fCVfcXm7zHPOl/RcyHQPJeVvtiWZ38Vx8rmYf5afCN1LPrXgRvmCYYcEn0Ofj0rhI/LjvEPkwXoD+WvrZpImBW+dT5zM2CU/4bqjvNWxqzyA/SNzfWd5lXBy0+/LYyi8Q/46cp+8QjhEvgJqmbyNOTFVVul/bfqS/59/TT514rfyn+cn0fGV+SJsuWj9bjfmGMbIfL+8e5uEwp/KXyyelJ/RPSRzVktSvMuem6/S2UnSsZlQeLSkqkwo/KZ8sYXpcY9zZWa2obyt7zB5m81/5UtqbyA/S/h/ZtYphDCzgKGws7xKuZZ8HsMs+Ty4reXB+wBrnPNSkFBomeW45fMrdpSvrnmmpDPkK0N2llcye1mCVoZcyQHyKsQY87bht+QVr2vlJwBmZ8KIOhoKM3pLuiVzeYS8EnmMfLuWHzcXBpIYEFbHfHGhy+QtYrPlb7hXyA8GjzWzfUMI/8giFJZlzoI/KZ+LN17Si5lQ+C35gjbdpWS8nmQOiM6Rz3M8Xn5i6WVJ92RC4e/ki7f8TxL+z5scyKnJ7/6/Jf01hDBRXmEKmYOVq+Vzq3MeCjP+KWlOCCFazbav/MTTWpL2NbPBTf+v8/n/bma7mNn3mlxVJ98aYLp8Jc0dMmNIVCjM6Cnp2eArK78jr25tI//93FDS8KbHDdkyX1xkc/nvzLbyv8uP5e+rB8grHdupycJoSfibbUkmTDwkPzE8NfP6do/84LxefmKvdz5CYca28rmrF8rnMh4tb2GeIt9T+TQz2yKHz5dLvTI/ixflc/g+kP/cnpGf1D5AHqq3afpvyOPvw7fkVcsfy49dDs+M4z15F96uufxbyJHF8irrkZnPP5Ef+50v6TAz2zHz/hhLKJRoJY1V5uD0aUkys4vlZ+XHyM8iHCU/KzhBfkAei0x15L0QwiIze6BJS8NiST8xs2ihiB9GLQNJEnzOwLPyyfKPyANYN/kcmjnyxS2Gy+d25p2ZbRpC+I+ZPSM/y/ppZkwby1/U3pDvmbWNmb0ZCjBpPxOiKs1bgj/PvChVmdlfJP0tNGkPzlQwY3vBasVb8rbOk+UBZpA8eN8YQhifeYPvUEuO+eIcPTMHEa/K56BsIT/JcIJ88ZXR0f2TfGC0OmbWJ3jb2dvy1rTTzOyf8t/L1+QHhA3y7Ul6tvf308w2Dr5yXRSa9pXUkKlWVZrvLbm/fE7U3Nz8qzrOzCrkYaYu8/o3zXzZ+rfkcwoPzYSqOSGEP8U62OatnalkPhn97pvZYfLVPv8tqYeZXSNfcOXsEEJ1Hsdyt/z3pre8fXgtedXrYHkL2l3m87zy0jaXCckbBm97niLpcDM7OhMABsqDzn/llZsecZ6xb4mZbRG8VfP3masq5McN35WHjM3lVafOyt18tL7ylU0HZF4LPpRv67GvpB/KX2d3lQeExDKzfiGEecHbSH8RQnjDzF42X/hljvw94235Cb/tzNdPaMjla7n5Pq8fZ04mdZb/rr0oP8Y7Qx50/i0/SZEo5nu0jjSzyzKdHP+SHwc2yLs+9pF0dwjhT5kTCXlfpyGE8ICZvSI/KfKJpNkhhD9nxnuSvLvjHXlnRyKEEB4zs1ny4PqqPBQeIP89eExe8XxfHnhjQStpDMyXAe8cQrg/8/UoeSi4T95WuLt8L5gfhszCGQUen2XOIlfKV3F6IITwrvn8orlN7jdafnbmvJCnRQo6InNG8FvylcTeyVy3nrwPfoik78jbRk8yswHyv4PZBRjXIEm/lnRdCOEd82XaN5Wv5PZ9eQX/4hDCv81XoF2U7zFlxrWB/P9xQWYsb4QQ3sucUZ8YQng/qa1BmYO9jeQtrg2Z/+cG+eTtH8grPC/LVyPt8KJN5vOyvp55rM9CCMszz/1L+cHZvfIz+dNCCK9l82+Ki/l8v/3kk/XfCd7aN0B+4P6E/Kz23I6erDCf5zla0iMhhBfN2/cOk/SPTPC6Ql51O7OjlchcafIa+G35QcVzwefgdZO3mP3VfJ7ILfIVGC9p+n3xjbxR5vdza/nfR1/5CbHb5Sc0qkII88zsDPn/7w9DFosHtTKOfUIIz2U+303ePrxQXmnaVn4i9EtJp4Y8LfqVeU+4S94C/EgIYVnm//JyeYXjC/nv9rOZ31MLCVi1sKnM6/SV8hWOo8XTRsgPwLeR/wzPks+dztVCM5vLq6k95e+pk+Q/qzflHSV95K+LZ4c8zEnNlczJiN3kVcJX5eFsmXk7/KfyVVyXSFqer/fdzPHUKHkYvEn+M91L/r5/knz1zufk25R9kY8xdJT5fPIb5KsuryFpQQjhs0xVcBP58et4+XHE3SHPrbCZ94pPQmZhMjO7Un5S+JbMsctB8vn/Z8T9e5n5OzpZHvY+DCHMMl/0ajP59Kbvy18PHw/egRednI0NraTxeEu+IfQIM9ta/kJ7dOZyuPxs0RlxhEJphWrH/vIXgu3M7OfyRWck/a9Peg/5G0LSQuHf5L3765tZV/O2oE7yM5t7ykP3h5mzxXMKEQozBsvfgL5vvv3DXPmCFV3lq2WdLOmbZta7gKHwdPm+a1PlVbBt5BPyJW9Xel9KZgUs83/9iPxA82uSlHlD7SKfQzVavqrcQEnbWgdbYM33CestP5A9RX5AJHmI6htCOCGE8JR8rk2SW21bZGYj/7+98w6Ts6ze8P2E0EuAQEApASLB0JuCShelQ2gCofeaCChF0EhXiqiAAtL7DxEQaUoHQZAiBEVASqQTakLoBM7vj+cddoibtrsz8+3m3NeVi92Z2ZmXmfm+7z3nPOc5+Pv5En4/azKgcfj7+UFEvNyRoFCetXYZduA7AX/H1ygb7ytKULgF3rhVKSjsjY/JdSjfL/zdur78fCRWU1QxKKw58y6CqyCrAN8M8+8SFG6J5UydcpSdxDoG4JE320v6bkTci3u4TsTnm61wBWqvBgaFwtXKaSPiSux+OlP5/g3Hgf8bEXEbWD5ataAQICJG4kHyO0haMdz6cB1ef198btq/C4PCq3Egsxt276z1GD4WrvjXZuvt1+rN98SQNCe+xr2BR8rUS4hfA+aJiFdLNfG98jddPlIhbNp2HzZyWzKsGLsaO3e+iM+9B1cwKFyTtrl6S+Drw6gSVM+A1VY/KpW6X+H+00auZyGssNqwJO6IiJ9i51FJuhC3PezT6u9lOQ9fiq+tawLzyO1NffGx8wlwVURshZ3f52p1UAhZMWw6JUM7H3a2G4pnAO1X7uuPA5rry0WgVWtcFEsD1sMXnpXwhmjPsFHLzJShr60+8OopB+ElWPt+ATYFWRGfqI7EAc/8tROvpC+Vk3Wj1/UdLBNYHWfVFsQnsd9GXYN2eewM0aR5NfIA3c1xUPoivmitih07/1P3PlVmw1ujfNbn4U3vA7jydA0OvOfCgcxD5bEL4WrA6A68zto4wPwdzvjNjftTz8bHxNiySapVxCpXaZgcZCn767gS8BV84boiLJ2cv6Ob9rpKzRtYdnQ7/rwOw+ePx2UnzCOBw6JBM/OmBLkXb2ZswjQGn1N646Tdc2G36H2AgeEB3pU6RtQ2/ujtiNi53LYg/t7ehRPCs+E+4gu6IpCYwBrGdwqcNiKOqnvMyriv5tAGBqa1a8Ka+PxwR1nTu9iIbDh2mK3EZzchJO2E5Zqn4RaEH+K5hA+rzWVzlugiV3BJ2wFfj4hhJbDqhzexW2HZ5a1VSghPDHkswAG0zbVbs/z3ahzYzNiM5HC5PgzC+78F8UzCmsP3/Ng9tlH9vR1CNqo6Fgd/4yLit+X2H+C91Q5R5NbNOgeW8/OX8PmrH253uaLcNy/eZz1Shb2ppNNx8vBUSX/ALRkvYtXC2+M9tjrXkIqsY6pA1jz/FM+4uricDDbAJfGavXlL+xpKhncTLBu5AveBLI7NZXrhk8FvgGmqtgGW9BPcQ7KzpCE4s/U63oSOjoh3WrAm4Sxv4Orgc7iHQFjyOLJ2MmjmiUGWCP4Ma/PXBAZFxMnlffukrPXeiKhcrwOApKuAhyPi6PLzaBy8jcbH0yeyqVCH+5VKUHgS3ry+gDdmj2ODm4WAJyLidVXUfXJyKJW6PjgTfDO+0P4Vy1xmx0mqDh83ko4C5ouIXcvvv8JumGvgCuFZOGM+exW+a7K8ezNcSRuJN+CrYLnPh8BOYRnxomFb+0pd0AEkHYx7BqfH550rcXIv8Pf3qYi4XQ2Sq2vCToH9sXLjT+U97I1bKhqWCCvvxWj8//1mWGa2BL6GHVcq/ZVG0h74mnwkrrofg1sQ9sTmdQ804DUXw32LF2CJ3uZYlnw8Vt1cExUb4TE+stR7PSzXG4VHA7yFTUq+gzfs9zR4Dd/H7RgPyAZBS+PExADco1zpAFtuoXgfH78LR8Tl5Zy+bERsXB7TtOufpN3wfu4OnHDcEl+nromIPzR7PZNCnvl9Lw5ix2FX5kFYvnx7LVldtWtISkmbRNlwHwIch50wj8Mnrf8C35C0MXw+0LdllMztZbgiuBzWj9+GA5mTcJWzbwWDwl7YUOBKScOwc6DwJncAcGbtPW4mYY6mbXDp41jeNQBXnzYtleKmyjVLtmof7EC6egkKB2NXttvwhbSqMynnw0Yo90m6AZ9kz8bSjM3w8VRzvezI89dkRNPhXrtbcRC/Lw7sF8aVhsGymUolLkKTy3gyqWmxXPLXuNI6bUQ8i/vODgLW6aSs6mrgHUmLycYy43BAuBKWZ/4AJ5laHhQClAv1A7jKdTkOYHemfP4loFFVg8LCeRExBFfUz8TXmCXwMdIPVyxoRFBYmJBT4OO0OQVOGxHjmqCOOLf82xIYIxuNXAicXwsKO/n9biiyjH0dfD3rjdUvn+LN+kXAkKKI6Gqews6dK9Fm/T8Uy+XXxE7alURtUv63sPR1PpyoWBMrTGbEQfUBkgY2cB2zYyfeHSRtjpUY0+BjcB1gb2BrVbD1oHZMhGX9H2DfixtLpfA72Pm7T3lMs4LCdXHL1Zb4c3wYK1HeBHYs73El3KAB1GYutBpe5xn4+B2Cky4rq7jBV+0akhXDBiNpqYj4Z9kUzYqrMcvgTezd2EnpU1yVu6tZMsJ21rkDDvh+WX7/ITbwOBrLqvbEB+U3q5YplDRneBRBL7y5/Q1+Tx/CNso/xBvd5aNJ/UuyodBlNWmPpAOBP4ZdUjfAm6W/YaOPp8aXFTRwXV/YyJaM4CY4q3p3XdatU9W2RlMkLuvgIO0sfPLdEAe0VwKvR8QdHXjemiyrF5arzIANHVbDfQsP4w32ebQFiVdENW3t26Vk0rcETg8bqqyHj+1Z8CzNbwIH4oBi25hCGWnZVOyCeyfelrQsrsB9hOd1fh1Llp/APVEt76mR5fMf1P5fZXnrx/j89zGW1I/EVYamKw8mB7nf5uOIuLr8vhmuci6CA7LRWCWwT6PPgyXZtT8Tdgo8MJrkOls2sIthWfCZ+Lp7G5YFN0TC2lnkmYQPhse3TI+PmVUi4mdyb+gMEXFRSZK9Gw0atVR3PtwDf4+WpfpGM9/Go4MuluWbu+MewwdwsHsUfj/PCvemNWINh+Gk+gk4sNodnz8+wgmxVfH5da+owMD1yUHST3G163Ac5M6K96yvNen1p8N71Ffk1od7sePo9Dhp8Q8807Mp/gwTQtL+uEp8f/l9Jfx+fQurKGqzMlfFVcPKXU9yXEUDkaWiP5B0RkRcW27bF282PwX+Hm3Nzq9GawdxXgwcLGnviDgdZ8zPKOu8AG/slq9gUPgtYICkG4usbxm8AfoFrk4chAOGNZoVFBbeBQ6XdEz5jJ/CQQu4knlXFEetZiA3kP8jbDpRHxw+A9wErFoXFHZ4rEMjkV1Sp4+I34adW3vjitf7WGJ1a0QcI8uhp7hnpPx/14LCc/AF/ULcr/UgrlJeBRwRETfJLrOPdaegsPAGrl4Pl3RkRNwoaSyWGu4M7AX8AfjBlAaFhS2wwcMCkn4ZEY9I+m9EjJbnn26MkyL7R4sMtuqRe4APxdWXmSLi/Yh4tCR3PsO9aIthY6axOJlTRR4FVpNt5Z/H7sLPySYRg7HDZMPMfVTnFFhe9x0seTyj3L8B7vvet5FBYUnC9sFmHkvjdoL3cFB8NO6z3AgbRb1QteNXdq/sj/t8/4ivwW/hcS77YwfmKwCiE07Lk0M5H06He4+Fg6lKBtMA8niZ24EjJA2JiEvlPq+n8LF8GZZFDo+IX5e/aUTV/zX8GR4MHB8Rh8tOlHvi8UY34vNfpYLCsmddDV9Tx+Ak4SM4Cfo+ThR+Kinw+9gUo5SSoPgYeKVcn8fgVo5aUHpwM9YxKYoiYTpgO0mfhD0kpsWJqG3wmoeXx/65asq7GlkxbCBFSjAtzrBcGbZo74OzBx9ExL9bub4acj/Bs+G+rFNxpvKCct98+GR2VdWCQvi8J3JxvKmdHm8GHignr4NwT8SK4aHOzVrTKljqsBTeBB8Rxc1RnmO0DXB/NNjSuW49c+GZU4E3GjNOKEvVoItkl1ACwYOAUeFZSQtgE431gLkj4pDyuCnuMaj/G3lY+eu4Z3FrXEm9v1RgRkWD+1IaSamEHYoz2GthedUh5djvXX7fBweFz3bwNXph6VttJtdJ9RUNSSdhW/GWuo+WtayNFQWH4M3cIhFxjzxWYXbg5mgbTbIQHkfSElXHxCgJx7lwT99QfG0fVu4bgP9fXmvURlSWMx6Dr3dXRcTl5fZZ8Ab5EFxt2DYa2FNVXu8o/FlegKv9z+Jq0Qe1Slepmr/XqEpbZ5C0Ij5X98dVhvvDvV1r4U37kRERVT5XN5uawkX2GRiLpfE/xVXh88pjZsfyzdki4kflti57D+sSim/h69IonFD6BLgwIv5crlnHAsc08jjoKOV8uD3u3/sIJwq/YJJXV0VuuKpIdYZKkr4cZVa23Jp1J/BylY4FSRvivcPyWL5/enjU2wxYbXdbeVxl+iDbIwPDBlGqGxtExGayjn1fLDm7W3XGBa2mbCi+h+eUfQUPW58Fy1POLI+ZvmqZjfoTgTzfaRXcD/STiHi5bHK/gU8cTc1wSlofOxg+ghv2PwWOioj3yrqWxpK0ZrmProL7Kj7EEsIHwjKkSpxMJ4dSBfgUZ1oPo7hDlvsWjuLi25kTbrmwn4wrzcfhTe485d+t2KXvvs7+v7QSWYJbM9M5Hl+8psMV7HGybK1XRHRouG6paCwVEbuWTdoyuMJ2UlTAhrseWeJ6Ic7gv4STOLfic/XH2CQsmrEB6gyyPPMI4KCI+H0J0jYA/hkRdzVpDS13CizHby9clbwYJzmWi4gTSyb/hWiCC3VnkM01VsXjdmbDiamRtfcyaR+V4fWSDqFtH3MuVgu9UEsM1xQB5ecu3ZzLTsWLR8R+Zf/3Gr6WvI4Tii+Ux/WO1qrD/oe6YG8lYNaIuKWcv2/AqqIBeF7rJ83aN5SE1mZYCTEXrqCfGZ4/OXdUz8F1D7wHPRn3VAeWXp8zXmBd+X1Xms80gBJsHYD15ZTM0CnA5pK+UaGgcHZKVSsifoY3cL0i4hfAfLKUiqoFhYU+tR9KUHAbroYtJ2m+sLHBX5sZFEpaqZz0b8By1t1wz9ZfsLRl5nJBeLSJQeEu2BV1M9wrei/wmWz+UOmTU41ykR2Kg5j1sSRsoKTt4fPP/3MpaCde6mhsDnAtlpptDSwUETfjvsIVOvHcLUXSYEkX4+Hs2+LeyP0i4m6cLDi3fCc+6kRQOBRXb0fKA4efxzLl5YBDJc3aJf8zXcecOMM/F21B4c7AvBFxeO34qHhQuB0Oxn4OrCI7Bq6Oq2RrSFqnCWvYDUv1jsIS5NeBjWXHWyLiVZwUbWhfWjn2e+N9ze44MPyvpN/jntk15RlilaTsG7bEA+pHh2XWVwIfSKqkSUmrkZkWy+IvwP2jB2JVRD98HPxK0p4AdUFhZ68V7XEX/r7NVn7vh5OLmwKLS9qyHI+VMzuqey+mA+aQZeFj8bn7Njyz9zslSdasfUNvLEV/B3g6Ik4pQeG3cDW91s/ecso+66dYcv0vbCz4Hzzrcy+5xQmontFMe2Rg2EWUE9TSJdhaH2er1pV0UMlMz4hdPbdUA52wJnONK5ab3sFZjQ0BIuJkHNAQ1kG/LuviK4Xcg3GSpMXL771w3+aH+ES8kopjVpNZEThRNge4AW+Uti7ygfvxQFY1K1sou7PuEBHr4oHSG+Nem1HAVrLsqtLITqlD8IZpBB5r8BnwW2BQ2RgDXXLCPSkihuJN7mx4XEt/SVcD70TEbzr5/C0jIv6IpTefyRb+7wDHyiZT6+OxNHN08mVGAE9GxDHA00C/iPgdcA/O4m9UjtWWMd5G4k7sErcE3tTtjEeSVP5zrruGfIir26/jvuZPcfXzCVwNVakCN2od61Mtp8AZccXtE+CXuHr4NO55fRbP4Ksq82Ijsvr+6JXwZ/sprj4kX2TmsJP7cXiM0FewDPIgLIU8AUvA+9b/UYM2509hyfI+WK56Dj7HDMJGLc/jqnlLnedrlP3gl0tip8bC+HpwOZ63tyMOss/HPfcNTU5IWq72c0kkXR8R9+J+4BnK+eRo/FlXIsgqe83e+NqxEFZvPItbm0bi78Sycq9utyClpF1EkfNsiDeX95bbfowzMDcDC4QboefBA3Vb0ttQslknAhcVWWsf3IcxEl9UVTZzlaNUMP8vIsbKPUBb4AD8aRz0jMRBTz8s1exQ5aMD6+pT+zzluUXfwWYP62P3uN+X+2Zs1prK6x0ELBkRO5bfl8EnrztwX+arwH1VOLlOiBK81uZnzlcksDviTNzD+H2+oZYJ7uRr1cuTV8NS4FOB/0Zxr+sOMpB6SrV1xog4rfx+ILBYROwpO7vtgd/HodEF/WfyjLgh+H3bEbu3voEvkh+3svqmNrmUgEWjrsdHHh/UH/el9cVy65b3QLaHLBU9CjgxIv5ZbjsA2/K/A5xQUySoQbI1eUzL0yXonCsiXlIFnALL5mvNiPhLSYD0j4h9a/dFxYxmAFQniysqiAF4ZuG2eO97iaS5cXtH064fVaYcw7PigPD8iHhQ7qU/Hit07sTjPBYFTisqqGatbWbg/YgIWbq/X0Ts0qzXn1zKXnAsrkpfHxHnSFoSB38jcWL0pHIs9cIzRxt2/Mju2NsBZ4fnrK6PVTpn4PabdbDC7YCIeKJR6+gItXNLKQrMiQsBfXGCbARlclkr1zglZGDYBZSL0bewhGcePMD3RtkJ8t1owADaKaUc2H/CQWBv3IR9fVhLPj02ohhdF9RWbgMsaVt8Yji2LjjcDTuojoyIW8rjmtYTVDbeC+HNT82eeDf8fbgtmus82gtLmP8VEX8pt22AA9XhWOY3NiJukNQXmy9UzkgDvPEE3o6IN+X+peNw5m0Ulvo1pOdmvODwXGy1/8Px7+suyD2tB+Lh3ufU3dYHV5VG4KHtHXEfndBrLou/a/dGB0aGNAJ9cQzJ+TjwO7XctzawVUTsXn5fqhZwVZUSgO9BGXBeNsX9gXERMaLBr70Hlmn+IiIeLLdNg68pV0UxiGgl5XNePSJuL79X8tiVJWjL4T3DzXW3rQTcGW1jPiq5/lZTKuf7ABdExMOSZoiID+XB4qcBh0XECeWxTX8P5aH2i0bEVc183UkhaQ1cRb8WVzQXxj3Jvyj3L4XbikY0432TzaBWwMHUarhH+H4843aMLAUejIPsKrviLo4NzK5r9Vo6QwaGXUCpFj6NZZn74y/3IVi2t2AJElt2Yi8XyYtwL81GJbPRFwdVZ4xfvaziRahksp7EAey3sZnLu5K+CswUTXQdrVvTjvjk+iv82T8VxWlU0jK1DVqTTqy9gEux3ONabC89TdhNcwv8vt0VEf/XyHV0BbJ8dB+crawNoZ4N94M9GBHHl9sa9r6WY3pQRBzc6NdqFLIsZ9WIOEXSj7Ar5Tl19y+Nk0FdPjJCdW5yraadoLAvdpr9mSxLr4wsaXKofRclDcLB2Pnh8S0NMzWre80ZcOZ+Jex0elbZkAtXim/Hzq1VcgqsxDrGp5xjhmAHzUE4EKwlFwdFxOPl50quv1XUHc/DcLLwZewsfE7UOadLWrPViQFZpTMq3GdbCUrB4igs8f8zlj0ujBVvT0bE2U1cyzR4jvKb+HzSC1gXqx9Oiog7yv5lGLBro85vk0u5huyMzbVGj3efgAWBOaKCDv5TQgaGnUR2otoAW/zOgYfCL1F+vi4i/tzC5QEg6SxgJmwuMws+mc6OG3tnwl/yprjXdYSSoR6MZ5+diE8c38CWz++2KBO4G7A5sH1EvFFOXp9GxNWy1OvVkrlsVlB4CT6pHyHPIjoXjyDZqzxmkSjjB6q80SgVzmNwEmNd2npeX1IT3XElzRZlpEeV369JIelnWFZ9UQkOX44yimZqomxALsJzpI4qyYf9cYD4Y0mLR0XGB00ISbOHZ0HWj1b5JrAV3hQ/2oQ1bIer9r1xcNgPS7/+IWmeiBg10SdIACgVkA2w3Hpb7Kp9PT6PL0gTrx/dlZLY2hM4HUuof4i/i4+O97iWjQZo5Wu3RwleDqUtefx1rJ54R1bpXAhcHREnNnFNF2D55RDczrQObsFaBgev8wB/iQabV02Kss+6HO+ff4FbW55XxV2rO0Kaz3SCkm0eih1H58LBylW4N+k9YJNS6Wo1R4WdCEfjE8Kz+CA8q/w8f+uWNnGKJGQjrD1/E1ghIq7BFsbDZfvpZgeFC+MM7+7AWHkO5J+A60uA+BNshtOsKsSewPMRcUTd72NrQWFZR3cJCk/HzqCbYgOJU4F3ywb4q+VxDXci685BoaSVJe0kG2HdCSxVNqI/B76iOsOeno7c7wN27vwy3gyBJekPl6DwZLwxrySSppEHd59UAthaUDgPvs5cDexczkuNXMfe2BH4QXxsvo17lHaTtFwtKGzG8dmdkWXAg/A1eCNslrNtuO1ga5p//eg2yOwnt5GMBh7C42X6YOnoPuV6/DmtDMyqEhSW922O8n06viib+gJjSlC4AH7/5sPBWbPWNS9O+D+GK+dL497Rp8ptXwf+XqGg8C5sInk48H7Z328hqXdPOu9lYNgJwjORtsYZ24PwQbUmMAYHCsdjJ6qWIfcTvVR+/QAbQSyP+46+jCtx97ZkcZPHBzirujh24Lu/ZPtvwBr0jVpwQD4HHB7uy5oN2AtvNNcoP580vsygwVwbbcPdD8NV6+HtPbCqGw1JM2LThVewDPstfCI+H1fgj8bf3ab+P1T1/WqPIvMDG/OshL8Djxc57Lw4K3sU8KEq6Dbc1cj9RwfLPY8/j4g1gNklXYfNwA6QdDwwXVTUcKvwWUS8hhN5u9VtfNfG/bZ3YCXFWxP4+05TNkAb4nEUBwPCo0iuxzMfdy0Vh251zDSTkkgGH5P7A/vhvcNjwCIlMbYzNhUa3ZJFVhRJs9Yl6R7H0sJNIuJcPEpotWgbC7aAWux+XEEWAAbLvcg1h9ZZ8Xt1Pq4UfgU4NSKOgqYleN6OiDMj4lBsevMOnrH7AQ4Of4F74VvNMJwEOwfPGB2J1RK/w8qscT3pvJdS0i5A0oKlpHwGLsufM8k/agKSdsINvc8A1+BKzLP4wr4ELtEPi+o5PK0HfBJtZjIL4g1tbfjvgjU5nJro9Fku3M/W9X70Dg8Fnw64DM8J/H6rsltFNtgfb94+wm6aj7ViLR1Bdt7bBF8UDgJ+j23a18JOZJWW+rWKsgk6FSdKrgsb9syME1N/xUOWZ4omGiFVgXIeWQvL+i8JO93tj2dT7i/pBGD6iPh+eXxlqsN1n+kjeFD2dRHxqTxqaOdy+xsRcXWT1lPvnHk5VsbMjTPoc+Hk46vRIrftqiO3F6yPg5oX8HX4sPBoFyTdgBP1Lbt+VBV59t+m+Lp2Z3jI+hrADtj1+BvYmbrW318p+WYVKOqCpfFYGSJij5oEsihITsWVxJ+Xxzf1XFjULb/G7tg1tc4MURFzPHl24gB8PbkD753Xx4rBd7Ez8/0tW2AXk1mVruEFSSsAN0Wb819Ly8pyY/sWOMs8DvhSRDwdEZ+Vg/8sYMcKBoXTYYnIlyQtL2mxsDnGncB1wDz1PVJNDAqHAIcBn49FiDYb+HVwULh3My/qkpaUNF/5eTU8O2lI2AFtRjznb55mracjSFpL0qIAZeN5M5bHrY8rX2sC+2ZQ2D4lgLgA93y9CvQpF/o+wI9wJXvWWlDY6vNSM6gdEzhgeQ1LHrcplcMzS1D4a1wprGpQeCGukD+Hx4t8WhJk/8RyzntqQWGjPlNJq0tav7yfB0vqI5uW/QcfpxeG+7nuiIgnMyicKC/h9oeDgVXKdbgWFA7Ge7G9Mij8IrJRyuFYbrgQDm4oVfLTsOLpxlpQWO7LoLAgu31SZN634mH1/5THK3xa7rsY2KBVQWFZw2j8eY6tu63lQaGkRcpa7sFJnR9hKf1G2HhwDuzn8Eqr1tgIsmLYRdRXrlq9yahJp4BdIuLlslH8a0Q8J1uzj42Iv7dqfZOiyAoXBzbDM9gOLLdvGC2wAS5B9ubALbiC9RAe9TBC7hcZDhzZzOBF7hnbFksbbsH9lx/VvnclwB6EDWlafoJtD9mWfSdgs7CBT72pxoZ4E7V7bpbapwQE1+KxKCdLGgp8F0vZdwubV3w+u63V56VmUaqC38Zy8ztwYmwFPE7oZmxssHKR81XufZE0HA/uPqTID5fAhi/H4cr503WPbcjaSwb/aCyX+j/cEjEW98U9joPBNJqZBKXadSceIzKuVHyXwhWuUfJYgCNxa8LjrVxr1ZD0bfydr/kj7IRVJNsAL4TnQlfG/biKyLOMZ8EKgwdwS8GGOEnxcESMHO/xrTTqqUyFED53lP0afq/+GxGvyU7f12EDn1ew4dEBPe3YzcCwB1J05IPxyWA63Pd2HDbv2B87aXZ6mHVXIw+DHR1tRikr4IvoExFxX93jmraRk7QV1pRvGBFvSToa9zyuh4PEAbg5+o1mrKesaRcsuTwSD5KeD2/U3qjaJndCyE6zG2Ap83NlgzR7RPy1ZOm2wW65lapoV4mSTd8e+DGWuGyDq63H4r6vz2pBdXf5XnQVsqHMdbhSMyuWoG+Obdl/GBGXlcdV7n2RtC7uA3oOKxTWxf3LD0XEj5rw+rVxAOvhETxPyw6Qp+Dv1h0R8Umj19ETkHQsPj+/jZMSH+NrRi88iH0UTn427frRHZC9EYbjY+BmYEl8LO+AzfK2jwYOW+9JSDobnwN/iyteL+PRVkvhcTMZWI+H3K+/GHbt3xm4NSIuL0WW+XGiYndgu54WFEJKSXsqgT/b5bEW+iZskrMXlqtULigszAPsLmlr2exgFPAvYKDsQgY0x9xA0srlx+WAu4E1SiX261iG+wPgDOCRJgeFm2GH1j3CsxtfwNWFN4qc9FvNWktHKQmAPYEjSlC4Cq58Pi7puzjIOS2DwknyJHAFNiHZEfcQ/5O2TcDwUjmeagxBJPUqm8r3seQHLPXeAJvvnFrloLDwOnb9BGes18EmDNNJ2rLRL16CwjmwYmOMpK/j4/OiiLg5g8JJI49HAQc3I4Azgb/jIHFtfC3eHvgwg8IvIpsrzYT7B6cHvodl8tvgoHr38CzmaSb8LFMvkpaQNF9NBolHoAzHhmRPRMQuuAo7dwaF/4ukbfD14pv4WnoBMKM88uviIrl9ENi4JwaF4L6UpIcRNp84r3YBl7QtsDKwX70MqWpExI1lI/s9LJ96Gsvi/gXMWi+LaySS5gR2kc1lDi23/Q5n7Wv9hCfggasvTfCJun5d02JZ3JAiQ9oBZ+8vkLQprmxu36z1dILRuPrwbpGMHo11+ssARwA7ZL/ShJH0NeDRiHgZeFnSL3FF4o84WNwJX9RWmNqy6kUG9ZmkK7GL8by4WjgfcG6U+VxVCwol7Qj0jYiTI+Ih4KGSiNoSuDQi/iLpHrxhbgazAL/BwfTx2H30WUkDw+6PyUQI94TOUOTc02N1yZZ4LMogXAk7N3rY/LPOUuTxa2BDmWFYxjwdbitYEBvQLCHpXxExdkLPM7UiaS3gpzhhOA4nrz8DFsWJ96tLFfvtiDis/E2lzoWtpLQxLY9dlx/DhYE78PE6X3mvnomIByf8LN2flJL2cOS5esNwz1HlLuiSvgq8GW2Od9MDgyPi8vEeN20zM9Vy0/bRwDUR8SdJ5+GN5nv4xLFfM3sKJ7DGlXEQPRI3Q1fOYbZGkaWNiYi/ld+XBFbEgez52E11VezKV8n/hyogjwRYFXguIm4r7+NatG0EfoVlxqtGxMMtW2iLGa+38nigV0QcVH6v5EZI0oG4d/lMSX3wZ3kPPt9cEE3uC5fUH9uxnxARt0raGKtRboqIj5q5lu5C2ZjPjBM0u+IWjrVwH/i+WMp3C7B/hZU7LUE2IRuIjdPWxO/jvlgCvjEe7TEQb9afKIqZpFCUN0fgUWSfAJtGxHGlbePvWEX2Q9zvumP5m3RwLcimX/Nj6T5YfTMw2hzw98TB9fE9/fyXgWEPpuikhwF/rGhQuBd2Tj0fG2i8XOQhOwN/Cs/uavaatsNByoXYAGcwllD9rUg1f4plnM80e211axRYHliay1fHDdBPtWpNE0N2MhyIe1wH4jldb0nqVxq6V8FDnfetckW7CpSL19JYUrUscH9EXFvuWw1niHfo6RnNyaG9ALCKQWFJ3k0bEZdJOhyPfTin7vgYCLwTEa82eV19sZt1bQzAXHiMUFbz26EE88fhauuluCfuYxzcHI6rr8dho7JKnqtbRelh3Qu4Hbt/X4J74frhEVF/Ko/rheftvRgR70/g6aZKJO2Nk6+XyqOfFsMmXEtGxJblMQuGXd4reS5sNUWxVhuPdhvusb6zJMUOxAWWHr9HycCwh1PkkOMm/cjmIjt9bgocg/sI5gDuLgHDYtECJ8qypt1xRvc32Op+Huxo2AvbZd9clYqWpM2xfHSXqp6sJC2As3B9cO/U2vhzvqfc/10cFO7RU/X6XU3ZHH0V94A9GBF/LrfPjitjDRt03t2o3/xUcSMkz5odAlyNR2l8JruSvhge3l0JqvjeVQm1GfZsgZM1z8vmaSfheYX3lsdV8nrcaiRtBLwcEQ/JTq6vYQOmgTgQPKlI55MJUK6lK2D34BewF8G4iNim3F/v+p3H80SQx3x9gqvT62Ojnv2qWGBpBGk+08Op4kVI0tZYQrh7eCjoy8CcJShcCWdcGzafawJrmoW2DNslETEqzKs4aB0K/L5CQeEMuGpU2QyW7Jp5Ipa5Lo7Xezs2E/pq3UO3z6Bw4kj6mmyqUuujewZnNKeTZ81NGxGjMyj8IvWbn6pthOTRQdthI6a3cB84EXEUsICkXVu4vC9QtfeuapSgcE48CmCMpG9i85RfAR9JGlbkzZW7HleEJ7DxXH98HGyOlTt/wMnPw1q4tu7Cfdgk6mzcy9oLuEZlrmu9ZDSP54kTHsUzGpuY9cGKrKkiKISsGCZNRNLKEXGfpO/hAc0vycY4fw4b5mwG7IelcC+2YH29sEnF5sCIiLi9ZDKHAkNbUcWcGFXOPpcgZhHsfnYzzvq+h0cITI+rXSPCRhvJJCj9Df2BH5dNaH+cxXwHV7Ufj7ohz0n1KbKl2cKOwqvg8SJ/q7t/MO7nS8lcN6BswOfEfZiX4f7MBXGwuMnUtLHsCCVZ+GXcGjEC93j9AXglItad2N8mbUj6Ea50fR+b+M2F91vZ0zqFlOLEtDGVmbilK2nSFNTm9DlTRPy+7q7XgEMkPYVd2/ZpRVAIn2d938X9Dd+VdDVugK9cUAjVrAbX0bv8Czzz8T7spPlBkcBujceoJBOgJErGRcSfwoYk2wJHSzoDS4ZGRcQ9khbEMt2kG1A2wGMi4hWgNqpgBpyd/lzyFRF/bNESkw5QEp29gbuwy3LNYXvDDAonTVHjPCHpbzjAvgcnvNaHNEqZHCTNih2qh0TEOEmBW2DebOnCuimlsjpVBYWQFcOkiajN6fOKWl9UuX04ng94YJUuoJIOpqLGPd2FUhXZHngYb5QG4CriAVUMtqtCyVQugvtwBwKHFqn1nsDcwN8i4rbaY1Ma1D1oz3Cr3L4T7rHKZEk3Rp7/OAgH+jtjR9d/tnZV3Q95Bt+x7fXHJZOHpGnCY1Py+pBMERkYJg1H/+v0uQlwXUTcUKpH+wM7V6VXLk+kHUfSLFGG5o7ngDYPtm/fDtisKr2aVUTSbBHxTvl5IWAH4IGIuLHc9uW6gCK/q92ECRhu3RURo1Vm3rV0gUmXIc9D6x05a6/TZFCYJM0lA8OkoUzA6bMflsIFriDdnNWj7o+kAbh38FHc19AXOCPa5sn1w66ZTbXd704U86XdsEvlKGwg8CZ2Rrsj+wi7J6Wvei9gm4gYVY6VVSPi/NJf+FFEPJCBfpIkSdJK0pU0aRgTcfochXsIDsCy0gwKewa9sezxHeDpiDglIj6WtJqk5SPitQwKJ054iPltuDdpAA6wX4iI04CvFUvypBshafry47YlKNwWGF2Cws3wzKyXId0CkyRJktaSFcOkoXQ3p8+kc0gaHBF/lLQW8DdgAzzguSVOs92BWj9hRDxTfu8LfDsifl/GUHwiaRvcs7R7RDzXyvUmU854M8S+A3wHqBluDUtpdZIkSVIF0pU0aSjdzekzmTIkLQm8XRz51geWlHQPIFwJWYoWOs12E4YDy0g6IiIexXM8+0laFhhQKu/fw8dMBoXdBEl9ImJM+bU/MBIgIm6W9A3caz3VDE1OkiRJqk9WDJOmkk6fPYfikLktHqp7K/AJ8GFEjCn3DcYb32dat8rqI2ldYBdgLHBKRIwoVcRp8CyqfYANsqrUfZC0MB7J8iQwI541+ZuI+KiKhltJkiRJAhkYJk0iTRV6FpJ2wRWPI7HD4peB28tIhS1wQLNLRDzVwmVWkvpjofSb3QTMDxwEfEAJDsv90+Mh6DmnsBtRZkseDFyMkyWPlNtXAlYEbknFRJIkSVI10nwmaQoZFPYcimHGdsAeEfEP4AVglhIUfg1XR3bLoLB96oLCPYEfA8fhmYUPALMBQ4uMlIj4KIPC7kcZ03Ib/kznkjR7SZicBFyVQWGSJElSRTIwTJJkspE0LTAOGFIcFnfAIygukLQpcDK58Z0oJUjoh3swd8PB4fp4zucJwJeAvSUt2rpVJp2huMcugQP9T4DD8RzP3SPilVauLUmSJEkmREpJkyTpMJJWxsYoI4GNSIfFCVIces8Azioz65bB7915wKLAVyLiVElr4xmGz9eZlyTdCEnz0NZvuyuwBdlvmyRJklScdCVNkmSKKeYoRMR9klYF1gH2Tflo+5Sg8HzgmRIUrhgRD0qaEzgMyw7/BRARt7RupUlXUGa1UoxmdsDS6gwKkyRJkkqTFcMkSTpM2fjWjGbSYbEdShB9DXB3RJwgaQh2q5wd+AZwM/BxRDxce3z25HZ/JM0ADCNdmJMkSZJuQgaGSZJ0iNz4Th6SVseDzE8AVgKex0Hh4cAxEXFT61aXNBJJvSNiXKvXkSRJkiSTQwaGSZJ0mNz4ThpJswEbAwOBO7Hp12HAeRFxYSvXliRJkiRJUiMDwyRJkgYjaQ7c070UDgpvBR4Dnshqa5IkSZIkVSDHVSRJkjSYiHgbmAU4FDgW+DkeY/BqK9eVJEmSJElSIyuGSZIkTUBSX2DeiHis/J4y3CRJkiRJKkMGhkmSJEmSJEmSJFM5KSVNkiRJkiRJkiSZysnAMEmSJEmSJEmSZConA8MkSZIkSZIkSZKpnAwMkyRJkqkGSYtJ+lYnn2OgpMW6ak2tRtLaks5o9TqSJEmS1pKBYZIkSdJjkDRA0lBJ35e0VDsPGQpcUh67sqSQtMYUvsxvgTM7t9IpQ9JMkl6UtE35fbLXLulJST+ZyEOWBfbskoUmSZIk3ZberV5AkiRJknQFkoYA5wFvAx8Dv5R0eET8rIPPNz+ePzk+MwG9JX21nfvGRsRLU/g6awNbT+DuZ8r6ewHzATNPyXMXZgam78DfJUmSJFMRGRgmSZIk3Z4SxJ0D/BI4LCI+kzQM+LWkWyLigQ487RnABhO5//F2brsGGDyFr7MksGv52/F5cwqfqz1mLP+SJEmSZIJkYJgkSZL0BPbAQdThEfEZQEScIml74FJJT5bHLTG5TxgRG45/m6RvAzcBAawZEX/t9MrbXm9wVz1XDUn9gDmB9mS1SZIkSfI52WOYJEmS9ATWAv4cEZ+Od/uNQH/gv+Xf2I48eenxOxi4tvy7ErhR0gGSZujoopvAFuW/a0rq39KVJEmSJJUmA8MkSZKkJzAQeKqd2/+D1TH7R8R+wF2T82SS5pS0tKStJF0EvAgcBBwKbIZ7AocBPwBeknSRpCGSVpQ0Txf8/3QaSbPg9T4EvA+cIkkTeXyUf080a41JkiRJdcjAMEmSJOkJzA6Maef2MYCAuabw+fYGRgAXAPMC+wP9I+KUiPgszLnAAGAfoC9wLvBA+duWImka4CKgH+5f3AvYCDhtIn82qPxbr+ELTJIkSSpH9hgmSZIkPYWYyG1T6sp5AnAd8O+I+GSCLxjxEXA5cLmkaXEPY3uVy65isKSFsENpu5R1nAVsAmwXESOAEaWCeLqkPsD3I+ILxjYRkZXCJEmSqZgMDJMkSZKewBigTzu3124bPSVPVoLBER34m0em5G86wCBc/WxvjAaSlgPOL4/bPiIurVvfWZKeBy4GHpC0RER80OD1JkmSJN2EDAyTJEmSnsBTwKLt3L4o8Bnwm9Je97VJPZGkO4DVO7meWyNi7U4+R3v8LCLOlrQycG879/fCQfAqEXH/+HdGxF8kDQIWyqAwSZIkqScDwyRJkqQncDuwnaRetXEVhXWxAc2UsAMeYt8Z3uvk33eIiHiISQS1EfEG8EbdTXcDP2nkupIkSZLqk4FhkiRJ0hM4G7uGDgeOAJC0G7ASsGpE3F1uOw34n/mE9UTE8w1daRORNCOwI+43XBLLUHvjsR3PAHcCZ0bEMS1bZJIkSVIJMjBMkiRJuj0RMVLS3sCZknYCPsYy0qNrQeGUImkmYMEp+JOPImJkR16rvN6DtR/x9Xkm7LZ6OjbDmdLn6w/cBMwNXAqcAbwKfFhuWxrYFhgmad+IOKuja0+SJEm6PxkYJkmSJD2CiDhH0r14LAPAbRHxQCee8pvAzVPw+CeBr3bgde7DVc7PgHE4qP0Ay1FHA//qwHOCR1PMDiwdES+2c/8tkn4JnIndSv/Sk6qlSZIkyZSRgWGSJEnSY4iIfwP/7qLnugVX7yaJpLOBVTr4Ovfh4HBiz9+uC+kkWBa4YwJBYe21Q9LFwO7AUkAGhkmSJFMpOeA+SZIkSXom/wDWkDTBmYeFbXGl8tHGLylJkiSpKlkxTJIkSZKeyVAshR0h6RLgFmAU8BE2oVkSB4XLAXtHxAutWmiSJEnSejIwTJIkSZIeSEQ8L2lZYCfsSro5Np2ZBruSPotdSbePiCdbtMwkSZKkImRgmCRJkkw1RMR+wH7l1w+wYcz7rVvR5BER7/LFfsfJWnsZYn96+ZckSZIkE0QR0eo1JEmSJEm3RlJfYIaIeKnVa0mSJEmSjpCBYZIkSZIkSZIkyVROupImSZIkSZIkSZJM5WRgmCRJkiRJkiRJMpWTgWGSJEmSJEmSJMlUTgaGSZIkSZIkSZIkUzkZGCZJkiRJkiRJkkzlZGCYJEmSJEmSJEkylZOBYZIkSZIkSZIkyVROBoZJkiRJkiRJkiRTOf8PfjjLYKeaObkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "chart = fig.add_subplot(1,1,1)\n",
    "chart.plot(y_test.sum(), marker='o', color='blue', label='실제값')\n",
    "chart.plot(lasso_test_pred.sum(), marker='^', color='red', label='lasso 에측')\n",
    "chart.plot(ridge_test_pred.sum(), marker='^', color='green', label='ridge 예측')\n",
    "chart.set_xticklabels(xlabel, rotation=45, size=8)\n",
    "plt.xlabel('예측 대상', size=20)\n",
    "plt.ylabel('오더 건수', size=20)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\user\\\\Dongwon\\\\Dongwon_Project\\\\더반찬_XGB모델\\\\0708_ridge_model.pkl']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lasso_reg, 'C:\\\\Users\\\\user\\\\Dongwon\\\\Dongwon_Project\\\\더반찬_XGB모델\\\\0708_lasso_model.pkl')\n",
    "joblib.dump(ridge_reg, 'C:\\\\Users\\\\user\\\\Dongwon\\\\Dongwon_Project\\\\더반찬_XGB모델\\\\0708_ridge_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model = joblib.load('C:\\\\Users\\\\user\\\\Dongwon\\\\Dongwon_Project\\\\더반찬_XGB모델\\\\0707_xgb_model_ne1500.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = model.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
